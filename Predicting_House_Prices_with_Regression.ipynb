{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Predicting House Prices with Regression.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xuCQb3NsBK0"
      },
      "source": [
        "# **IMPORTING IMPORTANT LIBRARIES**\n",
        "\n",
        "## 1.) Pandas [ For DataFrame Creation ]\n",
        "## 2.) Matplotlib [ For Visualization ]\n",
        "## 3.) Tensorflow [ For Building Models ]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2LsbrFMsBK1",
        "outputId": "aac79c0b-09bb-407c-ae52-10ed43571a0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "# Utils Library is not an inbuilt library of Google Co-Lab, Hence needs to be installed\n",
        "!pip install utils \n",
        "from utils import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LambdaCallback\n",
        "\n",
        "#To Ensure that the plots aren't creating new windows\n",
        "%matplotlib inline "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: utils in /usr/local/lib/python3.6/dist-packages (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5XsxR8wsBK4"
      },
      "source": [
        "# **IMPORTING THE DATASET USING PANDAS** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCdex0_tuXM5"
      },
      "source": [
        "### NOTE: The dataset is manually loaded into the Google Co-Lab. Hence, kindly upload the dataset into the files section first before proceeding ahead.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJMKY6HJsBK5",
        "outputId": "47368d61-17d1-4554-fea8-a7c319363aad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "column_names = [\"Year of sale\", \"Age of House\", \"Distance from city center\", \"Number of Stores in Locality\", \"Latitude\", \"Longitude\", \"Price\"]\n",
        "df = pd.read_csv('house_price_data.csv', names = column_names) \n",
        "\n",
        "# The Dataset is Huge and so Its advisable to display the first 5 rows to check if it properly imported. \n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year of sale</th>\n",
              "      <th>Age of House</th>\n",
              "      <th>Distance from city center</th>\n",
              "      <th>Number of Stores in Locality</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2009</td>\n",
              "      <td>21</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>84</td>\n",
              "      <td>121</td>\n",
              "      <td>14264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2007</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>86</td>\n",
              "      <td>121</td>\n",
              "      <td>12032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016</td>\n",
              "      <td>18</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>90</td>\n",
              "      <td>120</td>\n",
              "      <td>13560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2002</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>80</td>\n",
              "      <td>128</td>\n",
              "      <td>12029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2014</td>\n",
              "      <td>25</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>81</td>\n",
              "      <td>122</td>\n",
              "      <td>14157</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Year of sale  Age of House  ...  Longitude  Price\n",
              "0          2009            21  ...        121  14264\n",
              "1          2007             4  ...        121  12032\n",
              "2          2016            18  ...        120  13560\n",
              "3          2002            13  ...        128  12029\n",
              "4          2014            25  ...        122  14157\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ie-U_NQgsBK7"
      },
      "source": [
        "\n",
        "# **MISSING DATA ANALYSIS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7tS34TAsBK8",
        "outputId": "9a92d2fd-8df8-4d5c-a462-38e99dacb8cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        }
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Year of sale                    0\n",
              "Age of House                    0\n",
              "Distance from city center       0\n",
              "Number of Stores in Locality    0\n",
              "Latitude                        0\n",
              "Longitude                       0\n",
              "Price                           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6sfIeCoxjcK"
      },
      "source": [
        "## NOTE: It is observed that the Dataset has no missing values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWFLkSQhsBK-"
      },
      "source": [
        "# **DATA NORMALIZATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNXK0FdQsBK_"
      },
      "source": [
        "## While using optimization algorithms, it is always appropriate to find minimas by normalizing the data before training a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zT2QLyUSsBK_",
        "outputId": "6272ffd9-49b8-4fbd-b292-1ea780554b8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "# Note: The \"Year of Sale\" Column is been excluded from the database due to the\n",
        "#       finding that it actually does affect house prices.\n",
        "df = df.iloc[:,1:] \n",
        "df_norm = (df - df.mean()) / df.std()\n",
        "df_norm.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age of House</th>\n",
              "      <th>Distance from city center</th>\n",
              "      <th>Number of Stores in Locality</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.181384</td>\n",
              "      <td>1.257002</td>\n",
              "      <td>0.345224</td>\n",
              "      <td>-0.307212</td>\n",
              "      <td>-1.260799</td>\n",
              "      <td>0.350088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.319118</td>\n",
              "      <td>-0.930610</td>\n",
              "      <td>-0.609312</td>\n",
              "      <td>0.325301</td>\n",
              "      <td>-1.260799</td>\n",
              "      <td>-1.836486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.083410</td>\n",
              "      <td>-0.618094</td>\n",
              "      <td>0.663402</td>\n",
              "      <td>1.590328</td>\n",
              "      <td>-1.576456</td>\n",
              "      <td>-0.339584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.524735</td>\n",
              "      <td>-0.930610</td>\n",
              "      <td>-0.927491</td>\n",
              "      <td>-1.572238</td>\n",
              "      <td>0.948803</td>\n",
              "      <td>-1.839425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.534444</td>\n",
              "      <td>0.006938</td>\n",
              "      <td>0.981581</td>\n",
              "      <td>-1.255981</td>\n",
              "      <td>-0.945141</td>\n",
              "      <td>0.245266</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Age of House  Distance from city center  ...  Longitude     Price\n",
              "0      0.181384                   1.257002  ...  -1.260799  0.350088\n",
              "1     -1.319118                  -0.930610  ...  -1.260799 -1.836486\n",
              "2     -0.083410                  -0.618094  ...  -1.576456 -0.339584\n",
              "3     -0.524735                  -0.930610  ...   0.948803 -1.839425\n",
              "4      0.534444                   0.006938  ...  -0.945141  0.245266\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgcaakuUsBLB"
      },
      "source": [
        "## **FUNCTION FOR CONVERTING LABEL VALUES BACK TO ORIGINAL DISTRIBUTION**\n",
        "\n",
        "### We are using normalized values for the labels, so we will get the predictions back from a trained model in the same distribution. So, we need to convert the predicted values back to the original distribution if we want predicted prices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_OO5RevsBLB"
      },
      "source": [
        "output_variable_mean = df['Price'].mean()\n",
        "output_variable_std = df['Price'].std()\n",
        "\n",
        "def convert_label_value(prediction):\n",
        "    return int(prediction * output_variable_std + output_variable_mean)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI5LsRd3sBLE"
      },
      "source": [
        "# **SEPERATING INPUT AND OUTPUT DATA** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPrl-iFtsBLF",
        "outputId": "2b5ffb86-0bd6-4ccc-98fe-0cc36425d22c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "input_parameters = df_norm.iloc[:, :5]\n",
        "input_parameters.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age of House</th>\n",
              "      <th>Distance from city center</th>\n",
              "      <th>Number of Stores in Locality</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.181384</td>\n",
              "      <td>1.257002</td>\n",
              "      <td>0.345224</td>\n",
              "      <td>-0.307212</td>\n",
              "      <td>-1.260799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.319118</td>\n",
              "      <td>-0.930610</td>\n",
              "      <td>-0.609312</td>\n",
              "      <td>0.325301</td>\n",
              "      <td>-1.260799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.083410</td>\n",
              "      <td>-0.618094</td>\n",
              "      <td>0.663402</td>\n",
              "      <td>1.590328</td>\n",
              "      <td>-1.576456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.524735</td>\n",
              "      <td>-0.930610</td>\n",
              "      <td>-0.927491</td>\n",
              "      <td>-1.572238</td>\n",
              "      <td>0.948803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.534444</td>\n",
              "      <td>0.006938</td>\n",
              "      <td>0.981581</td>\n",
              "      <td>-1.255981</td>\n",
              "      <td>-0.945141</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Age of House  Distance from city center  ...  Latitude  Longitude\n",
              "0      0.181384                   1.257002  ... -0.307212  -1.260799\n",
              "1     -1.319118                  -0.930610  ...  0.325301  -1.260799\n",
              "2     -0.083410                  -0.618094  ...  1.590328  -1.576456\n",
              "3     -0.524735                  -0.930610  ... -1.572238   0.948803\n",
              "4      0.534444                   0.006938  ... -1.255981  -0.945141\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH_StUcTsBLH",
        "outputId": "45060486-124e-4d42-b87f-4b4818b6359c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "output_variable = df_norm.iloc[:, -1:]\n",
        "output_variable.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.350088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.836486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.339584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.839425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.245266</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Price\n",
              "0  0.350088\n",
              "1 -1.836486\n",
              "2 -0.339584\n",
              "3 -1.839425\n",
              "4  0.245266"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiqCoYeosBLJ"
      },
      "source": [
        "## **EXTRACTION OF PARAMETER AND LABEL VALUES**\n",
        "\n",
        "### NOTE: TensorFlow Models Require numeric values as input so we need to ensure that before training and testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Amtwp6LjsBLK",
        "outputId": "1e20fb17-2312-42fa-a3db-0a91b3171ff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "input_parameters_arr = input_parameters.values\n",
        "output_variable_arr = output_variable.values\n",
        "\n",
        "print('Shape of Input Parameters : ', input_parameters_arr.shape)\n",
        "print('Shape of Output Variables : ', output_variable_arr.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of Input Parameters :  (5000, 5)\n",
            "Shape of Output Variables :  (5000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buEP1WgusBLM"
      },
      "source": [
        "## **SPLITING DATA FOR TRAINING AND TESTING**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQBdIUxXsBLM",
        "outputId": "d34f19fe-0b37-44c5-aa27-274c81202278",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "input_parameters_train, input_parameters_test, output_variable_train, output_variable_test = train_test_split(input_parameters_arr, output_variable_arr, test_size = 0.15)\n",
        "\n",
        "print('input_parameters_train shape: ', input_parameters_train.shape)\n",
        "print('output_variable_train shape: ', output_variable_train.shape)\n",
        "print('input_parameters_test shape: ', input_parameters_test.shape)\n",
        "print('output_variable_test shape: ', output_variable_test.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_parameters_train shape:  (4250, 5)\n",
            "output_variable_train shape:  (4250, 1)\n",
            "input_parameters_test shape:  (750, 5)\n",
            "output_variable_test shape:  (750, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywEolwP-sBLO"
      },
      "source": [
        "# **DEFINIING THE MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkyq217-sBLP",
        "outputId": "35db7dac-861d-4b7e-e8b5-d7bfc4d73c5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "def use_model():\n",
        "    \n",
        "    tf_model = Sequential([\n",
        "        Dense(10, input_shape = (5,), activation = 'relu'),\n",
        "        Dense(20, activation = 'relu'),\n",
        "        Dense(15, activation = 'relu'),\n",
        "        Dense(10, activation = 'relu'),\n",
        "        Dense(5, activation = 'relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "\n",
        "    tf_model.compile(\n",
        "        loss='mse',\n",
        "        optimizer='adadelta'\n",
        "    )\n",
        "    \n",
        "    return tf_model\n",
        "\n",
        "tf_model = use_model()\n",
        "tf_model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 10)                60        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                220       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 15)                315       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                160       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 5)                 55        \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 6         \n",
            "=================================================================\n",
            "Total params: 816\n",
            "Trainable params: 816\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPqUXCEysBLR"
      },
      "source": [
        "# **TRAINING THE MODEL** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YaR9w8usBLR"
      },
      "source": [
        "### NOTE: **`EarlyStopping`** callback from Keras is used stop the model training if the validation loss stops decreasing for few epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUCAZAFSsBLS",
        "outputId": "d6cf4860-c3b5-4302-aed7-874919810991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience = 5)\n",
        "\n",
        "tf_model = use_model()\n",
        "\n",
        "preds_on_untrained = tf_model.predict(input_parameters_test)\n",
        "\n",
        "history = tf_model.fit(\n",
        "    input_parameters_train, output_variable_train,\n",
        "    validation_data = (input_parameters_test, output_variable_test),\n",
        "    epochs = 3000,\n",
        "    callbacks = [early_stopping]\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5844 - val_loss: 0.6384\n",
            "Epoch 502/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5833 - val_loss: 0.6372\n",
            "Epoch 503/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5822 - val_loss: 0.6359\n",
            "Epoch 504/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5811 - val_loss: 0.6347\n",
            "Epoch 505/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5799 - val_loss: 0.6335\n",
            "Epoch 506/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5788 - val_loss: 0.6322\n",
            "Epoch 507/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5777 - val_loss: 0.6310\n",
            "Epoch 508/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5766 - val_loss: 0.6298\n",
            "Epoch 509/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5755 - val_loss: 0.6285\n",
            "Epoch 510/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5744 - val_loss: 0.6273\n",
            "Epoch 511/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5733 - val_loss: 0.6261\n",
            "Epoch 512/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5721 - val_loss: 0.6248\n",
            "Epoch 513/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5710 - val_loss: 0.6236\n",
            "Epoch 514/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5699 - val_loss: 0.6224\n",
            "Epoch 515/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5688 - val_loss: 0.6211\n",
            "Epoch 516/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5677 - val_loss: 0.6199\n",
            "Epoch 517/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5666 - val_loss: 0.6187\n",
            "Epoch 518/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5655 - val_loss: 0.6174\n",
            "Epoch 519/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5644 - val_loss: 0.6162\n",
            "Epoch 520/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5633 - val_loss: 0.6150\n",
            "Epoch 521/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5621 - val_loss: 0.6137\n",
            "Epoch 522/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5610 - val_loss: 0.6125\n",
            "Epoch 523/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5599 - val_loss: 0.6113\n",
            "Epoch 524/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5588 - val_loss: 0.6100\n",
            "Epoch 525/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5577 - val_loss: 0.6088\n",
            "Epoch 526/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5566 - val_loss: 0.6076\n",
            "Epoch 527/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5555 - val_loss: 0.6063\n",
            "Epoch 528/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5543 - val_loss: 0.6050\n",
            "Epoch 529/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5532 - val_loss: 0.6038\n",
            "Epoch 530/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5521 - val_loss: 0.6026\n",
            "Epoch 531/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5510 - val_loss: 0.6014\n",
            "Epoch 532/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5499 - val_loss: 0.6002\n",
            "Epoch 533/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5488 - val_loss: 0.5989\n",
            "Epoch 534/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5477 - val_loss: 0.5977\n",
            "Epoch 535/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5466 - val_loss: 0.5965\n",
            "Epoch 536/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5455 - val_loss: 0.5953\n",
            "Epoch 537/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5445 - val_loss: 0.5941\n",
            "Epoch 538/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5434 - val_loss: 0.5928\n",
            "Epoch 539/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5423 - val_loss: 0.5917\n",
            "Epoch 540/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5412 - val_loss: 0.5904\n",
            "Epoch 541/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5401 - val_loss: 0.5892\n",
            "Epoch 542/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5390 - val_loss: 0.5880\n",
            "Epoch 543/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5380 - val_loss: 0.5869\n",
            "Epoch 544/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5369 - val_loss: 0.5857\n",
            "Epoch 545/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5359 - val_loss: 0.5845\n",
            "Epoch 546/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5348 - val_loss: 0.5833\n",
            "Epoch 547/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5337 - val_loss: 0.5821\n",
            "Epoch 548/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5327 - val_loss: 0.5809\n",
            "Epoch 549/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5316 - val_loss: 0.5797\n",
            "Epoch 550/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5305 - val_loss: 0.5785\n",
            "Epoch 551/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5294 - val_loss: 0.5772\n",
            "Epoch 552/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5283 - val_loss: 0.5760\n",
            "Epoch 553/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5272 - val_loss: 0.5748\n",
            "Epoch 554/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5262 - val_loss: 0.5736\n",
            "Epoch 555/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5251 - val_loss: 0.5724\n",
            "Epoch 556/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5240 - val_loss: 0.5712\n",
            "Epoch 557/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5230 - val_loss: 0.5701\n",
            "Epoch 558/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5219 - val_loss: 0.5689\n",
            "Epoch 559/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5209 - val_loss: 0.5677\n",
            "Epoch 560/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5198 - val_loss: 0.5665\n",
            "Epoch 561/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5188 - val_loss: 0.5653\n",
            "Epoch 562/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5177 - val_loss: 0.5642\n",
            "Epoch 563/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5167 - val_loss: 0.5630\n",
            "Epoch 564/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5156 - val_loss: 0.5618\n",
            "Epoch 565/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5146 - val_loss: 0.5607\n",
            "Epoch 566/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5136 - val_loss: 0.5596\n",
            "Epoch 567/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5126 - val_loss: 0.5584\n",
            "Epoch 568/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5115 - val_loss: 0.5573\n",
            "Epoch 569/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5105 - val_loss: 0.5561\n",
            "Epoch 570/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5095 - val_loss: 0.5549\n",
            "Epoch 571/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5084 - val_loss: 0.5538\n",
            "Epoch 572/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5074 - val_loss: 0.5526\n",
            "Epoch 573/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5064 - val_loss: 0.5514\n",
            "Epoch 574/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5053 - val_loss: 0.5503\n",
            "Epoch 575/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5043 - val_loss: 0.5491\n",
            "Epoch 576/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5033 - val_loss: 0.5480\n",
            "Epoch 577/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5022 - val_loss: 0.5468\n",
            "Epoch 578/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5012 - val_loss: 0.5457\n",
            "Epoch 579/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.5002 - val_loss: 0.5445\n",
            "Epoch 580/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4992 - val_loss: 0.5434\n",
            "Epoch 581/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4981 - val_loss: 0.5422\n",
            "Epoch 582/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4971 - val_loss: 0.5411\n",
            "Epoch 583/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4961 - val_loss: 0.5399\n",
            "Epoch 584/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4951 - val_loss: 0.5388\n",
            "Epoch 585/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4941 - val_loss: 0.5377\n",
            "Epoch 586/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4931 - val_loss: 0.5365\n",
            "Epoch 587/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4921 - val_loss: 0.5354\n",
            "Epoch 588/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4910 - val_loss: 0.5342\n",
            "Epoch 589/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4900 - val_loss: 0.5331\n",
            "Epoch 590/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4890 - val_loss: 0.5320\n",
            "Epoch 591/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4880 - val_loss: 0.5308\n",
            "Epoch 592/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4870 - val_loss: 0.5297\n",
            "Epoch 593/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4859 - val_loss: 0.5285\n",
            "Epoch 594/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4849 - val_loss: 0.5274\n",
            "Epoch 595/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4839 - val_loss: 0.5263\n",
            "Epoch 596/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4829 - val_loss: 0.5251\n",
            "Epoch 597/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4819 - val_loss: 0.5240\n",
            "Epoch 598/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4809 - val_loss: 0.5229\n",
            "Epoch 599/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4799 - val_loss: 0.5217\n",
            "Epoch 600/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4789 - val_loss: 0.5206\n",
            "Epoch 601/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4779 - val_loss: 0.5195\n",
            "Epoch 602/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4769 - val_loss: 0.5184\n",
            "Epoch 603/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4759 - val_loss: 0.5173\n",
            "Epoch 604/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4750 - val_loss: 0.5162\n",
            "Epoch 605/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4740 - val_loss: 0.5151\n",
            "Epoch 606/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4730 - val_loss: 0.5140\n",
            "Epoch 607/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4721 - val_loss: 0.5129\n",
            "Epoch 608/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4711 - val_loss: 0.5118\n",
            "Epoch 609/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4702 - val_loss: 0.5108\n",
            "Epoch 610/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4692 - val_loss: 0.5097\n",
            "Epoch 611/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4682 - val_loss: 0.5086\n",
            "Epoch 612/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4673 - val_loss: 0.5075\n",
            "Epoch 613/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4663 - val_loss: 0.5065\n",
            "Epoch 614/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4654 - val_loss: 0.5054\n",
            "Epoch 615/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4645 - val_loss: 0.5044\n",
            "Epoch 616/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4635 - val_loss: 0.5033\n",
            "Epoch 617/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4626 - val_loss: 0.5022\n",
            "Epoch 618/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4617 - val_loss: 0.5012\n",
            "Epoch 619/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4607 - val_loss: 0.5001\n",
            "Epoch 620/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4598 - val_loss: 0.4991\n",
            "Epoch 621/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4589 - val_loss: 0.4980\n",
            "Epoch 622/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4579 - val_loss: 0.4970\n",
            "Epoch 623/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4570 - val_loss: 0.4959\n",
            "Epoch 624/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4561 - val_loss: 0.4949\n",
            "Epoch 625/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4552 - val_loss: 0.4938\n",
            "Epoch 626/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4542 - val_loss: 0.4928\n",
            "Epoch 627/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4533 - val_loss: 0.4917\n",
            "Epoch 628/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4524 - val_loss: 0.4907\n",
            "Epoch 629/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4515 - val_loss: 0.4897\n",
            "Epoch 630/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4506 - val_loss: 0.4886\n",
            "Epoch 631/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4496 - val_loss: 0.4876\n",
            "Epoch 632/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4487 - val_loss: 0.4865\n",
            "Epoch 633/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4478 - val_loss: 0.4855\n",
            "Epoch 634/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4469 - val_loss: 0.4845\n",
            "Epoch 635/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4460 - val_loss: 0.4835\n",
            "Epoch 636/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4451 - val_loss: 0.4825\n",
            "Epoch 637/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4443 - val_loss: 0.4815\n",
            "Epoch 638/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4434 - val_loss: 0.4805\n",
            "Epoch 639/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4425 - val_loss: 0.4795\n",
            "Epoch 640/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4416 - val_loss: 0.4785\n",
            "Epoch 641/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4408 - val_loss: 0.4775\n",
            "Epoch 642/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4399 - val_loss: 0.4765\n",
            "Epoch 643/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4390 - val_loss: 0.4755\n",
            "Epoch 644/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4382 - val_loss: 0.4746\n",
            "Epoch 645/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4373 - val_loss: 0.4736\n",
            "Epoch 646/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4364 - val_loss: 0.4726\n",
            "Epoch 647/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4355 - val_loss: 0.4716\n",
            "Epoch 648/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4346 - val_loss: 0.4705\n",
            "Epoch 649/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4337 - val_loss: 0.4695\n",
            "Epoch 650/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4328 - val_loss: 0.4685\n",
            "Epoch 651/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4319 - val_loss: 0.4675\n",
            "Epoch 652/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4310 - val_loss: 0.4664\n",
            "Epoch 653/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4301 - val_loss: 0.4654\n",
            "Epoch 654/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4293 - val_loss: 0.4644\n",
            "Epoch 655/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4284 - val_loss: 0.4634\n",
            "Epoch 656/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4275 - val_loss: 0.4624\n",
            "Epoch 657/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4266 - val_loss: 0.4614\n",
            "Epoch 658/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4257 - val_loss: 0.4604\n",
            "Epoch 659/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4249 - val_loss: 0.4594\n",
            "Epoch 660/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4240 - val_loss: 0.4585\n",
            "Epoch 661/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4232 - val_loss: 0.4575\n",
            "Epoch 662/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4223 - val_loss: 0.4565\n",
            "Epoch 663/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4215 - val_loss: 0.4556\n",
            "Epoch 664/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4207 - val_loss: 0.4546\n",
            "Epoch 665/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4198 - val_loss: 0.4536\n",
            "Epoch 666/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4190 - val_loss: 0.4527\n",
            "Epoch 667/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4181 - val_loss: 0.4517\n",
            "Epoch 668/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4172 - val_loss: 0.4507\n",
            "Epoch 669/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4164 - val_loss: 0.4497\n",
            "Epoch 670/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4155 - val_loss: 0.4487\n",
            "Epoch 671/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4147 - val_loss: 0.4478\n",
            "Epoch 672/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4139 - val_loss: 0.4468\n",
            "Epoch 673/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4130 - val_loss: 0.4459\n",
            "Epoch 674/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4122 - val_loss: 0.4449\n",
            "Epoch 675/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4114 - val_loss: 0.4440\n",
            "Epoch 676/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4105 - val_loss: 0.4430\n",
            "Epoch 677/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4097 - val_loss: 0.4421\n",
            "Epoch 678/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4089 - val_loss: 0.4412\n",
            "Epoch 679/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4081 - val_loss: 0.4403\n",
            "Epoch 680/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4073 - val_loss: 0.4394\n",
            "Epoch 681/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4065 - val_loss: 0.4385\n",
            "Epoch 682/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4057 - val_loss: 0.4375\n",
            "Epoch 683/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4049 - val_loss: 0.4366\n",
            "Epoch 684/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4041 - val_loss: 0.4357\n",
            "Epoch 685/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4033 - val_loss: 0.4348\n",
            "Epoch 686/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4025 - val_loss: 0.4338\n",
            "Epoch 687/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4017 - val_loss: 0.4329\n",
            "Epoch 688/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4009 - val_loss: 0.4320\n",
            "Epoch 689/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.4001 - val_loss: 0.4311\n",
            "Epoch 690/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3993 - val_loss: 0.4302\n",
            "Epoch 691/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3985 - val_loss: 0.4293\n",
            "Epoch 692/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3978 - val_loss: 0.4285\n",
            "Epoch 693/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3970 - val_loss: 0.4276\n",
            "Epoch 694/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3962 - val_loss: 0.4267\n",
            "Epoch 695/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3954 - val_loss: 0.4258\n",
            "Epoch 696/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3946 - val_loss: 0.4249\n",
            "Epoch 697/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3939 - val_loss: 0.4240\n",
            "Epoch 698/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3931 - val_loss: 0.4231\n",
            "Epoch 699/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3923 - val_loss: 0.4222\n",
            "Epoch 700/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3915 - val_loss: 0.4213\n",
            "Epoch 701/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3908 - val_loss: 0.4204\n",
            "Epoch 702/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3900 - val_loss: 0.4196\n",
            "Epoch 703/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3892 - val_loss: 0.4187\n",
            "Epoch 704/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3885 - val_loss: 0.4179\n",
            "Epoch 705/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3877 - val_loss: 0.4170\n",
            "Epoch 706/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3870 - val_loss: 0.4162\n",
            "Epoch 707/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3863 - val_loss: 0.4153\n",
            "Epoch 708/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3855 - val_loss: 0.4145\n",
            "Epoch 709/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3848 - val_loss: 0.4136\n",
            "Epoch 710/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3841 - val_loss: 0.4128\n",
            "Epoch 711/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3833 - val_loss: 0.4119\n",
            "Epoch 712/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.4111\n",
            "Epoch 713/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3819 - val_loss: 0.4103\n",
            "Epoch 714/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3812 - val_loss: 0.4095\n",
            "Epoch 715/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3805 - val_loss: 0.4086\n",
            "Epoch 716/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3797 - val_loss: 0.4078\n",
            "Epoch 717/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3790 - val_loss: 0.4070\n",
            "Epoch 718/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3783 - val_loss: 0.4062\n",
            "Epoch 719/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3776 - val_loss: 0.4054\n",
            "Epoch 720/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3769 - val_loss: 0.4045\n",
            "Epoch 721/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3762 - val_loss: 0.4037\n",
            "Epoch 722/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3755 - val_loss: 0.4029\n",
            "Epoch 723/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3748 - val_loss: 0.4021\n",
            "Epoch 724/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3741 - val_loss: 0.4013\n",
            "Epoch 725/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3734 - val_loss: 0.4005\n",
            "Epoch 726/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3726 - val_loss: 0.3996\n",
            "Epoch 727/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3719 - val_loss: 0.3988\n",
            "Epoch 728/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3712 - val_loss: 0.3980\n",
            "Epoch 729/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3706 - val_loss: 0.3972\n",
            "Epoch 730/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3699 - val_loss: 0.3965\n",
            "Epoch 731/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3692 - val_loss: 0.3957\n",
            "Epoch 732/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3685 - val_loss: 0.3949\n",
            "Epoch 733/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3678 - val_loss: 0.3941\n",
            "Epoch 734/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3671 - val_loss: 0.3933\n",
            "Epoch 735/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3665 - val_loss: 0.3926\n",
            "Epoch 736/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3658 - val_loss: 0.3918\n",
            "Epoch 737/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3651 - val_loss: 0.3910\n",
            "Epoch 738/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3645 - val_loss: 0.3902\n",
            "Epoch 739/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3638 - val_loss: 0.3895\n",
            "Epoch 740/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3631 - val_loss: 0.3887\n",
            "Epoch 741/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3625 - val_loss: 0.3880\n",
            "Epoch 742/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3618 - val_loss: 0.3872\n",
            "Epoch 743/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3612 - val_loss: 0.3865\n",
            "Epoch 744/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3605 - val_loss: 0.3857\n",
            "Epoch 745/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3599 - val_loss: 0.3850\n",
            "Epoch 746/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3592 - val_loss: 0.3842\n",
            "Epoch 747/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3586 - val_loss: 0.3835\n",
            "Epoch 748/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3579 - val_loss: 0.3827\n",
            "Epoch 749/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3573 - val_loss: 0.3820\n",
            "Epoch 750/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3566 - val_loss: 0.3813\n",
            "Epoch 751/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3560 - val_loss: 0.3805\n",
            "Epoch 752/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3554 - val_loss: 0.3798\n",
            "Epoch 753/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3547 - val_loss: 0.3791\n",
            "Epoch 754/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3541 - val_loss: 0.3784\n",
            "Epoch 755/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3535 - val_loss: 0.3777\n",
            "Epoch 756/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3528 - val_loss: 0.3769\n",
            "Epoch 757/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3522 - val_loss: 0.3762\n",
            "Epoch 758/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3516 - val_loss: 0.3755\n",
            "Epoch 759/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3510 - val_loss: 0.3748\n",
            "Epoch 760/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3503 - val_loss: 0.3741\n",
            "Epoch 761/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3497 - val_loss: 0.3734\n",
            "Epoch 762/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3491 - val_loss: 0.3726\n",
            "Epoch 763/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3485 - val_loss: 0.3719\n",
            "Epoch 764/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3479 - val_loss: 0.3712\n",
            "Epoch 765/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3473 - val_loss: 0.3705\n",
            "Epoch 766/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3467 - val_loss: 0.3699\n",
            "Epoch 767/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3461 - val_loss: 0.3692\n",
            "Epoch 768/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3456 - val_loss: 0.3686\n",
            "Epoch 769/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3450 - val_loss: 0.3679\n",
            "Epoch 770/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3444 - val_loss: 0.3672\n",
            "Epoch 771/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3438 - val_loss: 0.3665\n",
            "Epoch 772/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3432 - val_loss: 0.3659\n",
            "Epoch 773/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3427 - val_loss: 0.3652\n",
            "Epoch 774/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3421 - val_loss: 0.3646\n",
            "Epoch 775/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3415 - val_loss: 0.3639\n",
            "Epoch 776/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3410 - val_loss: 0.3632\n",
            "Epoch 777/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3404 - val_loss: 0.3626\n",
            "Epoch 778/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3398 - val_loss: 0.3619\n",
            "Epoch 779/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3392 - val_loss: 0.3612\n",
            "Epoch 780/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3386 - val_loss: 0.3606\n",
            "Epoch 781/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3381 - val_loss: 0.3599\n",
            "Epoch 782/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3375 - val_loss: 0.3593\n",
            "Epoch 783/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3370 - val_loss: 0.3586\n",
            "Epoch 784/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3364 - val_loss: 0.3580\n",
            "Epoch 785/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3358 - val_loss: 0.3573\n",
            "Epoch 786/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3353 - val_loss: 0.3567\n",
            "Epoch 787/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3347 - val_loss: 0.3560\n",
            "Epoch 788/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3342 - val_loss: 0.3553\n",
            "Epoch 789/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3336 - val_loss: 0.3547\n",
            "Epoch 790/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3330 - val_loss: 0.3540\n",
            "Epoch 791/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3325 - val_loss: 0.3534\n",
            "Epoch 792/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3319 - val_loss: 0.3528\n",
            "Epoch 793/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3314 - val_loss: 0.3522\n",
            "Epoch 794/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3309 - val_loss: 0.3515\n",
            "Epoch 795/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3303 - val_loss: 0.3509\n",
            "Epoch 796/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3298 - val_loss: 0.3503\n",
            "Epoch 797/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3293 - val_loss: 0.3497\n",
            "Epoch 798/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3288 - val_loss: 0.3491\n",
            "Epoch 799/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3283 - val_loss: 0.3485\n",
            "Epoch 800/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3277 - val_loss: 0.3479\n",
            "Epoch 801/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3272 - val_loss: 0.3473\n",
            "Epoch 802/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3267 - val_loss: 0.3467\n",
            "Epoch 803/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3262 - val_loss: 0.3461\n",
            "Epoch 804/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3256 - val_loss: 0.3455\n",
            "Epoch 805/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3251 - val_loss: 0.3448\n",
            "Epoch 806/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3246 - val_loss: 0.3442\n",
            "Epoch 807/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3241 - val_loss: 0.3436\n",
            "Epoch 808/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3235 - val_loss: 0.3430\n",
            "Epoch 809/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3230 - val_loss: 0.3424\n",
            "Epoch 810/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3225 - val_loss: 0.3418\n",
            "Epoch 811/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3220 - val_loss: 0.3412\n",
            "Epoch 812/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3215 - val_loss: 0.3406\n",
            "Epoch 813/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3210 - val_loss: 0.3400\n",
            "Epoch 814/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3205 - val_loss: 0.3395\n",
            "Epoch 815/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3200 - val_loss: 0.3389\n",
            "Epoch 816/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3195 - val_loss: 0.3384\n",
            "Epoch 817/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3190 - val_loss: 0.3378\n",
            "Epoch 818/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3186 - val_loss: 0.3372\n",
            "Epoch 819/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3181 - val_loss: 0.3366\n",
            "Epoch 820/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3176 - val_loss: 0.3361\n",
            "Epoch 821/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3171 - val_loss: 0.3355\n",
            "Epoch 822/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3166 - val_loss: 0.3350\n",
            "Epoch 823/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3161 - val_loss: 0.3344\n",
            "Epoch 824/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3156 - val_loss: 0.3338\n",
            "Epoch 825/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3151 - val_loss: 0.3332\n",
            "Epoch 826/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3146 - val_loss: 0.3327\n",
            "Epoch 827/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3142 - val_loss: 0.3321\n",
            "Epoch 828/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3137 - val_loss: 0.3316\n",
            "Epoch 829/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3132 - val_loss: 0.3310\n",
            "Epoch 830/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3127 - val_loss: 0.3305\n",
            "Epoch 831/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3123 - val_loss: 0.3300\n",
            "Epoch 832/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3118 - val_loss: 0.3294\n",
            "Epoch 833/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3114 - val_loss: 0.3289\n",
            "Epoch 834/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3109 - val_loss: 0.3284\n",
            "Epoch 835/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3104 - val_loss: 0.3278\n",
            "Epoch 836/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3100 - val_loss: 0.3273\n",
            "Epoch 837/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3095 - val_loss: 0.3267\n",
            "Epoch 838/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3090 - val_loss: 0.3262\n",
            "Epoch 839/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3086 - val_loss: 0.3256\n",
            "Epoch 840/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3081 - val_loss: 0.3251\n",
            "Epoch 841/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3077 - val_loss: 0.3246\n",
            "Epoch 842/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3072 - val_loss: 0.3241\n",
            "Epoch 843/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3068 - val_loss: 0.3236\n",
            "Epoch 844/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3063 - val_loss: 0.3230\n",
            "Epoch 845/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3059 - val_loss: 0.3225\n",
            "Epoch 846/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3054 - val_loss: 0.3220\n",
            "Epoch 847/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3050 - val_loss: 0.3215\n",
            "Epoch 848/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3046 - val_loss: 0.3210\n",
            "Epoch 849/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3041 - val_loss: 0.3205\n",
            "Epoch 850/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3037 - val_loss: 0.3200\n",
            "Epoch 851/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3033 - val_loss: 0.3196\n",
            "Epoch 852/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3029 - val_loss: 0.3191\n",
            "Epoch 853/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3025 - val_loss: 0.3186\n",
            "Epoch 854/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3020 - val_loss: 0.3181\n",
            "Epoch 855/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3016 - val_loss: 0.3176\n",
            "Epoch 856/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3012 - val_loss: 0.3171\n",
            "Epoch 857/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3008 - val_loss: 0.3167\n",
            "Epoch 858/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.3004 - val_loss: 0.3162\n",
            "Epoch 859/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2999 - val_loss: 0.3157\n",
            "Epoch 860/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2995 - val_loss: 0.3152\n",
            "Epoch 861/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2991 - val_loss: 0.3147\n",
            "Epoch 862/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2987 - val_loss: 0.3143\n",
            "Epoch 863/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2983 - val_loss: 0.3138\n",
            "Epoch 864/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2979 - val_loss: 0.3133\n",
            "Epoch 865/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2975 - val_loss: 0.3128\n",
            "Epoch 866/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2971 - val_loss: 0.3124\n",
            "Epoch 867/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2967 - val_loss: 0.3119\n",
            "Epoch 868/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2963 - val_loss: 0.3115\n",
            "Epoch 869/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2959 - val_loss: 0.3110\n",
            "Epoch 870/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2955 - val_loss: 0.3106\n",
            "Epoch 871/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2951 - val_loss: 0.3101\n",
            "Epoch 872/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2947 - val_loss: 0.3097\n",
            "Epoch 873/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2944 - val_loss: 0.3092\n",
            "Epoch 874/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2940 - val_loss: 0.3087\n",
            "Epoch 875/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2936 - val_loss: 0.3083\n",
            "Epoch 876/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2932 - val_loss: 0.3079\n",
            "Epoch 877/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2928 - val_loss: 0.3074\n",
            "Epoch 878/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2924 - val_loss: 0.3070\n",
            "Epoch 879/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2920 - val_loss: 0.3065\n",
            "Epoch 880/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2916 - val_loss: 0.3061\n",
            "Epoch 881/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2913 - val_loss: 0.3056\n",
            "Epoch 882/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2909 - val_loss: 0.3052\n",
            "Epoch 883/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2905 - val_loss: 0.3047\n",
            "Epoch 884/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2901 - val_loss: 0.3043\n",
            "Epoch 885/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2898 - val_loss: 0.3039\n",
            "Epoch 886/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2894 - val_loss: 0.3034\n",
            "Epoch 887/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2890 - val_loss: 0.3030\n",
            "Epoch 888/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2886 - val_loss: 0.3026\n",
            "Epoch 889/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2883 - val_loss: 0.3022\n",
            "Epoch 890/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2879 - val_loss: 0.3018\n",
            "Epoch 891/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2876 - val_loss: 0.3013\n",
            "Epoch 892/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2872 - val_loss: 0.3009\n",
            "Epoch 893/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2868 - val_loss: 0.3005\n",
            "Epoch 894/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2865 - val_loss: 0.3001\n",
            "Epoch 895/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2861 - val_loss: 0.2997\n",
            "Epoch 896/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2858 - val_loss: 0.2993\n",
            "Epoch 897/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2854 - val_loss: 0.2989\n",
            "Epoch 898/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2851 - val_loss: 0.2985\n",
            "Epoch 899/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2847 - val_loss: 0.2981\n",
            "Epoch 900/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2844 - val_loss: 0.2976\n",
            "Epoch 901/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2840 - val_loss: 0.2972\n",
            "Epoch 902/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2836 - val_loss: 0.2968\n",
            "Epoch 903/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2833 - val_loss: 0.2964\n",
            "Epoch 904/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2829 - val_loss: 0.2960\n",
            "Epoch 905/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2826 - val_loss: 0.2956\n",
            "Epoch 906/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2822 - val_loss: 0.2952\n",
            "Epoch 907/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2819 - val_loss: 0.2948\n",
            "Epoch 908/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2816 - val_loss: 0.2944\n",
            "Epoch 909/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2813 - val_loss: 0.2941\n",
            "Epoch 910/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2809 - val_loss: 0.2937\n",
            "Epoch 911/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2806 - val_loss: 0.2933\n",
            "Epoch 912/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2803 - val_loss: 0.2929\n",
            "Epoch 913/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2799 - val_loss: 0.2925\n",
            "Epoch 914/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2796 - val_loss: 0.2922\n",
            "Epoch 915/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2793 - val_loss: 0.2918\n",
            "Epoch 916/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2790 - val_loss: 0.2914\n",
            "Epoch 917/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2786 - val_loss: 0.2910\n",
            "Epoch 918/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2783 - val_loss: 0.2907\n",
            "Epoch 919/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2780 - val_loss: 0.2903\n",
            "Epoch 920/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2777 - val_loss: 0.2899\n",
            "Epoch 921/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2773 - val_loss: 0.2896\n",
            "Epoch 922/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2770 - val_loss: 0.2892\n",
            "Epoch 923/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2767 - val_loss: 0.2888\n",
            "Epoch 924/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2764 - val_loss: 0.2885\n",
            "Epoch 925/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2761 - val_loss: 0.2881\n",
            "Epoch 926/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2757 - val_loss: 0.2877\n",
            "Epoch 927/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2754 - val_loss: 0.2874\n",
            "Epoch 928/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2751 - val_loss: 0.2870\n",
            "Epoch 929/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2748 - val_loss: 0.2867\n",
            "Epoch 930/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2745 - val_loss: 0.2863\n",
            "Epoch 931/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2742 - val_loss: 0.2860\n",
            "Epoch 932/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2739 - val_loss: 0.2856\n",
            "Epoch 933/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2736 - val_loss: 0.2853\n",
            "Epoch 934/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2733 - val_loss: 0.2849\n",
            "Epoch 935/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2730 - val_loss: 0.2846\n",
            "Epoch 936/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2727 - val_loss: 0.2842\n",
            "Epoch 937/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2724 - val_loss: 0.2839\n",
            "Epoch 938/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2721 - val_loss: 0.2835\n",
            "Epoch 939/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2718 - val_loss: 0.2832\n",
            "Epoch 940/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2715 - val_loss: 0.2829\n",
            "Epoch 941/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2712 - val_loss: 0.2825\n",
            "Epoch 942/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2709 - val_loss: 0.2822\n",
            "Epoch 943/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2706 - val_loss: 0.2819\n",
            "Epoch 944/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2703 - val_loss: 0.2815\n",
            "Epoch 945/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2701 - val_loss: 0.2812\n",
            "Epoch 946/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2698 - val_loss: 0.2809\n",
            "Epoch 947/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2695 - val_loss: 0.2805\n",
            "Epoch 948/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2692 - val_loss: 0.2802\n",
            "Epoch 949/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2689 - val_loss: 0.2799\n",
            "Epoch 950/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2686 - val_loss: 0.2796\n",
            "Epoch 951/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2683 - val_loss: 0.2792\n",
            "Epoch 952/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2681 - val_loss: 0.2789\n",
            "Epoch 953/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2678 - val_loss: 0.2786\n",
            "Epoch 954/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2675 - val_loss: 0.2783\n",
            "Epoch 955/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2672 - val_loss: 0.2779\n",
            "Epoch 956/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2669 - val_loss: 0.2776\n",
            "Epoch 957/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2667 - val_loss: 0.2773\n",
            "Epoch 958/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2664 - val_loss: 0.2770\n",
            "Epoch 959/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2661 - val_loss: 0.2767\n",
            "Epoch 960/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2658 - val_loss: 0.2763\n",
            "Epoch 961/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2655 - val_loss: 0.2760\n",
            "Epoch 962/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2653 - val_loss: 0.2757\n",
            "Epoch 963/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2650 - val_loss: 0.2754\n",
            "Epoch 964/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2647 - val_loss: 0.2751\n",
            "Epoch 965/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2645 - val_loss: 0.2747\n",
            "Epoch 966/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2642 - val_loss: 0.2744\n",
            "Epoch 967/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2639 - val_loss: 0.2741\n",
            "Epoch 968/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2636 - val_loss: 0.2738\n",
            "Epoch 969/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2634 - val_loss: 0.2735\n",
            "Epoch 970/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2631 - val_loss: 0.2732\n",
            "Epoch 971/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2628 - val_loss: 0.2729\n",
            "Epoch 972/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2625 - val_loss: 0.2726\n",
            "Epoch 973/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2623 - val_loss: 0.2722\n",
            "Epoch 974/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2620 - val_loss: 0.2719\n",
            "Epoch 975/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2618 - val_loss: 0.2717\n",
            "Epoch 976/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2615 - val_loss: 0.2714\n",
            "Epoch 977/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2612 - val_loss: 0.2711\n",
            "Epoch 978/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2610 - val_loss: 0.2708\n",
            "Epoch 979/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2607 - val_loss: 0.2705\n",
            "Epoch 980/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2605 - val_loss: 0.2702\n",
            "Epoch 981/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2602 - val_loss: 0.2699\n",
            "Epoch 982/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2600 - val_loss: 0.2696\n",
            "Epoch 983/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2597 - val_loss: 0.2694\n",
            "Epoch 984/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2595 - val_loss: 0.2691\n",
            "Epoch 985/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2593 - val_loss: 0.2688\n",
            "Epoch 986/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2590 - val_loss: 0.2685\n",
            "Epoch 987/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2588 - val_loss: 0.2683\n",
            "Epoch 988/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2585 - val_loss: 0.2680\n",
            "Epoch 989/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2583 - val_loss: 0.2677\n",
            "Epoch 990/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2581 - val_loss: 0.2674\n",
            "Epoch 991/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2578 - val_loss: 0.2672\n",
            "Epoch 992/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2576 - val_loss: 0.2669\n",
            "Epoch 993/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2574 - val_loss: 0.2666\n",
            "Epoch 994/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2571 - val_loss: 0.2664\n",
            "Epoch 995/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2569 - val_loss: 0.2661\n",
            "Epoch 996/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2566 - val_loss: 0.2658\n",
            "Epoch 997/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2564 - val_loss: 0.2656\n",
            "Epoch 998/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2562 - val_loss: 0.2653\n",
            "Epoch 999/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2559 - val_loss: 0.2650\n",
            "Epoch 1000/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2557 - val_loss: 0.2647\n",
            "Epoch 1001/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2555 - val_loss: 0.2645\n",
            "Epoch 1002/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.2552 - val_loss: 0.2642\n",
            "Epoch 1003/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2550 - val_loss: 0.2640\n",
            "Epoch 1004/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2548 - val_loss: 0.2637\n",
            "Epoch 1005/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2545 - val_loss: 0.2634\n",
            "Epoch 1006/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2543 - val_loss: 0.2632\n",
            "Epoch 1007/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2541 - val_loss: 0.2629\n",
            "Epoch 1008/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2539 - val_loss: 0.2626\n",
            "Epoch 1009/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2536 - val_loss: 0.2624\n",
            "Epoch 1010/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2534 - val_loss: 0.2621\n",
            "Epoch 1011/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2532 - val_loss: 0.2619\n",
            "Epoch 1012/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2530 - val_loss: 0.2616\n",
            "Epoch 1013/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2527 - val_loss: 0.2613\n",
            "Epoch 1014/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2525 - val_loss: 0.2611\n",
            "Epoch 1015/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2523 - val_loss: 0.2608\n",
            "Epoch 1016/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2521 - val_loss: 0.2606\n",
            "Epoch 1017/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2519 - val_loss: 0.2603\n",
            "Epoch 1018/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2516 - val_loss: 0.2601\n",
            "Epoch 1019/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2514 - val_loss: 0.2598\n",
            "Epoch 1020/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2512 - val_loss: 0.2596\n",
            "Epoch 1021/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2510 - val_loss: 0.2593\n",
            "Epoch 1022/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2508 - val_loss: 0.2591\n",
            "Epoch 1023/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2506 - val_loss: 0.2588\n",
            "Epoch 1024/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2504 - val_loss: 0.2586\n",
            "Epoch 1025/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2502 - val_loss: 0.2584\n",
            "Epoch 1026/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2499 - val_loss: 0.2581\n",
            "Epoch 1027/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2497 - val_loss: 0.2579\n",
            "Epoch 1028/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2495 - val_loss: 0.2577\n",
            "Epoch 1029/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2493 - val_loss: 0.2574\n",
            "Epoch 1030/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2491 - val_loss: 0.2572\n",
            "Epoch 1031/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2489 - val_loss: 0.2569\n",
            "Epoch 1032/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2487 - val_loss: 0.2567\n",
            "Epoch 1033/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2485 - val_loss: 0.2565\n",
            "Epoch 1034/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2483 - val_loss: 0.2562\n",
            "Epoch 1035/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2481 - val_loss: 0.2560\n",
            "Epoch 1036/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2479 - val_loss: 0.2558\n",
            "Epoch 1037/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2477 - val_loss: 0.2555\n",
            "Epoch 1038/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2475 - val_loss: 0.2553\n",
            "Epoch 1039/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2473 - val_loss: 0.2551\n",
            "Epoch 1040/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2471 - val_loss: 0.2548\n",
            "Epoch 1041/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2469 - val_loss: 0.2546\n",
            "Epoch 1042/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2467 - val_loss: 0.2544\n",
            "Epoch 1043/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2465 - val_loss: 0.2541\n",
            "Epoch 1044/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2463 - val_loss: 0.2539\n",
            "Epoch 1045/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2461 - val_loss: 0.2537\n",
            "Epoch 1046/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2459 - val_loss: 0.2535\n",
            "Epoch 1047/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2457 - val_loss: 0.2532\n",
            "Epoch 1048/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2455 - val_loss: 0.2530\n",
            "Epoch 1049/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2453 - val_loss: 0.2528\n",
            "Epoch 1050/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2451 - val_loss: 0.2526\n",
            "Epoch 1051/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2449 - val_loss: 0.2523\n",
            "Epoch 1052/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2448 - val_loss: 0.2521\n",
            "Epoch 1053/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2446 - val_loss: 0.2519\n",
            "Epoch 1054/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2444 - val_loss: 0.2517\n",
            "Epoch 1055/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2442 - val_loss: 0.2515\n",
            "Epoch 1056/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2440 - val_loss: 0.2513\n",
            "Epoch 1057/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2438 - val_loss: 0.2511\n",
            "Epoch 1058/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2437 - val_loss: 0.2508\n",
            "Epoch 1059/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2435 - val_loss: 0.2506\n",
            "Epoch 1060/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2433 - val_loss: 0.2504\n",
            "Epoch 1061/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2431 - val_loss: 0.2502\n",
            "Epoch 1062/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2429 - val_loss: 0.2500\n",
            "Epoch 1063/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2428 - val_loss: 0.2498\n",
            "Epoch 1064/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2426 - val_loss: 0.2496\n",
            "Epoch 1065/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2424 - val_loss: 0.2494\n",
            "Epoch 1066/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2422 - val_loss: 0.2492\n",
            "Epoch 1067/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2420 - val_loss: 0.2490\n",
            "Epoch 1068/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2419 - val_loss: 0.2488\n",
            "Epoch 1069/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2417 - val_loss: 0.2485\n",
            "Epoch 1070/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2415 - val_loss: 0.2483\n",
            "Epoch 1071/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2413 - val_loss: 0.2481\n",
            "Epoch 1072/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2412 - val_loss: 0.2479\n",
            "Epoch 1073/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2410 - val_loss: 0.2477\n",
            "Epoch 1074/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2408 - val_loss: 0.2475\n",
            "Epoch 1075/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2406 - val_loss: 0.2473\n",
            "Epoch 1076/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2405 - val_loss: 0.2471\n",
            "Epoch 1077/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2403 - val_loss: 0.2469\n",
            "Epoch 1078/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2401 - val_loss: 0.2467\n",
            "Epoch 1079/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2400 - val_loss: 0.2465\n",
            "Epoch 1080/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2398 - val_loss: 0.2463\n",
            "Epoch 1081/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2396 - val_loss: 0.2461\n",
            "Epoch 1082/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2394 - val_loss: 0.2459\n",
            "Epoch 1083/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2393 - val_loss: 0.2457\n",
            "Epoch 1084/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2391 - val_loss: 0.2455\n",
            "Epoch 1085/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2390 - val_loss: 0.2453\n",
            "Epoch 1086/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2388 - val_loss: 0.2451\n",
            "Epoch 1087/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2386 - val_loss: 0.2449\n",
            "Epoch 1088/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2385 - val_loss: 0.2447\n",
            "Epoch 1089/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2383 - val_loss: 0.2446\n",
            "Epoch 1090/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2381 - val_loss: 0.2444\n",
            "Epoch 1091/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2380 - val_loss: 0.2442\n",
            "Epoch 1092/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2378 - val_loss: 0.2440\n",
            "Epoch 1093/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2377 - val_loss: 0.2438\n",
            "Epoch 1094/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2375 - val_loss: 0.2436\n",
            "Epoch 1095/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2373 - val_loss: 0.2434\n",
            "Epoch 1096/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2372 - val_loss: 0.2433\n",
            "Epoch 1097/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2370 - val_loss: 0.2431\n",
            "Epoch 1098/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2369 - val_loss: 0.2429\n",
            "Epoch 1099/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2367 - val_loss: 0.2427\n",
            "Epoch 1100/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2366 - val_loss: 0.2425\n",
            "Epoch 1101/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2364 - val_loss: 0.2423\n",
            "Epoch 1102/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2363 - val_loss: 0.2422\n",
            "Epoch 1103/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2361 - val_loss: 0.2420\n",
            "Epoch 1104/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2360 - val_loss: 0.2418\n",
            "Epoch 1105/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2358 - val_loss: 0.2416\n",
            "Epoch 1106/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2357 - val_loss: 0.2415\n",
            "Epoch 1107/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2355 - val_loss: 0.2413\n",
            "Epoch 1108/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2354 - val_loss: 0.2411\n",
            "Epoch 1109/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2352 - val_loss: 0.2409\n",
            "Epoch 1110/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2351 - val_loss: 0.2408\n",
            "Epoch 1111/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2349 - val_loss: 0.2406\n",
            "Epoch 1112/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2348 - val_loss: 0.2404\n",
            "Epoch 1113/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2346 - val_loss: 0.2402\n",
            "Epoch 1114/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2345 - val_loss: 0.2401\n",
            "Epoch 1115/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2343 - val_loss: 0.2399\n",
            "Epoch 1116/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2342 - val_loss: 0.2397\n",
            "Epoch 1117/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2341 - val_loss: 0.2395\n",
            "Epoch 1118/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2339 - val_loss: 0.2394\n",
            "Epoch 1119/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2338 - val_loss: 0.2392\n",
            "Epoch 1120/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2336 - val_loss: 0.2390\n",
            "Epoch 1121/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2335 - val_loss: 0.2389\n",
            "Epoch 1122/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2333 - val_loss: 0.2387\n",
            "Epoch 1123/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2332 - val_loss: 0.2385\n",
            "Epoch 1124/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2331 - val_loss: 0.2384\n",
            "Epoch 1125/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2329 - val_loss: 0.2382\n",
            "Epoch 1126/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2328 - val_loss: 0.2380\n",
            "Epoch 1127/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2326 - val_loss: 0.2379\n",
            "Epoch 1128/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2325 - val_loss: 0.2377\n",
            "Epoch 1129/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2324 - val_loss: 0.2375\n",
            "Epoch 1130/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2322 - val_loss: 0.2374\n",
            "Epoch 1131/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2321 - val_loss: 0.2372\n",
            "Epoch 1132/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2320 - val_loss: 0.2370\n",
            "Epoch 1133/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2318 - val_loss: 0.2369\n",
            "Epoch 1134/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2317 - val_loss: 0.2367\n",
            "Epoch 1135/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2316 - val_loss: 0.2366\n",
            "Epoch 1136/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2314 - val_loss: 0.2364\n",
            "Epoch 1137/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2313 - val_loss: 0.2362\n",
            "Epoch 1138/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2312 - val_loss: 0.2361\n",
            "Epoch 1139/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2310 - val_loss: 0.2359\n",
            "Epoch 1140/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2309 - val_loss: 0.2358\n",
            "Epoch 1141/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2308 - val_loss: 0.2356\n",
            "Epoch 1142/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2306 - val_loss: 0.2355\n",
            "Epoch 1143/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2305 - val_loss: 0.2353\n",
            "Epoch 1144/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2304 - val_loss: 0.2351\n",
            "Epoch 1145/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2302 - val_loss: 0.2350\n",
            "Epoch 1146/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2301 - val_loss: 0.2348\n",
            "Epoch 1147/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2300 - val_loss: 0.2347\n",
            "Epoch 1148/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2299 - val_loss: 0.2345\n",
            "Epoch 1149/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2297 - val_loss: 0.2344\n",
            "Epoch 1150/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2296 - val_loss: 0.2342\n",
            "Epoch 1151/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2295 - val_loss: 0.2341\n",
            "Epoch 1152/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2293 - val_loss: 0.2339\n",
            "Epoch 1153/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2292 - val_loss: 0.2338\n",
            "Epoch 1154/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2291 - val_loss: 0.2336\n",
            "Epoch 1155/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2289 - val_loss: 0.2335\n",
            "Epoch 1156/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2288 - val_loss: 0.2333\n",
            "Epoch 1157/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2287 - val_loss: 0.2331\n",
            "Epoch 1158/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2286 - val_loss: 0.2330\n",
            "Epoch 1159/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2284 - val_loss: 0.2328\n",
            "Epoch 1160/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2283 - val_loss: 0.2327\n",
            "Epoch 1161/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2282 - val_loss: 0.2326\n",
            "Epoch 1162/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2281 - val_loss: 0.2324\n",
            "Epoch 1163/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2279 - val_loss: 0.2323\n",
            "Epoch 1164/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2278 - val_loss: 0.2321\n",
            "Epoch 1165/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2277 - val_loss: 0.2320\n",
            "Epoch 1166/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2276 - val_loss: 0.2318\n",
            "Epoch 1167/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2274 - val_loss: 0.2317\n",
            "Epoch 1168/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2273 - val_loss: 0.2315\n",
            "Epoch 1169/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2272 - val_loss: 0.2314\n",
            "Epoch 1170/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2271 - val_loss: 0.2312\n",
            "Epoch 1171/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2270 - val_loss: 0.2311\n",
            "Epoch 1172/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2268 - val_loss: 0.2310\n",
            "Epoch 1173/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2267 - val_loss: 0.2308\n",
            "Epoch 1174/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2266 - val_loss: 0.2307\n",
            "Epoch 1175/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2265 - val_loss: 0.2305\n",
            "Epoch 1176/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2264 - val_loss: 0.2304\n",
            "Epoch 1177/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2262 - val_loss: 0.2303\n",
            "Epoch 1178/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2261 - val_loss: 0.2301\n",
            "Epoch 1179/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2260 - val_loss: 0.2300\n",
            "Epoch 1180/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2259 - val_loss: 0.2298\n",
            "Epoch 1181/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2258 - val_loss: 0.2297\n",
            "Epoch 1182/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2257 - val_loss: 0.2296\n",
            "Epoch 1183/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2256 - val_loss: 0.2294\n",
            "Epoch 1184/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2254 - val_loss: 0.2293\n",
            "Epoch 1185/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2253 - val_loss: 0.2292\n",
            "Epoch 1186/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2252 - val_loss: 0.2290\n",
            "Epoch 1187/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2251 - val_loss: 0.2289\n",
            "Epoch 1188/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2250 - val_loss: 0.2288\n",
            "Epoch 1189/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2249 - val_loss: 0.2286\n",
            "Epoch 1190/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2248 - val_loss: 0.2285\n",
            "Epoch 1191/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2247 - val_loss: 0.2284\n",
            "Epoch 1192/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2245 - val_loss: 0.2282\n",
            "Epoch 1193/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2244 - val_loss: 0.2281\n",
            "Epoch 1194/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2243 - val_loss: 0.2280\n",
            "Epoch 1195/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2242 - val_loss: 0.2278\n",
            "Epoch 1196/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2241 - val_loss: 0.2277\n",
            "Epoch 1197/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2240 - val_loss: 0.2276\n",
            "Epoch 1198/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2239 - val_loss: 0.2275\n",
            "Epoch 1199/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2238 - val_loss: 0.2273\n",
            "Epoch 1200/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2237 - val_loss: 0.2272\n",
            "Epoch 1201/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2236 - val_loss: 0.2271\n",
            "Epoch 1202/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2235 - val_loss: 0.2270\n",
            "Epoch 1203/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2234 - val_loss: 0.2268\n",
            "Epoch 1204/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2233 - val_loss: 0.2267\n",
            "Epoch 1205/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2231 - val_loss: 0.2266\n",
            "Epoch 1206/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2230 - val_loss: 0.2265\n",
            "Epoch 1207/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2229 - val_loss: 0.2263\n",
            "Epoch 1208/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2228 - val_loss: 0.2262\n",
            "Epoch 1209/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2227 - val_loss: 0.2261\n",
            "Epoch 1210/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2226 - val_loss: 0.2260\n",
            "Epoch 1211/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2225 - val_loss: 0.2258\n",
            "Epoch 1212/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2224 - val_loss: 0.2257\n",
            "Epoch 1213/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2223 - val_loss: 0.2256\n",
            "Epoch 1214/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2222 - val_loss: 0.2255\n",
            "Epoch 1215/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2221 - val_loss: 0.2254\n",
            "Epoch 1216/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2220 - val_loss: 0.2252\n",
            "Epoch 1217/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2219 - val_loss: 0.2251\n",
            "Epoch 1218/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2218 - val_loss: 0.2250\n",
            "Epoch 1219/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2217 - val_loss: 0.2249\n",
            "Epoch 1220/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2216 - val_loss: 0.2248\n",
            "Epoch 1221/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2215 - val_loss: 0.2246\n",
            "Epoch 1222/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2214 - val_loss: 0.2245\n",
            "Epoch 1223/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2213 - val_loss: 0.2244\n",
            "Epoch 1224/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2212 - val_loss: 0.2243\n",
            "Epoch 1225/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2211 - val_loss: 0.2242\n",
            "Epoch 1226/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2210 - val_loss: 0.2240\n",
            "Epoch 1227/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2209 - val_loss: 0.2239\n",
            "Epoch 1228/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2208 - val_loss: 0.2238\n",
            "Epoch 1229/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2207 - val_loss: 0.2237\n",
            "Epoch 1230/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2206 - val_loss: 0.2236\n",
            "Epoch 1231/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2205 - val_loss: 0.2234\n",
            "Epoch 1232/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2204 - val_loss: 0.2233\n",
            "Epoch 1233/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2203 - val_loss: 0.2232\n",
            "Epoch 1234/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2202 - val_loss: 0.2231\n",
            "Epoch 1235/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2201 - val_loss: 0.2230\n",
            "Epoch 1236/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2200 - val_loss: 0.2229\n",
            "Epoch 1237/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2199 - val_loss: 0.2228\n",
            "Epoch 1238/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2198 - val_loss: 0.2226\n",
            "Epoch 1239/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2197 - val_loss: 0.2225\n",
            "Epoch 1240/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2196 - val_loss: 0.2224\n",
            "Epoch 1241/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2195 - val_loss: 0.2223\n",
            "Epoch 1242/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2194 - val_loss: 0.2222\n",
            "Epoch 1243/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2193 - val_loss: 0.2221\n",
            "Epoch 1244/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2192 - val_loss: 0.2220\n",
            "Epoch 1245/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2192 - val_loss: 0.2219\n",
            "Epoch 1246/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2191 - val_loss: 0.2218\n",
            "Epoch 1247/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2190 - val_loss: 0.2216\n",
            "Epoch 1248/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2189 - val_loss: 0.2215\n",
            "Epoch 1249/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2188 - val_loss: 0.2214\n",
            "Epoch 1250/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2187 - val_loss: 0.2213\n",
            "Epoch 1251/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2186 - val_loss: 0.2212\n",
            "Epoch 1252/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2185 - val_loss: 0.2211\n",
            "Epoch 1253/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2184 - val_loss: 0.2210\n",
            "Epoch 1254/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2183 - val_loss: 0.2209\n",
            "Epoch 1255/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2182 - val_loss: 0.2208\n",
            "Epoch 1256/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2182 - val_loss: 0.2207\n",
            "Epoch 1257/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2181 - val_loss: 0.2206\n",
            "Epoch 1258/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2180 - val_loss: 0.2205\n",
            "Epoch 1259/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2179 - val_loss: 0.2204\n",
            "Epoch 1260/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2178 - val_loss: 0.2203\n",
            "Epoch 1261/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2177 - val_loss: 0.2202\n",
            "Epoch 1262/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2176 - val_loss: 0.2201\n",
            "Epoch 1263/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2175 - val_loss: 0.2200\n",
            "Epoch 1264/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2175 - val_loss: 0.2199\n",
            "Epoch 1265/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2174 - val_loss: 0.2198\n",
            "Epoch 1266/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2173 - val_loss: 0.2197\n",
            "Epoch 1267/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2172 - val_loss: 0.2196\n",
            "Epoch 1268/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2171 - val_loss: 0.2195\n",
            "Epoch 1269/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2170 - val_loss: 0.2194\n",
            "Epoch 1270/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2169 - val_loss: 0.2193\n",
            "Epoch 1271/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2169 - val_loss: 0.2192\n",
            "Epoch 1272/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2168 - val_loss: 0.2191\n",
            "Epoch 1273/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2167 - val_loss: 0.2190\n",
            "Epoch 1274/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2166 - val_loss: 0.2189\n",
            "Epoch 1275/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2165 - val_loss: 0.2188\n",
            "Epoch 1276/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2164 - val_loss: 0.2187\n",
            "Epoch 1277/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2164 - val_loss: 0.2186\n",
            "Epoch 1278/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2163 - val_loss: 0.2185\n",
            "Epoch 1279/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2162 - val_loss: 0.2184\n",
            "Epoch 1280/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2161 - val_loss: 0.2183\n",
            "Epoch 1281/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2160 - val_loss: 0.2182\n",
            "Epoch 1282/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2160 - val_loss: 0.2181\n",
            "Epoch 1283/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2159 - val_loss: 0.2180\n",
            "Epoch 1284/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2158 - val_loss: 0.2179\n",
            "Epoch 1285/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2157 - val_loss: 0.2178\n",
            "Epoch 1286/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2156 - val_loss: 0.2177\n",
            "Epoch 1287/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2155 - val_loss: 0.2176\n",
            "Epoch 1288/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2155 - val_loss: 0.2175\n",
            "Epoch 1289/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2154 - val_loss: 0.2174\n",
            "Epoch 1290/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2153 - val_loss: 0.2173\n",
            "Epoch 1291/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2152 - val_loss: 0.2172\n",
            "Epoch 1292/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2151 - val_loss: 0.2171\n",
            "Epoch 1293/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2151 - val_loss: 0.2170\n",
            "Epoch 1294/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2150 - val_loss: 0.2169\n",
            "Epoch 1295/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2149 - val_loss: 0.2168\n",
            "Epoch 1296/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2148 - val_loss: 0.2167\n",
            "Epoch 1297/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2147 - val_loss: 0.2166\n",
            "Epoch 1298/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2147 - val_loss: 0.2165\n",
            "Epoch 1299/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2146 - val_loss: 0.2164\n",
            "Epoch 1300/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2145 - val_loss: 0.2164\n",
            "Epoch 1301/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2144 - val_loss: 0.2163\n",
            "Epoch 1302/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2144 - val_loss: 0.2162\n",
            "Epoch 1303/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2143 - val_loss: 0.2161\n",
            "Epoch 1304/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2142 - val_loss: 0.2160\n",
            "Epoch 1305/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2141 - val_loss: 0.2159\n",
            "Epoch 1306/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2141 - val_loss: 0.2158\n",
            "Epoch 1307/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2140 - val_loss: 0.2157\n",
            "Epoch 1308/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2139 - val_loss: 0.2156\n",
            "Epoch 1309/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2138 - val_loss: 0.2155\n",
            "Epoch 1310/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2137 - val_loss: 0.2154\n",
            "Epoch 1311/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2137 - val_loss: 0.2153\n",
            "Epoch 1312/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2136 - val_loss: 0.2152\n",
            "Epoch 1313/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2135 - val_loss: 0.2152\n",
            "Epoch 1314/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2134 - val_loss: 0.2151\n",
            "Epoch 1315/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2134 - val_loss: 0.2150\n",
            "Epoch 1316/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2133 - val_loss: 0.2149\n",
            "Epoch 1317/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2132 - val_loss: 0.2148\n",
            "Epoch 1318/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2131 - val_loss: 0.2147\n",
            "Epoch 1319/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2131 - val_loss: 0.2146\n",
            "Epoch 1320/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2130 - val_loss: 0.2145\n",
            "Epoch 1321/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2129 - val_loss: 0.2144\n",
            "Epoch 1322/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2128 - val_loss: 0.2143\n",
            "Epoch 1323/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2128 - val_loss: 0.2142\n",
            "Epoch 1324/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2127 - val_loss: 0.2142\n",
            "Epoch 1325/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2126 - val_loss: 0.2141\n",
            "Epoch 1326/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2125 - val_loss: 0.2140\n",
            "Epoch 1327/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2125 - val_loss: 0.2139\n",
            "Epoch 1328/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2124 - val_loss: 0.2138\n",
            "Epoch 1329/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2123 - val_loss: 0.2137\n",
            "Epoch 1330/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2123 - val_loss: 0.2136\n",
            "Epoch 1331/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2122 - val_loss: 0.2135\n",
            "Epoch 1332/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2121 - val_loss: 0.2135\n",
            "Epoch 1333/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2120 - val_loss: 0.2134\n",
            "Epoch 1334/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2120 - val_loss: 0.2133\n",
            "Epoch 1335/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2119 - val_loss: 0.2132\n",
            "Epoch 1336/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2118 - val_loss: 0.2131\n",
            "Epoch 1337/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2118 - val_loss: 0.2130\n",
            "Epoch 1338/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2117 - val_loss: 0.2129\n",
            "Epoch 1339/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2116 - val_loss: 0.2129\n",
            "Epoch 1340/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2115 - val_loss: 0.2128\n",
            "Epoch 1341/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2115 - val_loss: 0.2127\n",
            "Epoch 1342/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2114 - val_loss: 0.2126\n",
            "Epoch 1343/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2113 - val_loss: 0.2125\n",
            "Epoch 1344/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2113 - val_loss: 0.2124\n",
            "Epoch 1345/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2112 - val_loss: 0.2124\n",
            "Epoch 1346/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2111 - val_loss: 0.2123\n",
            "Epoch 1347/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2111 - val_loss: 0.2122\n",
            "Epoch 1348/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2110 - val_loss: 0.2121\n",
            "Epoch 1349/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2109 - val_loss: 0.2120\n",
            "Epoch 1350/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2109 - val_loss: 0.2119\n",
            "Epoch 1351/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2108 - val_loss: 0.2119\n",
            "Epoch 1352/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2107 - val_loss: 0.2118\n",
            "Epoch 1353/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2107 - val_loss: 0.2117\n",
            "Epoch 1354/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2106 - val_loss: 0.2116\n",
            "Epoch 1355/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2105 - val_loss: 0.2115\n",
            "Epoch 1356/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2104 - val_loss: 0.2115\n",
            "Epoch 1357/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2104 - val_loss: 0.2114\n",
            "Epoch 1358/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2103 - val_loss: 0.2113\n",
            "Epoch 1359/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2103 - val_loss: 0.2112\n",
            "Epoch 1360/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2102 - val_loss: 0.2111\n",
            "Epoch 1361/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2101 - val_loss: 0.2111\n",
            "Epoch 1362/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2101 - val_loss: 0.2110\n",
            "Epoch 1363/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2100 - val_loss: 0.2109\n",
            "Epoch 1364/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2099 - val_loss: 0.2108\n",
            "Epoch 1365/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2099 - val_loss: 0.2108\n",
            "Epoch 1366/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2098 - val_loss: 0.2107\n",
            "Epoch 1367/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2097 - val_loss: 0.2106\n",
            "Epoch 1368/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2097 - val_loss: 0.2105\n",
            "Epoch 1369/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2096 - val_loss: 0.2104\n",
            "Epoch 1370/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2095 - val_loss: 0.2104\n",
            "Epoch 1371/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2095 - val_loss: 0.2103\n",
            "Epoch 1372/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2094 - val_loss: 0.2102\n",
            "Epoch 1373/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2093 - val_loss: 0.2101\n",
            "Epoch 1374/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2093 - val_loss: 0.2100\n",
            "Epoch 1375/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2092 - val_loss: 0.2100\n",
            "Epoch 1376/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2091 - val_loss: 0.2099\n",
            "Epoch 1377/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2091 - val_loss: 0.2098\n",
            "Epoch 1378/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2090 - val_loss: 0.2097\n",
            "Epoch 1379/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2089 - val_loss: 0.2097\n",
            "Epoch 1380/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2089 - val_loss: 0.2096\n",
            "Epoch 1381/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2088 - val_loss: 0.2095\n",
            "Epoch 1382/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2088 - val_loss: 0.2094\n",
            "Epoch 1383/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2087 - val_loss: 0.2094\n",
            "Epoch 1384/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2086 - val_loss: 0.2093\n",
            "Epoch 1385/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2086 - val_loss: 0.2092\n",
            "Epoch 1386/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2085 - val_loss: 0.2091\n",
            "Epoch 1387/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2084 - val_loss: 0.2091\n",
            "Epoch 1388/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2084 - val_loss: 0.2090\n",
            "Epoch 1389/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2083 - val_loss: 0.2089\n",
            "Epoch 1390/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2082 - val_loss: 0.2088\n",
            "Epoch 1391/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2082 - val_loss: 0.2088\n",
            "Epoch 1392/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2081 - val_loss: 0.2087\n",
            "Epoch 1393/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2081 - val_loss: 0.2086\n",
            "Epoch 1394/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2080 - val_loss: 0.2086\n",
            "Epoch 1395/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2079 - val_loss: 0.2085\n",
            "Epoch 1396/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2079 - val_loss: 0.2084\n",
            "Epoch 1397/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2078 - val_loss: 0.2083\n",
            "Epoch 1398/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2078 - val_loss: 0.2083\n",
            "Epoch 1399/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2077 - val_loss: 0.2082\n",
            "Epoch 1400/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2076 - val_loss: 0.2081\n",
            "Epoch 1401/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2076 - val_loss: 0.2081\n",
            "Epoch 1402/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2075 - val_loss: 0.2080\n",
            "Epoch 1403/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2074 - val_loss: 0.2079\n",
            "Epoch 1404/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2074 - val_loss: 0.2078\n",
            "Epoch 1405/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2073 - val_loss: 0.2078\n",
            "Epoch 1406/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2073 - val_loss: 0.2077\n",
            "Epoch 1407/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2072 - val_loss: 0.2076\n",
            "Epoch 1408/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2071 - val_loss: 0.2076\n",
            "Epoch 1409/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2071 - val_loss: 0.2075\n",
            "Epoch 1410/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2070 - val_loss: 0.2074\n",
            "Epoch 1411/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2070 - val_loss: 0.2073\n",
            "Epoch 1412/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2069 - val_loss: 0.2073\n",
            "Epoch 1413/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2068 - val_loss: 0.2072\n",
            "Epoch 1414/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2068 - val_loss: 0.2071\n",
            "Epoch 1415/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2067 - val_loss: 0.2071\n",
            "Epoch 1416/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2067 - val_loss: 0.2070\n",
            "Epoch 1417/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2066 - val_loss: 0.2069\n",
            "Epoch 1418/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2065 - val_loss: 0.2069\n",
            "Epoch 1419/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2065 - val_loss: 0.2068\n",
            "Epoch 1420/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2064 - val_loss: 0.2067\n",
            "Epoch 1421/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2064 - val_loss: 0.2066\n",
            "Epoch 1422/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2063 - val_loss: 0.2066\n",
            "Epoch 1423/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2062 - val_loss: 0.2065\n",
            "Epoch 1424/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2062 - val_loss: 0.2064\n",
            "Epoch 1425/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2061 - val_loss: 0.2064\n",
            "Epoch 1426/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2061 - val_loss: 0.2063\n",
            "Epoch 1427/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2060 - val_loss: 0.2062\n",
            "Epoch 1428/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2059 - val_loss: 0.2062\n",
            "Epoch 1429/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2059 - val_loss: 0.2061\n",
            "Epoch 1430/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2058 - val_loss: 0.2060\n",
            "Epoch 1431/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2058 - val_loss: 0.2059\n",
            "Epoch 1432/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2057 - val_loss: 0.2059\n",
            "Epoch 1433/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2056 - val_loss: 0.2058\n",
            "Epoch 1434/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2056 - val_loss: 0.2057\n",
            "Epoch 1435/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2055 - val_loss: 0.2057\n",
            "Epoch 1436/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2055 - val_loss: 0.2056\n",
            "Epoch 1437/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2054 - val_loss: 0.2055\n",
            "Epoch 1438/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2053 - val_loss: 0.2055\n",
            "Epoch 1439/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2053 - val_loss: 0.2054\n",
            "Epoch 1440/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2052 - val_loss: 0.2053\n",
            "Epoch 1441/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2052 - val_loss: 0.2053\n",
            "Epoch 1442/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2051 - val_loss: 0.2052\n",
            "Epoch 1443/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2051 - val_loss: 0.2051\n",
            "Epoch 1444/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2050 - val_loss: 0.2051\n",
            "Epoch 1445/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2049 - val_loss: 0.2050\n",
            "Epoch 1446/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2049 - val_loss: 0.2049\n",
            "Epoch 1447/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2048 - val_loss: 0.2049\n",
            "Epoch 1448/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2048 - val_loss: 0.2048\n",
            "Epoch 1449/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2047 - val_loss: 0.2047\n",
            "Epoch 1450/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2047 - val_loss: 0.2047\n",
            "Epoch 1451/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2046 - val_loss: 0.2046\n",
            "Epoch 1452/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2045 - val_loss: 0.2045\n",
            "Epoch 1453/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2045 - val_loss: 0.2045\n",
            "Epoch 1454/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2044 - val_loss: 0.2044\n",
            "Epoch 1455/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2044 - val_loss: 0.2043\n",
            "Epoch 1456/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2043 - val_loss: 0.2043\n",
            "Epoch 1457/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2043 - val_loss: 0.2042\n",
            "Epoch 1458/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2042 - val_loss: 0.2042\n",
            "Epoch 1459/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2042 - val_loss: 0.2041\n",
            "Epoch 1460/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2041 - val_loss: 0.2040\n",
            "Epoch 1461/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2041 - val_loss: 0.2040\n",
            "Epoch 1462/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2040 - val_loss: 0.2039\n",
            "Epoch 1463/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2039 - val_loss: 0.2038\n",
            "Epoch 1464/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2039 - val_loss: 0.2038\n",
            "Epoch 1465/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2038 - val_loss: 0.2037\n",
            "Epoch 1466/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2038 - val_loss: 0.2036\n",
            "Epoch 1467/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2037 - val_loss: 0.2036\n",
            "Epoch 1468/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2037 - val_loss: 0.2035\n",
            "Epoch 1469/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2036 - val_loss: 0.2035\n",
            "Epoch 1470/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2036 - val_loss: 0.2034\n",
            "Epoch 1471/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2035 - val_loss: 0.2033\n",
            "Epoch 1472/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2035 - val_loss: 0.2033\n",
            "Epoch 1473/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2034 - val_loss: 0.2032\n",
            "Epoch 1474/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2033 - val_loss: 0.2031\n",
            "Epoch 1475/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2033 - val_loss: 0.2031\n",
            "Epoch 1476/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2032 - val_loss: 0.2030\n",
            "Epoch 1477/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2032 - val_loss: 0.2030\n",
            "Epoch 1478/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2031 - val_loss: 0.2029\n",
            "Epoch 1479/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2031 - val_loss: 0.2028\n",
            "Epoch 1480/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2030 - val_loss: 0.2028\n",
            "Epoch 1481/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2030 - val_loss: 0.2027\n",
            "Epoch 1482/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2029 - val_loss: 0.2027\n",
            "Epoch 1483/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2029 - val_loss: 0.2026\n",
            "Epoch 1484/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2028 - val_loss: 0.2025\n",
            "Epoch 1485/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2028 - val_loss: 0.2025\n",
            "Epoch 1486/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2027 - val_loss: 0.2024\n",
            "Epoch 1487/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2027 - val_loss: 0.2023\n",
            "Epoch 1488/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2026 - val_loss: 0.2023\n",
            "Epoch 1489/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2026 - val_loss: 0.2022\n",
            "Epoch 1490/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2025 - val_loss: 0.2022\n",
            "Epoch 1491/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2025 - val_loss: 0.2021\n",
            "Epoch 1492/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2024 - val_loss: 0.2020\n",
            "Epoch 1493/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2023 - val_loss: 0.2020\n",
            "Epoch 1494/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2023 - val_loss: 0.2019\n",
            "Epoch 1495/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2022 - val_loss: 0.2019\n",
            "Epoch 1496/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2022 - val_loss: 0.2018\n",
            "Epoch 1497/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2021 - val_loss: 0.2017\n",
            "Epoch 1498/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2021 - val_loss: 0.2017\n",
            "Epoch 1499/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2020 - val_loss: 0.2016\n",
            "Epoch 1500/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2020 - val_loss: 0.2015\n",
            "Epoch 1501/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2019 - val_loss: 0.2015\n",
            "Epoch 1502/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2019 - val_loss: 0.2014\n",
            "Epoch 1503/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2018 - val_loss: 0.2014\n",
            "Epoch 1504/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2018 - val_loss: 0.2013\n",
            "Epoch 1505/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2017 - val_loss: 0.2012\n",
            "Epoch 1506/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2017 - val_loss: 0.2012\n",
            "Epoch 1507/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2016 - val_loss: 0.2011\n",
            "Epoch 1508/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2016 - val_loss: 0.2011\n",
            "Epoch 1509/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2015 - val_loss: 0.2010\n",
            "Epoch 1510/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2015 - val_loss: 0.2009\n",
            "Epoch 1511/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2014 - val_loss: 0.2009\n",
            "Epoch 1512/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2014 - val_loss: 0.2008\n",
            "Epoch 1513/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2013 - val_loss: 0.2008\n",
            "Epoch 1514/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2013 - val_loss: 0.2007\n",
            "Epoch 1515/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2012 - val_loss: 0.2006\n",
            "Epoch 1516/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2012 - val_loss: 0.2006\n",
            "Epoch 1517/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2011 - val_loss: 0.2005\n",
            "Epoch 1518/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2011 - val_loss: 0.2005\n",
            "Epoch 1519/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2010 - val_loss: 0.2004\n",
            "Epoch 1520/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2010 - val_loss: 0.2003\n",
            "Epoch 1521/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2009 - val_loss: 0.2003\n",
            "Epoch 1522/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2009 - val_loss: 0.2002\n",
            "Epoch 1523/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2008 - val_loss: 0.2002\n",
            "Epoch 1524/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2008 - val_loss: 0.2001\n",
            "Epoch 1525/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2007 - val_loss: 0.2001\n",
            "Epoch 1526/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2007 - val_loss: 0.2000\n",
            "Epoch 1527/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2006 - val_loss: 0.1999\n",
            "Epoch 1528/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2006 - val_loss: 0.1999\n",
            "Epoch 1529/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2005 - val_loss: 0.1998\n",
            "Epoch 1530/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2005 - val_loss: 0.1998\n",
            "Epoch 1531/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2004 - val_loss: 0.1997\n",
            "Epoch 1532/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2004 - val_loss: 0.1996\n",
            "Epoch 1533/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2003 - val_loss: 0.1996\n",
            "Epoch 1534/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2003 - val_loss: 0.1995\n",
            "Epoch 1535/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2002 - val_loss: 0.1995\n",
            "Epoch 1536/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2002 - val_loss: 0.1994\n",
            "Epoch 1537/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2001 - val_loss: 0.1994\n",
            "Epoch 1538/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2001 - val_loss: 0.1993\n",
            "Epoch 1539/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2000 - val_loss: 0.1992\n",
            "Epoch 1540/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.2000 - val_loss: 0.1992\n",
            "Epoch 1541/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1999 - val_loss: 0.1991\n",
            "Epoch 1542/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1999 - val_loss: 0.1991\n",
            "Epoch 1543/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1998 - val_loss: 0.1990\n",
            "Epoch 1544/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1998 - val_loss: 0.1990\n",
            "Epoch 1545/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1997 - val_loss: 0.1989\n",
            "Epoch 1546/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1997 - val_loss: 0.1988\n",
            "Epoch 1547/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1996 - val_loss: 0.1988\n",
            "Epoch 1548/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1996 - val_loss: 0.1987\n",
            "Epoch 1549/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1996 - val_loss: 0.1987\n",
            "Epoch 1550/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1995 - val_loss: 0.1986\n",
            "Epoch 1551/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1995 - val_loss: 0.1986\n",
            "Epoch 1552/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1994 - val_loss: 0.1985\n",
            "Epoch 1553/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1994 - val_loss: 0.1984\n",
            "Epoch 1554/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1993 - val_loss: 0.1984\n",
            "Epoch 1555/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1993 - val_loss: 0.1983\n",
            "Epoch 1556/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1992 - val_loss: 0.1983\n",
            "Epoch 1557/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1992 - val_loss: 0.1982\n",
            "Epoch 1558/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1991 - val_loss: 0.1982\n",
            "Epoch 1559/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1991 - val_loss: 0.1981\n",
            "Epoch 1560/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1990 - val_loss: 0.1981\n",
            "Epoch 1561/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1990 - val_loss: 0.1980\n",
            "Epoch 1562/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1990 - val_loss: 0.1979\n",
            "Epoch 1563/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1989 - val_loss: 0.1979\n",
            "Epoch 1564/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1989 - val_loss: 0.1978\n",
            "Epoch 1565/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1988 - val_loss: 0.1978\n",
            "Epoch 1566/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1988 - val_loss: 0.1977\n",
            "Epoch 1567/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1987 - val_loss: 0.1977\n",
            "Epoch 1568/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1987 - val_loss: 0.1976\n",
            "Epoch 1569/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1986 - val_loss: 0.1976\n",
            "Epoch 1570/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1986 - val_loss: 0.1975\n",
            "Epoch 1571/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1985 - val_loss: 0.1974\n",
            "Epoch 1572/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1985 - val_loss: 0.1974\n",
            "Epoch 1573/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1985 - val_loss: 0.1973\n",
            "Epoch 1574/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1984 - val_loss: 0.1973\n",
            "Epoch 1575/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1984 - val_loss: 0.1972\n",
            "Epoch 1576/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1983 - val_loss: 0.1972\n",
            "Epoch 1577/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1983 - val_loss: 0.1971\n",
            "Epoch 1578/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1982 - val_loss: 0.1971\n",
            "Epoch 1579/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1982 - val_loss: 0.1970\n",
            "Epoch 1580/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1981 - val_loss: 0.1969\n",
            "Epoch 1581/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1981 - val_loss: 0.1969\n",
            "Epoch 1582/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1981 - val_loss: 0.1968\n",
            "Epoch 1583/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1980 - val_loss: 0.1968\n",
            "Epoch 1584/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1980 - val_loss: 0.1967\n",
            "Epoch 1585/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1979 - val_loss: 0.1967\n",
            "Epoch 1586/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1979 - val_loss: 0.1966\n",
            "Epoch 1587/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1978 - val_loss: 0.1965\n",
            "Epoch 1588/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1978 - val_loss: 0.1965\n",
            "Epoch 1589/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1977 - val_loss: 0.1964\n",
            "Epoch 1590/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1977 - val_loss: 0.1964\n",
            "Epoch 1591/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1976 - val_loss: 0.1963\n",
            "Epoch 1592/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1976 - val_loss: 0.1963\n",
            "Epoch 1593/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1975 - val_loss: 0.1962\n",
            "Epoch 1594/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1975 - val_loss: 0.1962\n",
            "Epoch 1595/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1975 - val_loss: 0.1961\n",
            "Epoch 1596/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1974 - val_loss: 0.1960\n",
            "Epoch 1597/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1974 - val_loss: 0.1960\n",
            "Epoch 1598/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1973 - val_loss: 0.1959\n",
            "Epoch 1599/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1973 - val_loss: 0.1959\n",
            "Epoch 1600/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1972 - val_loss: 0.1958\n",
            "Epoch 1601/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1972 - val_loss: 0.1958\n",
            "Epoch 1602/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1971 - val_loss: 0.1957\n",
            "Epoch 1603/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1971 - val_loss: 0.1957\n",
            "Epoch 1604/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1971 - val_loss: 0.1956\n",
            "Epoch 1605/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1970 - val_loss: 0.1956\n",
            "Epoch 1606/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1970 - val_loss: 0.1955\n",
            "Epoch 1607/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1969 - val_loss: 0.1955\n",
            "Epoch 1608/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1969 - val_loss: 0.1954\n",
            "Epoch 1609/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1968 - val_loss: 0.1953\n",
            "Epoch 1610/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1968 - val_loss: 0.1953\n",
            "Epoch 1611/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1968 - val_loss: 0.1952\n",
            "Epoch 1612/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1967 - val_loss: 0.1952\n",
            "Epoch 1613/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1967 - val_loss: 0.1951\n",
            "Epoch 1614/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1966 - val_loss: 0.1951\n",
            "Epoch 1615/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1966 - val_loss: 0.1950\n",
            "Epoch 1616/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1965 - val_loss: 0.1950\n",
            "Epoch 1617/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1965 - val_loss: 0.1949\n",
            "Epoch 1618/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1965 - val_loss: 0.1949\n",
            "Epoch 1619/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1964 - val_loss: 0.1948\n",
            "Epoch 1620/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1964 - val_loss: 0.1948\n",
            "Epoch 1621/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1963 - val_loss: 0.1947\n",
            "Epoch 1622/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1963 - val_loss: 0.1947\n",
            "Epoch 1623/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1962 - val_loss: 0.1946\n",
            "Epoch 1624/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1962 - val_loss: 0.1946\n",
            "Epoch 1625/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1962 - val_loss: 0.1945\n",
            "Epoch 1626/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1961 - val_loss: 0.1945\n",
            "Epoch 1627/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1961 - val_loss: 0.1944\n",
            "Epoch 1628/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1960 - val_loss: 0.1944\n",
            "Epoch 1629/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1960 - val_loss: 0.1943\n",
            "Epoch 1630/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1959 - val_loss: 0.1943\n",
            "Epoch 1631/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1959 - val_loss: 0.1942\n",
            "Epoch 1632/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1959 - val_loss: 0.1942\n",
            "Epoch 1633/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1958 - val_loss: 0.1941\n",
            "Epoch 1634/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1958 - val_loss: 0.1941\n",
            "Epoch 1635/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1957 - val_loss: 0.1940\n",
            "Epoch 1636/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1957 - val_loss: 0.1940\n",
            "Epoch 1637/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1957 - val_loss: 0.1939\n",
            "Epoch 1638/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1956 - val_loss: 0.1939\n",
            "Epoch 1639/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1956 - val_loss: 0.1938\n",
            "Epoch 1640/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1955 - val_loss: 0.1938\n",
            "Epoch 1641/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1955 - val_loss: 0.1937\n",
            "Epoch 1642/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1954 - val_loss: 0.1937\n",
            "Epoch 1643/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1954 - val_loss: 0.1936\n",
            "Epoch 1644/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1954 - val_loss: 0.1936\n",
            "Epoch 1645/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1953 - val_loss: 0.1935\n",
            "Epoch 1646/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1953 - val_loss: 0.1935\n",
            "Epoch 1647/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1952 - val_loss: 0.1934\n",
            "Epoch 1648/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1952 - val_loss: 0.1934\n",
            "Epoch 1649/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1952 - val_loss: 0.1933\n",
            "Epoch 1650/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1951 - val_loss: 0.1933\n",
            "Epoch 1651/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1951 - val_loss: 0.1932\n",
            "Epoch 1652/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1950 - val_loss: 0.1932\n",
            "Epoch 1653/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1950 - val_loss: 0.1931\n",
            "Epoch 1654/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1950 - val_loss: 0.1931\n",
            "Epoch 1655/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1949 - val_loss: 0.1930\n",
            "Epoch 1656/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1949 - val_loss: 0.1930\n",
            "Epoch 1657/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1948 - val_loss: 0.1929\n",
            "Epoch 1658/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1948 - val_loss: 0.1929\n",
            "Epoch 1659/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1948 - val_loss: 0.1929\n",
            "Epoch 1660/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1947 - val_loss: 0.1928\n",
            "Epoch 1661/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1947 - val_loss: 0.1928\n",
            "Epoch 1662/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1946 - val_loss: 0.1927\n",
            "Epoch 1663/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1946 - val_loss: 0.1927\n",
            "Epoch 1664/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1946 - val_loss: 0.1926\n",
            "Epoch 1665/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1945 - val_loss: 0.1926\n",
            "Epoch 1666/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1945 - val_loss: 0.1925\n",
            "Epoch 1667/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1944 - val_loss: 0.1925\n",
            "Epoch 1668/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1944 - val_loss: 0.1924\n",
            "Epoch 1669/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1944 - val_loss: 0.1924\n",
            "Epoch 1670/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1943 - val_loss: 0.1923\n",
            "Epoch 1671/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1943 - val_loss: 0.1923\n",
            "Epoch 1672/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1942 - val_loss: 0.1922\n",
            "Epoch 1673/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1942 - val_loss: 0.1922\n",
            "Epoch 1674/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1942 - val_loss: 0.1921\n",
            "Epoch 1675/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1941 - val_loss: 0.1921\n",
            "Epoch 1676/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1941 - val_loss: 0.1920\n",
            "Epoch 1677/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1940 - val_loss: 0.1920\n",
            "Epoch 1678/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1940 - val_loss: 0.1920\n",
            "Epoch 1679/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1940 - val_loss: 0.1919\n",
            "Epoch 1680/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1939 - val_loss: 0.1919\n",
            "Epoch 1681/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1939 - val_loss: 0.1918\n",
            "Epoch 1682/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1938 - val_loss: 0.1918\n",
            "Epoch 1683/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1938 - val_loss: 0.1917\n",
            "Epoch 1684/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1938 - val_loss: 0.1917\n",
            "Epoch 1685/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1937 - val_loss: 0.1916\n",
            "Epoch 1686/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1937 - val_loss: 0.1916\n",
            "Epoch 1687/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1937 - val_loss: 0.1915\n",
            "Epoch 1688/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1936 - val_loss: 0.1915\n",
            "Epoch 1689/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1936 - val_loss: 0.1914\n",
            "Epoch 1690/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1935 - val_loss: 0.1914\n",
            "Epoch 1691/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1935 - val_loss: 0.1914\n",
            "Epoch 1692/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1935 - val_loss: 0.1913\n",
            "Epoch 1693/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1934 - val_loss: 0.1913\n",
            "Epoch 1694/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1934 - val_loss: 0.1912\n",
            "Epoch 1695/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1933 - val_loss: 0.1912\n",
            "Epoch 1696/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1933 - val_loss: 0.1911\n",
            "Epoch 1697/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1933 - val_loss: 0.1911\n",
            "Epoch 1698/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1932 - val_loss: 0.1910\n",
            "Epoch 1699/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1932 - val_loss: 0.1910\n",
            "Epoch 1700/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1932 - val_loss: 0.1909\n",
            "Epoch 1701/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1931 - val_loss: 0.1909\n",
            "Epoch 1702/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1931 - val_loss: 0.1909\n",
            "Epoch 1703/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1930 - val_loss: 0.1908\n",
            "Epoch 1704/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1930 - val_loss: 0.1908\n",
            "Epoch 1705/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1930 - val_loss: 0.1907\n",
            "Epoch 1706/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1929 - val_loss: 0.1907\n",
            "Epoch 1707/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1929 - val_loss: 0.1906\n",
            "Epoch 1708/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1929 - val_loss: 0.1906\n",
            "Epoch 1709/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1928 - val_loss: 0.1905\n",
            "Epoch 1710/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1928 - val_loss: 0.1905\n",
            "Epoch 1711/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1927 - val_loss: 0.1904\n",
            "Epoch 1712/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1927 - val_loss: 0.1904\n",
            "Epoch 1713/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1927 - val_loss: 0.1904\n",
            "Epoch 1714/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1926 - val_loss: 0.1903\n",
            "Epoch 1715/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1926 - val_loss: 0.1903\n",
            "Epoch 1716/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1925 - val_loss: 0.1902\n",
            "Epoch 1717/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1925 - val_loss: 0.1902\n",
            "Epoch 1718/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1925 - val_loss: 0.1901\n",
            "Epoch 1719/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1924 - val_loss: 0.1901\n",
            "Epoch 1720/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1924 - val_loss: 0.1900\n",
            "Epoch 1721/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1924 - val_loss: 0.1900\n",
            "Epoch 1722/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1923 - val_loss: 0.1900\n",
            "Epoch 1723/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1923 - val_loss: 0.1899\n",
            "Epoch 1724/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1923 - val_loss: 0.1899\n",
            "Epoch 1725/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1922 - val_loss: 0.1898\n",
            "Epoch 1726/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1922 - val_loss: 0.1898\n",
            "Epoch 1727/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1921 - val_loss: 0.1897\n",
            "Epoch 1728/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1921 - val_loss: 0.1897\n",
            "Epoch 1729/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1921 - val_loss: 0.1897\n",
            "Epoch 1730/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1920 - val_loss: 0.1896\n",
            "Epoch 1731/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1920 - val_loss: 0.1896\n",
            "Epoch 1732/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1920 - val_loss: 0.1895\n",
            "Epoch 1733/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1919 - val_loss: 0.1895\n",
            "Epoch 1734/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1919 - val_loss: 0.1894\n",
            "Epoch 1735/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1919 - val_loss: 0.1894\n",
            "Epoch 1736/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1918 - val_loss: 0.1893\n",
            "Epoch 1737/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1918 - val_loss: 0.1893\n",
            "Epoch 1738/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1917 - val_loss: 0.1893\n",
            "Epoch 1739/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1917 - val_loss: 0.1892\n",
            "Epoch 1740/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1917 - val_loss: 0.1892\n",
            "Epoch 1741/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1916 - val_loss: 0.1891\n",
            "Epoch 1742/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1916 - val_loss: 0.1891\n",
            "Epoch 1743/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1916 - val_loss: 0.1890\n",
            "Epoch 1744/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1915 - val_loss: 0.1890\n",
            "Epoch 1745/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1915 - val_loss: 0.1889\n",
            "Epoch 1746/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1915 - val_loss: 0.1889\n",
            "Epoch 1747/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1914 - val_loss: 0.1889\n",
            "Epoch 1748/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1914 - val_loss: 0.1888\n",
            "Epoch 1749/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1913 - val_loss: 0.1888\n",
            "Epoch 1750/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1913 - val_loss: 0.1887\n",
            "Epoch 1751/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1913 - val_loss: 0.1887\n",
            "Epoch 1752/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1912 - val_loss: 0.1886\n",
            "Epoch 1753/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1912 - val_loss: 0.1886\n",
            "Epoch 1754/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1912 - val_loss: 0.1886\n",
            "Epoch 1755/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1911 - val_loss: 0.1885\n",
            "Epoch 1756/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1911 - val_loss: 0.1885\n",
            "Epoch 1757/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1911 - val_loss: 0.1884\n",
            "Epoch 1758/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1910 - val_loss: 0.1884\n",
            "Epoch 1759/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1910 - val_loss: 0.1883\n",
            "Epoch 1760/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1910 - val_loss: 0.1883\n",
            "Epoch 1761/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1909 - val_loss: 0.1883\n",
            "Epoch 1762/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1909 - val_loss: 0.1882\n",
            "Epoch 1763/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1909 - val_loss: 0.1882\n",
            "Epoch 1764/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1908 - val_loss: 0.1881\n",
            "Epoch 1765/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1908 - val_loss: 0.1881\n",
            "Epoch 1766/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1907 - val_loss: 0.1880\n",
            "Epoch 1767/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1907 - val_loss: 0.1880\n",
            "Epoch 1768/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1907 - val_loss: 0.1880\n",
            "Epoch 1769/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1906 - val_loss: 0.1879\n",
            "Epoch 1770/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1906 - val_loss: 0.1879\n",
            "Epoch 1771/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1906 - val_loss: 0.1878\n",
            "Epoch 1772/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1905 - val_loss: 0.1878\n",
            "Epoch 1773/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1905 - val_loss: 0.1878\n",
            "Epoch 1774/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1905 - val_loss: 0.1877\n",
            "Epoch 1775/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1904 - val_loss: 0.1877\n",
            "Epoch 1776/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1904 - val_loss: 0.1876\n",
            "Epoch 1777/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1904 - val_loss: 0.1876\n",
            "Epoch 1778/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1903 - val_loss: 0.1875\n",
            "Epoch 1779/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1903 - val_loss: 0.1875\n",
            "Epoch 1780/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1903 - val_loss: 0.1875\n",
            "Epoch 1781/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1902 - val_loss: 0.1874\n",
            "Epoch 1782/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1902 - val_loss: 0.1874\n",
            "Epoch 1783/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1902 - val_loss: 0.1873\n",
            "Epoch 1784/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1901 - val_loss: 0.1873\n",
            "Epoch 1785/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1901 - val_loss: 0.1873\n",
            "Epoch 1786/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1901 - val_loss: 0.1872\n",
            "Epoch 1787/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1900 - val_loss: 0.1872\n",
            "Epoch 1788/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1900 - val_loss: 0.1871\n",
            "Epoch 1789/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1900 - val_loss: 0.1871\n",
            "Epoch 1790/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1899 - val_loss: 0.1870\n",
            "Epoch 1791/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1899 - val_loss: 0.1870\n",
            "Epoch 1792/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1898 - val_loss: 0.1870\n",
            "Epoch 1793/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1898 - val_loss: 0.1869\n",
            "Epoch 1794/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1898 - val_loss: 0.1869\n",
            "Epoch 1795/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1897 - val_loss: 0.1868\n",
            "Epoch 1796/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1897 - val_loss: 0.1868\n",
            "Epoch 1797/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1897 - val_loss: 0.1867\n",
            "Epoch 1798/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1896 - val_loss: 0.1867\n",
            "Epoch 1799/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1896 - val_loss: 0.1867\n",
            "Epoch 1800/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1896 - val_loss: 0.1866\n",
            "Epoch 1801/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1895 - val_loss: 0.1866\n",
            "Epoch 1802/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1895 - val_loss: 0.1865\n",
            "Epoch 1803/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1895 - val_loss: 0.1865\n",
            "Epoch 1804/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1894 - val_loss: 0.1865\n",
            "Epoch 1805/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1894 - val_loss: 0.1864\n",
            "Epoch 1806/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1894 - val_loss: 0.1864\n",
            "Epoch 1807/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1893 - val_loss: 0.1863\n",
            "Epoch 1808/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1893 - val_loss: 0.1863\n",
            "Epoch 1809/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1893 - val_loss: 0.1863\n",
            "Epoch 1810/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1892 - val_loss: 0.1862\n",
            "Epoch 1811/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1892 - val_loss: 0.1862\n",
            "Epoch 1812/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1892 - val_loss: 0.1861\n",
            "Epoch 1813/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1891 - val_loss: 0.1861\n",
            "Epoch 1814/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1891 - val_loss: 0.1861\n",
            "Epoch 1815/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1891 - val_loss: 0.1860\n",
            "Epoch 1816/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1890 - val_loss: 0.1860\n",
            "Epoch 1817/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1890 - val_loss: 0.1859\n",
            "Epoch 1818/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1890 - val_loss: 0.1859\n",
            "Epoch 1819/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1889 - val_loss: 0.1859\n",
            "Epoch 1820/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1889 - val_loss: 0.1858\n",
            "Epoch 1821/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1889 - val_loss: 0.1858\n",
            "Epoch 1822/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1888 - val_loss: 0.1857\n",
            "Epoch 1823/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1888 - val_loss: 0.1857\n",
            "Epoch 1824/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1888 - val_loss: 0.1857\n",
            "Epoch 1825/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1887 - val_loss: 0.1856\n",
            "Epoch 1826/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1887 - val_loss: 0.1856\n",
            "Epoch 1827/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1887 - val_loss: 0.1855\n",
            "Epoch 1828/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1886 - val_loss: 0.1855\n",
            "Epoch 1829/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1886 - val_loss: 0.1855\n",
            "Epoch 1830/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1886 - val_loss: 0.1854\n",
            "Epoch 1831/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1885 - val_loss: 0.1854\n",
            "Epoch 1832/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1885 - val_loss: 0.1853\n",
            "Epoch 1833/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1885 - val_loss: 0.1853\n",
            "Epoch 1834/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1884 - val_loss: 0.1853\n",
            "Epoch 1835/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1884 - val_loss: 0.1852\n",
            "Epoch 1836/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1884 - val_loss: 0.1852\n",
            "Epoch 1837/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1883 - val_loss: 0.1852\n",
            "Epoch 1838/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1883 - val_loss: 0.1851\n",
            "Epoch 1839/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1883 - val_loss: 0.1851\n",
            "Epoch 1840/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1882 - val_loss: 0.1850\n",
            "Epoch 1841/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1882 - val_loss: 0.1850\n",
            "Epoch 1842/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1882 - val_loss: 0.1850\n",
            "Epoch 1843/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1881 - val_loss: 0.1849\n",
            "Epoch 1844/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1881 - val_loss: 0.1849\n",
            "Epoch 1845/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1881 - val_loss: 0.1848\n",
            "Epoch 1846/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1880 - val_loss: 0.1848\n",
            "Epoch 1847/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1880 - val_loss: 0.1848\n",
            "Epoch 1848/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1880 - val_loss: 0.1847\n",
            "Epoch 1849/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1879 - val_loss: 0.1847\n",
            "Epoch 1850/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1879 - val_loss: 0.1846\n",
            "Epoch 1851/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1879 - val_loss: 0.1846\n",
            "Epoch 1852/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1878 - val_loss: 0.1846\n",
            "Epoch 1853/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1878 - val_loss: 0.1845\n",
            "Epoch 1854/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1878 - val_loss: 0.1845\n",
            "Epoch 1855/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1878 - val_loss: 0.1845\n",
            "Epoch 1856/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1877 - val_loss: 0.1844\n",
            "Epoch 1857/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1877 - val_loss: 0.1844\n",
            "Epoch 1858/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1877 - val_loss: 0.1843\n",
            "Epoch 1859/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1876 - val_loss: 0.1843\n",
            "Epoch 1860/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1876 - val_loss: 0.1843\n",
            "Epoch 1861/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1876 - val_loss: 0.1842\n",
            "Epoch 1862/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1875 - val_loss: 0.1842\n",
            "Epoch 1863/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1875 - val_loss: 0.1841\n",
            "Epoch 1864/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1875 - val_loss: 0.1841\n",
            "Epoch 1865/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1874 - val_loss: 0.1841\n",
            "Epoch 1866/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1874 - val_loss: 0.1840\n",
            "Epoch 1867/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1874 - val_loss: 0.1840\n",
            "Epoch 1868/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1873 - val_loss: 0.1840\n",
            "Epoch 1869/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1873 - val_loss: 0.1839\n",
            "Epoch 1870/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1873 - val_loss: 0.1839\n",
            "Epoch 1871/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1872 - val_loss: 0.1839\n",
            "Epoch 1872/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1872 - val_loss: 0.1838\n",
            "Epoch 1873/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1872 - val_loss: 0.1838\n",
            "Epoch 1874/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1872 - val_loss: 0.1837\n",
            "Epoch 1875/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1871 - val_loss: 0.1837\n",
            "Epoch 1876/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1871 - val_loss: 0.1837\n",
            "Epoch 1877/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1871 - val_loss: 0.1836\n",
            "Epoch 1878/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1870 - val_loss: 0.1836\n",
            "Epoch 1879/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1870 - val_loss: 0.1836\n",
            "Epoch 1880/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1870 - val_loss: 0.1835\n",
            "Epoch 1881/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1869 - val_loss: 0.1835\n",
            "Epoch 1882/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1869 - val_loss: 0.1835\n",
            "Epoch 1883/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1869 - val_loss: 0.1834\n",
            "Epoch 1884/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1868 - val_loss: 0.1834\n",
            "Epoch 1885/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1868 - val_loss: 0.1833\n",
            "Epoch 1886/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1868 - val_loss: 0.1833\n",
            "Epoch 1887/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1868 - val_loss: 0.1833\n",
            "Epoch 1888/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1867 - val_loss: 0.1832\n",
            "Epoch 1889/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1867 - val_loss: 0.1832\n",
            "Epoch 1890/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1867 - val_loss: 0.1832\n",
            "Epoch 1891/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1866 - val_loss: 0.1831\n",
            "Epoch 1892/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1866 - val_loss: 0.1831\n",
            "Epoch 1893/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1866 - val_loss: 0.1831\n",
            "Epoch 1894/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1865 - val_loss: 0.1830\n",
            "Epoch 1895/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1865 - val_loss: 0.1830\n",
            "Epoch 1896/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1865 - val_loss: 0.1830\n",
            "Epoch 1897/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1864 - val_loss: 0.1829\n",
            "Epoch 1898/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1864 - val_loss: 0.1829\n",
            "Epoch 1899/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1864 - val_loss: 0.1829\n",
            "Epoch 1900/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1864 - val_loss: 0.1828\n",
            "Epoch 1901/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1863 - val_loss: 0.1828\n",
            "Epoch 1902/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1863 - val_loss: 0.1827\n",
            "Epoch 1903/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1863 - val_loss: 0.1827\n",
            "Epoch 1904/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1862 - val_loss: 0.1827\n",
            "Epoch 1905/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1862 - val_loss: 0.1826\n",
            "Epoch 1906/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1862 - val_loss: 0.1826\n",
            "Epoch 1907/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1861 - val_loss: 0.1826\n",
            "Epoch 1908/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1861 - val_loss: 0.1825\n",
            "Epoch 1909/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1861 - val_loss: 0.1825\n",
            "Epoch 1910/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1861 - val_loss: 0.1825\n",
            "Epoch 1911/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1860 - val_loss: 0.1824\n",
            "Epoch 1912/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1860 - val_loss: 0.1824\n",
            "Epoch 1913/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1860 - val_loss: 0.1824\n",
            "Epoch 1914/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1859 - val_loss: 0.1823\n",
            "Epoch 1915/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1859 - val_loss: 0.1823\n",
            "Epoch 1916/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1859 - val_loss: 0.1823\n",
            "Epoch 1917/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1859 - val_loss: 0.1822\n",
            "Epoch 1918/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1858 - val_loss: 0.1822\n",
            "Epoch 1919/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1858 - val_loss: 0.1822\n",
            "Epoch 1920/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1858 - val_loss: 0.1821\n",
            "Epoch 1921/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1857 - val_loss: 0.1821\n",
            "Epoch 1922/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1857 - val_loss: 0.1821\n",
            "Epoch 1923/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1857 - val_loss: 0.1820\n",
            "Epoch 1924/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1856 - val_loss: 0.1820\n",
            "Epoch 1925/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1856 - val_loss: 0.1820\n",
            "Epoch 1926/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1856 - val_loss: 0.1819\n",
            "Epoch 1927/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1856 - val_loss: 0.1819\n",
            "Epoch 1928/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1855 - val_loss: 0.1819\n",
            "Epoch 1929/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1855 - val_loss: 0.1818\n",
            "Epoch 1930/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1855 - val_loss: 0.1818\n",
            "Epoch 1931/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1854 - val_loss: 0.1818\n",
            "Epoch 1932/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1854 - val_loss: 0.1817\n",
            "Epoch 1933/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1854 - val_loss: 0.1817\n",
            "Epoch 1934/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1854 - val_loss: 0.1817\n",
            "Epoch 1935/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1853 - val_loss: 0.1816\n",
            "Epoch 1936/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1853 - val_loss: 0.1816\n",
            "Epoch 1937/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1853 - val_loss: 0.1816\n",
            "Epoch 1938/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1852 - val_loss: 0.1815\n",
            "Epoch 1939/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1852 - val_loss: 0.1815\n",
            "Epoch 1940/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1852 - val_loss: 0.1815\n",
            "Epoch 1941/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1852 - val_loss: 0.1814\n",
            "Epoch 1942/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1851 - val_loss: 0.1814\n",
            "Epoch 1943/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1851 - val_loss: 0.1814\n",
            "Epoch 1944/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1851 - val_loss: 0.1813\n",
            "Epoch 1945/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1850 - val_loss: 0.1813\n",
            "Epoch 1946/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1850 - val_loss: 0.1813\n",
            "Epoch 1947/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1850 - val_loss: 0.1812\n",
            "Epoch 1948/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1850 - val_loss: 0.1812\n",
            "Epoch 1949/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1849 - val_loss: 0.1812\n",
            "Epoch 1950/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1849 - val_loss: 0.1811\n",
            "Epoch 1951/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1849 - val_loss: 0.1811\n",
            "Epoch 1952/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1849 - val_loss: 0.1811\n",
            "Epoch 1953/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1848 - val_loss: 0.1810\n",
            "Epoch 1954/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1848 - val_loss: 0.1810\n",
            "Epoch 1955/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1848 - val_loss: 0.1810\n",
            "Epoch 1956/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1847 - val_loss: 0.1809\n",
            "Epoch 1957/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1847 - val_loss: 0.1809\n",
            "Epoch 1958/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1847 - val_loss: 0.1809\n",
            "Epoch 1959/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1847 - val_loss: 0.1809\n",
            "Epoch 1960/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1846 - val_loss: 0.1808\n",
            "Epoch 1961/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1846 - val_loss: 0.1808\n",
            "Epoch 1962/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1846 - val_loss: 0.1808\n",
            "Epoch 1963/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1846 - val_loss: 0.1807\n",
            "Epoch 1964/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1845 - val_loss: 0.1807\n",
            "Epoch 1965/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1845 - val_loss: 0.1807\n",
            "Epoch 1966/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1845 - val_loss: 0.1806\n",
            "Epoch 1967/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1844 - val_loss: 0.1806\n",
            "Epoch 1968/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1844 - val_loss: 0.1806\n",
            "Epoch 1969/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1844 - val_loss: 0.1805\n",
            "Epoch 1970/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1844 - val_loss: 0.1805\n",
            "Epoch 1971/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1843 - val_loss: 0.1805\n",
            "Epoch 1972/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1843 - val_loss: 0.1804\n",
            "Epoch 1973/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1843 - val_loss: 0.1804\n",
            "Epoch 1974/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1843 - val_loss: 0.1804\n",
            "Epoch 1975/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1842 - val_loss: 0.1803\n",
            "Epoch 1976/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1842 - val_loss: 0.1803\n",
            "Epoch 1977/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1842 - val_loss: 0.1803\n",
            "Epoch 1978/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1841 - val_loss: 0.1802\n",
            "Epoch 1979/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1841 - val_loss: 0.1802\n",
            "Epoch 1980/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1841 - val_loss: 0.1802\n",
            "Epoch 1981/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1841 - val_loss: 0.1802\n",
            "Epoch 1982/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1840 - val_loss: 0.1801\n",
            "Epoch 1983/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1840 - val_loss: 0.1801\n",
            "Epoch 1984/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1840 - val_loss: 0.1801\n",
            "Epoch 1985/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1840 - val_loss: 0.1800\n",
            "Epoch 1986/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1839 - val_loss: 0.1800\n",
            "Epoch 1987/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1839 - val_loss: 0.1800\n",
            "Epoch 1988/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1839 - val_loss: 0.1799\n",
            "Epoch 1989/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1839 - val_loss: 0.1799\n",
            "Epoch 1990/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1838 - val_loss: 0.1799\n",
            "Epoch 1991/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1838 - val_loss: 0.1798\n",
            "Epoch 1992/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1838 - val_loss: 0.1798\n",
            "Epoch 1993/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1837 - val_loss: 0.1798\n",
            "Epoch 1994/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1837 - val_loss: 0.1798\n",
            "Epoch 1995/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1837 - val_loss: 0.1797\n",
            "Epoch 1996/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1837 - val_loss: 0.1797\n",
            "Epoch 1997/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1836 - val_loss: 0.1797\n",
            "Epoch 1998/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1836 - val_loss: 0.1796\n",
            "Epoch 1999/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1836 - val_loss: 0.1796\n",
            "Epoch 2000/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1836 - val_loss: 0.1796\n",
            "Epoch 2001/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1835 - val_loss: 0.1795\n",
            "Epoch 2002/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1835 - val_loss: 0.1795\n",
            "Epoch 2003/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1835 - val_loss: 0.1795\n",
            "Epoch 2004/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1835 - val_loss: 0.1795\n",
            "Epoch 2005/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1834 - val_loss: 0.1794\n",
            "Epoch 2006/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1834 - val_loss: 0.1794\n",
            "Epoch 2007/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1834 - val_loss: 0.1794\n",
            "Epoch 2008/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1834 - val_loss: 0.1793\n",
            "Epoch 2009/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1833 - val_loss: 0.1793\n",
            "Epoch 2010/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1833 - val_loss: 0.1793\n",
            "Epoch 2011/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1833 - val_loss: 0.1792\n",
            "Epoch 2012/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1833 - val_loss: 0.1792\n",
            "Epoch 2013/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1832 - val_loss: 0.1792\n",
            "Epoch 2014/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1832 - val_loss: 0.1792\n",
            "Epoch 2015/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1832 - val_loss: 0.1791\n",
            "Epoch 2016/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1832 - val_loss: 0.1791\n",
            "Epoch 2017/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1831 - val_loss: 0.1791\n",
            "Epoch 2018/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1831 - val_loss: 0.1790\n",
            "Epoch 2019/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1831 - val_loss: 0.1790\n",
            "Epoch 2020/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1831 - val_loss: 0.1790\n",
            "Epoch 2021/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1830 - val_loss: 0.1790\n",
            "Epoch 2022/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1830 - val_loss: 0.1789\n",
            "Epoch 2023/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1830 - val_loss: 0.1789\n",
            "Epoch 2024/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1830 - val_loss: 0.1789\n",
            "Epoch 2025/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1829 - val_loss: 0.1788\n",
            "Epoch 2026/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1829 - val_loss: 0.1788\n",
            "Epoch 2027/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1829 - val_loss: 0.1788\n",
            "Epoch 2028/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1829 - val_loss: 0.1788\n",
            "Epoch 2029/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1828 - val_loss: 0.1787\n",
            "Epoch 2030/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1828 - val_loss: 0.1787\n",
            "Epoch 2031/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1828 - val_loss: 0.1787\n",
            "Epoch 2032/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1828 - val_loss: 0.1786\n",
            "Epoch 2033/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1827 - val_loss: 0.1786\n",
            "Epoch 2034/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1827 - val_loss: 0.1786\n",
            "Epoch 2035/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1827 - val_loss: 0.1785\n",
            "Epoch 2036/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1827 - val_loss: 0.1785\n",
            "Epoch 2037/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1826 - val_loss: 0.1785\n",
            "Epoch 2038/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1826 - val_loss: 0.1785\n",
            "Epoch 2039/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1826 - val_loss: 0.1784\n",
            "Epoch 2040/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1826 - val_loss: 0.1784\n",
            "Epoch 2041/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1825 - val_loss: 0.1784\n",
            "Epoch 2042/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1825 - val_loss: 0.1783\n",
            "Epoch 2043/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1825 - val_loss: 0.1783\n",
            "Epoch 2044/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1825 - val_loss: 0.1783\n",
            "Epoch 2045/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1824 - val_loss: 0.1783\n",
            "Epoch 2046/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1824 - val_loss: 0.1782\n",
            "Epoch 2047/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1824 - val_loss: 0.1782\n",
            "Epoch 2048/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1824 - val_loss: 0.1782\n",
            "Epoch 2049/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1824 - val_loss: 0.1782\n",
            "Epoch 2050/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1823 - val_loss: 0.1781\n",
            "Epoch 2051/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1823 - val_loss: 0.1781\n",
            "Epoch 2052/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1823 - val_loss: 0.1781\n",
            "Epoch 2053/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1823 - val_loss: 0.1780\n",
            "Epoch 2054/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1822 - val_loss: 0.1780\n",
            "Epoch 2055/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1822 - val_loss: 0.1780\n",
            "Epoch 2056/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1822 - val_loss: 0.1780\n",
            "Epoch 2057/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1822 - val_loss: 0.1779\n",
            "Epoch 2058/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1821 - val_loss: 0.1779\n",
            "Epoch 2059/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1821 - val_loss: 0.1779\n",
            "Epoch 2060/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1821 - val_loss: 0.1778\n",
            "Epoch 2061/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1821 - val_loss: 0.1778\n",
            "Epoch 2062/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1820 - val_loss: 0.1778\n",
            "Epoch 2063/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1820 - val_loss: 0.1778\n",
            "Epoch 2064/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1820 - val_loss: 0.1777\n",
            "Epoch 2065/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1820 - val_loss: 0.1777\n",
            "Epoch 2066/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1819 - val_loss: 0.1777\n",
            "Epoch 2067/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1819 - val_loss: 0.1777\n",
            "Epoch 2068/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1819 - val_loss: 0.1776\n",
            "Epoch 2069/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1819 - val_loss: 0.1776\n",
            "Epoch 2070/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1819 - val_loss: 0.1776\n",
            "Epoch 2071/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1818 - val_loss: 0.1775\n",
            "Epoch 2072/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1818 - val_loss: 0.1775\n",
            "Epoch 2073/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1818 - val_loss: 0.1775\n",
            "Epoch 2074/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1818 - val_loss: 0.1775\n",
            "Epoch 2075/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1817 - val_loss: 0.1774\n",
            "Epoch 2076/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1817 - val_loss: 0.1774\n",
            "Epoch 2077/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1817 - val_loss: 0.1774\n",
            "Epoch 2078/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1817 - val_loss: 0.1774\n",
            "Epoch 2079/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1816 - val_loss: 0.1773\n",
            "Epoch 2080/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1816 - val_loss: 0.1773\n",
            "Epoch 2081/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1816 - val_loss: 0.1773\n",
            "Epoch 2082/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1816 - val_loss: 0.1772\n",
            "Epoch 2083/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1816 - val_loss: 0.1772\n",
            "Epoch 2084/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1815 - val_loss: 0.1772\n",
            "Epoch 2085/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1815 - val_loss: 0.1772\n",
            "Epoch 2086/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1815 - val_loss: 0.1771\n",
            "Epoch 2087/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1815 - val_loss: 0.1771\n",
            "Epoch 2088/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1814 - val_loss: 0.1771\n",
            "Epoch 2089/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1814 - val_loss: 0.1771\n",
            "Epoch 2090/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1814 - val_loss: 0.1770\n",
            "Epoch 2091/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1814 - val_loss: 0.1770\n",
            "Epoch 2092/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1814 - val_loss: 0.1770\n",
            "Epoch 2093/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1813 - val_loss: 0.1770\n",
            "Epoch 2094/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1813 - val_loss: 0.1769\n",
            "Epoch 2095/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1813 - val_loss: 0.1769\n",
            "Epoch 2096/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1813 - val_loss: 0.1769\n",
            "Epoch 2097/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1812 - val_loss: 0.1768\n",
            "Epoch 2098/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1812 - val_loss: 0.1768\n",
            "Epoch 2099/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1812 - val_loss: 0.1768\n",
            "Epoch 2100/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1812 - val_loss: 0.1768\n",
            "Epoch 2101/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1811 - val_loss: 0.1767\n",
            "Epoch 2102/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1811 - val_loss: 0.1767\n",
            "Epoch 2103/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1811 - val_loss: 0.1767\n",
            "Epoch 2104/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1811 - val_loss: 0.1767\n",
            "Epoch 2105/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1811 - val_loss: 0.1766\n",
            "Epoch 2106/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1810 - val_loss: 0.1766\n",
            "Epoch 2107/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1810 - val_loss: 0.1766\n",
            "Epoch 2108/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1810 - val_loss: 0.1766\n",
            "Epoch 2109/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1810 - val_loss: 0.1765\n",
            "Epoch 2110/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1809 - val_loss: 0.1765\n",
            "Epoch 2111/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1809 - val_loss: 0.1765\n",
            "Epoch 2112/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1809 - val_loss: 0.1765\n",
            "Epoch 2113/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1809 - val_loss: 0.1764\n",
            "Epoch 2114/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1809 - val_loss: 0.1764\n",
            "Epoch 2115/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1808 - val_loss: 0.1764\n",
            "Epoch 2116/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1808 - val_loss: 0.1763\n",
            "Epoch 2117/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1808 - val_loss: 0.1763\n",
            "Epoch 2118/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1808 - val_loss: 0.1763\n",
            "Epoch 2119/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1807 - val_loss: 0.1763\n",
            "Epoch 2120/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1807 - val_loss: 0.1762\n",
            "Epoch 2121/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1807 - val_loss: 0.1762\n",
            "Epoch 2122/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1807 - val_loss: 0.1762\n",
            "Epoch 2123/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1807 - val_loss: 0.1762\n",
            "Epoch 2124/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1806 - val_loss: 0.1761\n",
            "Epoch 2125/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1806 - val_loss: 0.1761\n",
            "Epoch 2126/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1806 - val_loss: 0.1761\n",
            "Epoch 2127/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1806 - val_loss: 0.1761\n",
            "Epoch 2128/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1806 - val_loss: 0.1760\n",
            "Epoch 2129/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1805 - val_loss: 0.1760\n",
            "Epoch 2130/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1805 - val_loss: 0.1760\n",
            "Epoch 2131/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1805 - val_loss: 0.1760\n",
            "Epoch 2132/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1805 - val_loss: 0.1759\n",
            "Epoch 2133/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1804 - val_loss: 0.1759\n",
            "Epoch 2134/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1804 - val_loss: 0.1759\n",
            "Epoch 2135/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1804 - val_loss: 0.1759\n",
            "Epoch 2136/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1804 - val_loss: 0.1758\n",
            "Epoch 2137/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1804 - val_loss: 0.1758\n",
            "Epoch 2138/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1803 - val_loss: 0.1758\n",
            "Epoch 2139/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1803 - val_loss: 0.1758\n",
            "Epoch 2140/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1803 - val_loss: 0.1757\n",
            "Epoch 2141/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1803 - val_loss: 0.1757\n",
            "Epoch 2142/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1802 - val_loss: 0.1757\n",
            "Epoch 2143/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1802 - val_loss: 0.1757\n",
            "Epoch 2144/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1802 - val_loss: 0.1756\n",
            "Epoch 2145/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1802 - val_loss: 0.1756\n",
            "Epoch 2146/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1802 - val_loss: 0.1756\n",
            "Epoch 2147/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1801 - val_loss: 0.1756\n",
            "Epoch 2148/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1801 - val_loss: 0.1755\n",
            "Epoch 2149/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1801 - val_loss: 0.1755\n",
            "Epoch 2150/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1801 - val_loss: 0.1755\n",
            "Epoch 2151/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1801 - val_loss: 0.1755\n",
            "Epoch 2152/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1800 - val_loss: 0.1754\n",
            "Epoch 2153/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1800 - val_loss: 0.1754\n",
            "Epoch 2154/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1800 - val_loss: 0.1754\n",
            "Epoch 2155/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1800 - val_loss: 0.1754\n",
            "Epoch 2156/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1800 - val_loss: 0.1753\n",
            "Epoch 2157/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1799 - val_loss: 0.1753\n",
            "Epoch 2158/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1799 - val_loss: 0.1753\n",
            "Epoch 2159/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1799 - val_loss: 0.1753\n",
            "Epoch 2160/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1799 - val_loss: 0.1752\n",
            "Epoch 2161/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1798 - val_loss: 0.1752\n",
            "Epoch 2162/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1798 - val_loss: 0.1752\n",
            "Epoch 2163/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1798 - val_loss: 0.1752\n",
            "Epoch 2164/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1798 - val_loss: 0.1751\n",
            "Epoch 2165/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1798 - val_loss: 0.1751\n",
            "Epoch 2166/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1797 - val_loss: 0.1751\n",
            "Epoch 2167/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1797 - val_loss: 0.1751\n",
            "Epoch 2168/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1797 - val_loss: 0.1750\n",
            "Epoch 2169/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1797 - val_loss: 0.1750\n",
            "Epoch 2170/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1797 - val_loss: 0.1750\n",
            "Epoch 2171/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1796 - val_loss: 0.1750\n",
            "Epoch 2172/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1796 - val_loss: 0.1750\n",
            "Epoch 2173/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1796 - val_loss: 0.1749\n",
            "Epoch 2174/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1796 - val_loss: 0.1749\n",
            "Epoch 2175/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1796 - val_loss: 0.1749\n",
            "Epoch 2176/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1795 - val_loss: 0.1749\n",
            "Epoch 2177/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1795 - val_loss: 0.1748\n",
            "Epoch 2178/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1795 - val_loss: 0.1748\n",
            "Epoch 2179/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1795 - val_loss: 0.1748\n",
            "Epoch 2180/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1794 - val_loss: 0.1748\n",
            "Epoch 2181/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1794 - val_loss: 0.1747\n",
            "Epoch 2182/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1794 - val_loss: 0.1747\n",
            "Epoch 2183/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1794 - val_loss: 0.1747\n",
            "Epoch 2184/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1794 - val_loss: 0.1747\n",
            "Epoch 2185/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1793 - val_loss: 0.1746\n",
            "Epoch 2186/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1793 - val_loss: 0.1746\n",
            "Epoch 2187/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1793 - val_loss: 0.1746\n",
            "Epoch 2188/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1793 - val_loss: 0.1746\n",
            "Epoch 2189/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1793 - val_loss: 0.1745\n",
            "Epoch 2190/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1792 - val_loss: 0.1745\n",
            "Epoch 2191/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1792 - val_loss: 0.1745\n",
            "Epoch 2192/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1792 - val_loss: 0.1745\n",
            "Epoch 2193/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1792 - val_loss: 0.1745\n",
            "Epoch 2194/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1792 - val_loss: 0.1744\n",
            "Epoch 2195/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1791 - val_loss: 0.1744\n",
            "Epoch 2196/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1791 - val_loss: 0.1744\n",
            "Epoch 2197/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1791 - val_loss: 0.1744\n",
            "Epoch 2198/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1791 - val_loss: 0.1743\n",
            "Epoch 2199/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1791 - val_loss: 0.1743\n",
            "Epoch 2200/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1790 - val_loss: 0.1743\n",
            "Epoch 2201/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1790 - val_loss: 0.1743\n",
            "Epoch 2202/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1790 - val_loss: 0.1742\n",
            "Epoch 2203/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1790 - val_loss: 0.1742\n",
            "Epoch 2204/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1790 - val_loss: 0.1742\n",
            "Epoch 2205/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1789 - val_loss: 0.1742\n",
            "Epoch 2206/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1789 - val_loss: 0.1742\n",
            "Epoch 2207/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1789 - val_loss: 0.1741\n",
            "Epoch 2208/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1789 - val_loss: 0.1741\n",
            "Epoch 2209/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1789 - val_loss: 0.1741\n",
            "Epoch 2210/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1788 - val_loss: 0.1741\n",
            "Epoch 2211/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1788 - val_loss: 0.1740\n",
            "Epoch 2212/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1788 - val_loss: 0.1740\n",
            "Epoch 2213/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1788 - val_loss: 0.1740\n",
            "Epoch 2214/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1788 - val_loss: 0.1740\n",
            "Epoch 2215/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1787 - val_loss: 0.1739\n",
            "Epoch 2216/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1787 - val_loss: 0.1739\n",
            "Epoch 2217/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1787 - val_loss: 0.1739\n",
            "Epoch 2218/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1787 - val_loss: 0.1739\n",
            "Epoch 2219/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1787 - val_loss: 0.1739\n",
            "Epoch 2220/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1786 - val_loss: 0.1738\n",
            "Epoch 2221/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1786 - val_loss: 0.1738\n",
            "Epoch 2222/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1786 - val_loss: 0.1738\n",
            "Epoch 2223/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1786 - val_loss: 0.1738\n",
            "Epoch 2224/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1786 - val_loss: 0.1737\n",
            "Epoch 2225/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1785 - val_loss: 0.1737\n",
            "Epoch 2226/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1785 - val_loss: 0.1737\n",
            "Epoch 2227/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1785 - val_loss: 0.1737\n",
            "Epoch 2228/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1785 - val_loss: 0.1737\n",
            "Epoch 2229/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1785 - val_loss: 0.1736\n",
            "Epoch 2230/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1784 - val_loss: 0.1736\n",
            "Epoch 2231/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1784 - val_loss: 0.1736\n",
            "Epoch 2232/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1784 - val_loss: 0.1736\n",
            "Epoch 2233/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1784 - val_loss: 0.1735\n",
            "Epoch 2234/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1784 - val_loss: 0.1735\n",
            "Epoch 2235/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1783 - val_loss: 0.1735\n",
            "Epoch 2236/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1783 - val_loss: 0.1735\n",
            "Epoch 2237/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1783 - val_loss: 0.1734\n",
            "Epoch 2238/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1783 - val_loss: 0.1734\n",
            "Epoch 2239/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1783 - val_loss: 0.1734\n",
            "Epoch 2240/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1782 - val_loss: 0.1734\n",
            "Epoch 2241/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1782 - val_loss: 0.1734\n",
            "Epoch 2242/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1782 - val_loss: 0.1733\n",
            "Epoch 2243/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1782 - val_loss: 0.1733\n",
            "Epoch 2244/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1782 - val_loss: 0.1733\n",
            "Epoch 2245/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1782 - val_loss: 0.1733\n",
            "Epoch 2246/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1781 - val_loss: 0.1733\n",
            "Epoch 2247/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1781 - val_loss: 0.1732\n",
            "Epoch 2248/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1781 - val_loss: 0.1732\n",
            "Epoch 2249/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1781 - val_loss: 0.1732\n",
            "Epoch 2250/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1781 - val_loss: 0.1732\n",
            "Epoch 2251/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1780 - val_loss: 0.1731\n",
            "Epoch 2252/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1780 - val_loss: 0.1731\n",
            "Epoch 2253/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1780 - val_loss: 0.1731\n",
            "Epoch 2254/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1780 - val_loss: 0.1731\n",
            "Epoch 2255/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1780 - val_loss: 0.1731\n",
            "Epoch 2256/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1779 - val_loss: 0.1730\n",
            "Epoch 2257/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1779 - val_loss: 0.1730\n",
            "Epoch 2258/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1779 - val_loss: 0.1730\n",
            "Epoch 2259/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1779 - val_loss: 0.1730\n",
            "Epoch 2260/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1779 - val_loss: 0.1729\n",
            "Epoch 2261/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1778 - val_loss: 0.1729\n",
            "Epoch 2262/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1778 - val_loss: 0.1729\n",
            "Epoch 2263/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1778 - val_loss: 0.1729\n",
            "Epoch 2264/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1778 - val_loss: 0.1729\n",
            "Epoch 2265/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1778 - val_loss: 0.1728\n",
            "Epoch 2266/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1778 - val_loss: 0.1728\n",
            "Epoch 2267/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1777 - val_loss: 0.1728\n",
            "Epoch 2268/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1777 - val_loss: 0.1728\n",
            "Epoch 2269/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1777 - val_loss: 0.1728\n",
            "Epoch 2270/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1777 - val_loss: 0.1727\n",
            "Epoch 2271/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1777 - val_loss: 0.1727\n",
            "Epoch 2272/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1776 - val_loss: 0.1727\n",
            "Epoch 2273/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1776 - val_loss: 0.1727\n",
            "Epoch 2274/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1776 - val_loss: 0.1726\n",
            "Epoch 2275/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1776 - val_loss: 0.1726\n",
            "Epoch 2276/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1776 - val_loss: 0.1726\n",
            "Epoch 2277/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1776 - val_loss: 0.1726\n",
            "Epoch 2278/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1775 - val_loss: 0.1726\n",
            "Epoch 2279/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1775 - val_loss: 0.1725\n",
            "Epoch 2280/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1775 - val_loss: 0.1725\n",
            "Epoch 2281/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1775 - val_loss: 0.1725\n",
            "Epoch 2282/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1775 - val_loss: 0.1725\n",
            "Epoch 2283/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1774 - val_loss: 0.1724\n",
            "Epoch 2284/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1774 - val_loss: 0.1724\n",
            "Epoch 2285/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1774 - val_loss: 0.1724\n",
            "Epoch 2286/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1774 - val_loss: 0.1724\n",
            "Epoch 2287/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1774 - val_loss: 0.1724\n",
            "Epoch 2288/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1773 - val_loss: 0.1723\n",
            "Epoch 2289/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1773 - val_loss: 0.1723\n",
            "Epoch 2290/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1773 - val_loss: 0.1723\n",
            "Epoch 2291/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1773 - val_loss: 0.1723\n",
            "Epoch 2292/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1773 - val_loss: 0.1723\n",
            "Epoch 2293/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1773 - val_loss: 0.1722\n",
            "Epoch 2294/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1772 - val_loss: 0.1722\n",
            "Epoch 2295/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1772 - val_loss: 0.1722\n",
            "Epoch 2296/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1772 - val_loss: 0.1722\n",
            "Epoch 2297/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1772 - val_loss: 0.1722\n",
            "Epoch 2298/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1772 - val_loss: 0.1721\n",
            "Epoch 2299/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1771 - val_loss: 0.1721\n",
            "Epoch 2300/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1771 - val_loss: 0.1721\n",
            "Epoch 2301/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1771 - val_loss: 0.1721\n",
            "Epoch 2302/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1771 - val_loss: 0.1721\n",
            "Epoch 2303/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1771 - val_loss: 0.1720\n",
            "Epoch 2304/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1771 - val_loss: 0.1720\n",
            "Epoch 2305/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1770 - val_loss: 0.1720\n",
            "Epoch 2306/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1770 - val_loss: 0.1720\n",
            "Epoch 2307/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1770 - val_loss: 0.1719\n",
            "Epoch 2308/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1770 - val_loss: 0.1719\n",
            "Epoch 2309/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1770 - val_loss: 0.1719\n",
            "Epoch 2310/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1769 - val_loss: 0.1719\n",
            "Epoch 2311/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1769 - val_loss: 0.1719\n",
            "Epoch 2312/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1769 - val_loss: 0.1718\n",
            "Epoch 2313/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1769 - val_loss: 0.1718\n",
            "Epoch 2314/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1769 - val_loss: 0.1718\n",
            "Epoch 2315/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1769 - val_loss: 0.1718\n",
            "Epoch 2316/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1768 - val_loss: 0.1718\n",
            "Epoch 2317/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1768 - val_loss: 0.1717\n",
            "Epoch 2318/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1768 - val_loss: 0.1717\n",
            "Epoch 2319/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1768 - val_loss: 0.1717\n",
            "Epoch 2320/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1768 - val_loss: 0.1717\n",
            "Epoch 2321/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1767 - val_loss: 0.1717\n",
            "Epoch 2322/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1767 - val_loss: 0.1716\n",
            "Epoch 2323/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1767 - val_loss: 0.1716\n",
            "Epoch 2324/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1767 - val_loss: 0.1716\n",
            "Epoch 2325/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1767 - val_loss: 0.1716\n",
            "Epoch 2326/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1767 - val_loss: 0.1716\n",
            "Epoch 2327/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1766 - val_loss: 0.1715\n",
            "Epoch 2328/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1766 - val_loss: 0.1715\n",
            "Epoch 2329/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1766 - val_loss: 0.1715\n",
            "Epoch 2330/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1766 - val_loss: 0.1715\n",
            "Epoch 2331/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1766 - val_loss: 0.1715\n",
            "Epoch 2332/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1765 - val_loss: 0.1714\n",
            "Epoch 2333/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1765 - val_loss: 0.1714\n",
            "Epoch 2334/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1765 - val_loss: 0.1714\n",
            "Epoch 2335/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1765 - val_loss: 0.1714\n",
            "Epoch 2336/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1765 - val_loss: 0.1714\n",
            "Epoch 2337/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1765 - val_loss: 0.1713\n",
            "Epoch 2338/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1764 - val_loss: 0.1713\n",
            "Epoch 2339/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1764 - val_loss: 0.1713\n",
            "Epoch 2340/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1764 - val_loss: 0.1713\n",
            "Epoch 2341/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1764 - val_loss: 0.1713\n",
            "Epoch 2342/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1764 - val_loss: 0.1712\n",
            "Epoch 2343/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1763 - val_loss: 0.1712\n",
            "Epoch 2344/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1763 - val_loss: 0.1712\n",
            "Epoch 2345/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1763 - val_loss: 0.1712\n",
            "Epoch 2346/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1763 - val_loss: 0.1712\n",
            "Epoch 2347/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1763 - val_loss: 0.1711\n",
            "Epoch 2348/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1763 - val_loss: 0.1711\n",
            "Epoch 2349/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1762 - val_loss: 0.1711\n",
            "Epoch 2350/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1762 - val_loss: 0.1711\n",
            "Epoch 2351/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1762 - val_loss: 0.1711\n",
            "Epoch 2352/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1762 - val_loss: 0.1710\n",
            "Epoch 2353/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1762 - val_loss: 0.1710\n",
            "Epoch 2354/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1762 - val_loss: 0.1710\n",
            "Epoch 2355/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1761 - val_loss: 0.1710\n",
            "Epoch 2356/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1761 - val_loss: 0.1710\n",
            "Epoch 2357/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1761 - val_loss: 0.1709\n",
            "Epoch 2358/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1761 - val_loss: 0.1709\n",
            "Epoch 2359/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1761 - val_loss: 0.1709\n",
            "Epoch 2360/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1760 - val_loss: 0.1709\n",
            "Epoch 2361/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1760 - val_loss: 0.1709\n",
            "Epoch 2362/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1760 - val_loss: 0.1708\n",
            "Epoch 2363/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1760 - val_loss: 0.1708\n",
            "Epoch 2364/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1760 - val_loss: 0.1708\n",
            "Epoch 2365/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1760 - val_loss: 0.1708\n",
            "Epoch 2366/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1759 - val_loss: 0.1708\n",
            "Epoch 2367/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1759 - val_loss: 0.1707\n",
            "Epoch 2368/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1759 - val_loss: 0.1707\n",
            "Epoch 2369/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1759 - val_loss: 0.1707\n",
            "Epoch 2370/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1759 - val_loss: 0.1707\n",
            "Epoch 2371/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1759 - val_loss: 0.1707\n",
            "Epoch 2372/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1758 - val_loss: 0.1706\n",
            "Epoch 2373/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1758 - val_loss: 0.1706\n",
            "Epoch 2374/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1758 - val_loss: 0.1706\n",
            "Epoch 2375/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1758 - val_loss: 0.1706\n",
            "Epoch 2376/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1758 - val_loss: 0.1706\n",
            "Epoch 2377/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1758 - val_loss: 0.1705\n",
            "Epoch 2378/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1757 - val_loss: 0.1705\n",
            "Epoch 2379/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1757 - val_loss: 0.1705\n",
            "Epoch 2380/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1757 - val_loss: 0.1705\n",
            "Epoch 2381/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1757 - val_loss: 0.1705\n",
            "Epoch 2382/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1757 - val_loss: 0.1705\n",
            "Epoch 2383/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1757 - val_loss: 0.1704\n",
            "Epoch 2384/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1756 - val_loss: 0.1704\n",
            "Epoch 2385/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1756 - val_loss: 0.1704\n",
            "Epoch 2386/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1756 - val_loss: 0.1704\n",
            "Epoch 2387/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1756 - val_loss: 0.1704\n",
            "Epoch 2388/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1756 - val_loss: 0.1703\n",
            "Epoch 2389/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1755 - val_loss: 0.1703\n",
            "Epoch 2390/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1755 - val_loss: 0.1703\n",
            "Epoch 2391/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1755 - val_loss: 0.1703\n",
            "Epoch 2392/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1755 - val_loss: 0.1703\n",
            "Epoch 2393/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1755 - val_loss: 0.1702\n",
            "Epoch 2394/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1755 - val_loss: 0.1702\n",
            "Epoch 2395/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1754 - val_loss: 0.1702\n",
            "Epoch 2396/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1754 - val_loss: 0.1702\n",
            "Epoch 2397/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1754 - val_loss: 0.1702\n",
            "Epoch 2398/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1754 - val_loss: 0.1701\n",
            "Epoch 2399/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1754 - val_loss: 0.1701\n",
            "Epoch 2400/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1754 - val_loss: 0.1701\n",
            "Epoch 2401/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1753 - val_loss: 0.1701\n",
            "Epoch 2402/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1753 - val_loss: 0.1701\n",
            "Epoch 2403/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1753 - val_loss: 0.1701\n",
            "Epoch 2404/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1753 - val_loss: 0.1700\n",
            "Epoch 2405/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1753 - val_loss: 0.1700\n",
            "Epoch 2406/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1753 - val_loss: 0.1700\n",
            "Epoch 2407/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1752 - val_loss: 0.1700\n",
            "Epoch 2408/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1752 - val_loss: 0.1700\n",
            "Epoch 2409/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1752 - val_loss: 0.1699\n",
            "Epoch 2410/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1752 - val_loss: 0.1699\n",
            "Epoch 2411/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1752 - val_loss: 0.1699\n",
            "Epoch 2412/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1752 - val_loss: 0.1699\n",
            "Epoch 2413/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1751 - val_loss: 0.1699\n",
            "Epoch 2414/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1751 - val_loss: 0.1698\n",
            "Epoch 2415/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1751 - val_loss: 0.1698\n",
            "Epoch 2416/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1751 - val_loss: 0.1698\n",
            "Epoch 2417/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1751 - val_loss: 0.1698\n",
            "Epoch 2418/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1751 - val_loss: 0.1698\n",
            "Epoch 2419/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1751 - val_loss: 0.1698\n",
            "Epoch 2420/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1750 - val_loss: 0.1697\n",
            "Epoch 2421/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1750 - val_loss: 0.1697\n",
            "Epoch 2422/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1750 - val_loss: 0.1697\n",
            "Epoch 2423/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1750 - val_loss: 0.1697\n",
            "Epoch 2424/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1750 - val_loss: 0.1697\n",
            "Epoch 2425/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1750 - val_loss: 0.1696\n",
            "Epoch 2426/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1749 - val_loss: 0.1696\n",
            "Epoch 2427/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1749 - val_loss: 0.1696\n",
            "Epoch 2428/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1749 - val_loss: 0.1696\n",
            "Epoch 2429/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1749 - val_loss: 0.1696\n",
            "Epoch 2430/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1749 - val_loss: 0.1696\n",
            "Epoch 2431/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1749 - val_loss: 0.1695\n",
            "Epoch 2432/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1748 - val_loss: 0.1695\n",
            "Epoch 2433/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1748 - val_loss: 0.1695\n",
            "Epoch 2434/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1748 - val_loss: 0.1695\n",
            "Epoch 2435/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1748 - val_loss: 0.1695\n",
            "Epoch 2436/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1748 - val_loss: 0.1694\n",
            "Epoch 2437/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1748 - val_loss: 0.1694\n",
            "Epoch 2438/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1747 - val_loss: 0.1694\n",
            "Epoch 2439/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1747 - val_loss: 0.1694\n",
            "Epoch 2440/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1747 - val_loss: 0.1694\n",
            "Epoch 2441/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1747 - val_loss: 0.1694\n",
            "Epoch 2442/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1747 - val_loss: 0.1693\n",
            "Epoch 2443/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1747 - val_loss: 0.1693\n",
            "Epoch 2444/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1747 - val_loss: 0.1693\n",
            "Epoch 2445/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1746 - val_loss: 0.1693\n",
            "Epoch 2446/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1746 - val_loss: 0.1693\n",
            "Epoch 2447/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1746 - val_loss: 0.1692\n",
            "Epoch 2448/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1746 - val_loss: 0.1692\n",
            "Epoch 2449/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1746 - val_loss: 0.1692\n",
            "Epoch 2450/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1746 - val_loss: 0.1692\n",
            "Epoch 2451/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1745 - val_loss: 0.1692\n",
            "Epoch 2452/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1745 - val_loss: 0.1692\n",
            "Epoch 2453/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1745 - val_loss: 0.1691\n",
            "Epoch 2454/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1745 - val_loss: 0.1691\n",
            "Epoch 2455/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1745 - val_loss: 0.1691\n",
            "Epoch 2456/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1745 - val_loss: 0.1691\n",
            "Epoch 2457/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1745 - val_loss: 0.1691\n",
            "Epoch 2458/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1744 - val_loss: 0.1690\n",
            "Epoch 2459/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1744 - val_loss: 0.1690\n",
            "Epoch 2460/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1744 - val_loss: 0.1690\n",
            "Epoch 2461/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1744 - val_loss: 0.1690\n",
            "Epoch 2462/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1744 - val_loss: 0.1690\n",
            "Epoch 2463/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1744 - val_loss: 0.1690\n",
            "Epoch 2464/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1743 - val_loss: 0.1689\n",
            "Epoch 2465/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1743 - val_loss: 0.1689\n",
            "Epoch 2466/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1743 - val_loss: 0.1689\n",
            "Epoch 2467/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1743 - val_loss: 0.1689\n",
            "Epoch 2468/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1743 - val_loss: 0.1689\n",
            "Epoch 2469/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1743 - val_loss: 0.1688\n",
            "Epoch 2470/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1743 - val_loss: 0.1688\n",
            "Epoch 2471/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1742 - val_loss: 0.1688\n",
            "Epoch 2472/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1742 - val_loss: 0.1688\n",
            "Epoch 2473/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1742 - val_loss: 0.1688\n",
            "Epoch 2474/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1742 - val_loss: 0.1688\n",
            "Epoch 2475/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1742 - val_loss: 0.1687\n",
            "Epoch 2476/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1742 - val_loss: 0.1687\n",
            "Epoch 2477/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1741 - val_loss: 0.1687\n",
            "Epoch 2478/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1741 - val_loss: 0.1687\n",
            "Epoch 2479/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1741 - val_loss: 0.1687\n",
            "Epoch 2480/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1741 - val_loss: 0.1687\n",
            "Epoch 2481/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1741 - val_loss: 0.1686\n",
            "Epoch 2482/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1741 - val_loss: 0.1686\n",
            "Epoch 2483/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1741 - val_loss: 0.1686\n",
            "Epoch 2484/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1740 - val_loss: 0.1686\n",
            "Epoch 2485/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1740 - val_loss: 0.1686\n",
            "Epoch 2486/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1740 - val_loss: 0.1685\n",
            "Epoch 2487/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1740 - val_loss: 0.1685\n",
            "Epoch 2488/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1740 - val_loss: 0.1685\n",
            "Epoch 2489/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1740 - val_loss: 0.1685\n",
            "Epoch 2490/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1739 - val_loss: 0.1685\n",
            "Epoch 2491/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1739 - val_loss: 0.1685\n",
            "Epoch 2492/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1739 - val_loss: 0.1684\n",
            "Epoch 2493/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1739 - val_loss: 0.1684\n",
            "Epoch 2494/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1739 - val_loss: 0.1684\n",
            "Epoch 2495/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1739 - val_loss: 0.1684\n",
            "Epoch 2496/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1739 - val_loss: 0.1684\n",
            "Epoch 2497/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1738 - val_loss: 0.1684\n",
            "Epoch 2498/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1738 - val_loss: 0.1683\n",
            "Epoch 2499/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1738 - val_loss: 0.1683\n",
            "Epoch 2500/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1738 - val_loss: 0.1683\n",
            "Epoch 2501/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1738 - val_loss: 0.1683\n",
            "Epoch 2502/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1738 - val_loss: 0.1683\n",
            "Epoch 2503/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1737 - val_loss: 0.1683\n",
            "Epoch 2504/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1737 - val_loss: 0.1682\n",
            "Epoch 2505/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1737 - val_loss: 0.1682\n",
            "Epoch 2506/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1737 - val_loss: 0.1682\n",
            "Epoch 2507/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1737 - val_loss: 0.1682\n",
            "Epoch 2508/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1737 - val_loss: 0.1682\n",
            "Epoch 2509/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1737 - val_loss: 0.1681\n",
            "Epoch 2510/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1736 - val_loss: 0.1681\n",
            "Epoch 2511/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1736 - val_loss: 0.1681\n",
            "Epoch 2512/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1736 - val_loss: 0.1681\n",
            "Epoch 2513/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1736 - val_loss: 0.1681\n",
            "Epoch 2514/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1736 - val_loss: 0.1681\n",
            "Epoch 2515/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1736 - val_loss: 0.1680\n",
            "Epoch 2516/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1736 - val_loss: 0.1680\n",
            "Epoch 2517/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1735 - val_loss: 0.1680\n",
            "Epoch 2518/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1735 - val_loss: 0.1680\n",
            "Epoch 2519/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1735 - val_loss: 0.1680\n",
            "Epoch 2520/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1735 - val_loss: 0.1680\n",
            "Epoch 2521/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1735 - val_loss: 0.1679\n",
            "Epoch 2522/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1735 - val_loss: 0.1679\n",
            "Epoch 2523/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1734 - val_loss: 0.1679\n",
            "Epoch 2524/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1734 - val_loss: 0.1679\n",
            "Epoch 2525/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1734 - val_loss: 0.1679\n",
            "Epoch 2526/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1734 - val_loss: 0.1679\n",
            "Epoch 2527/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1734 - val_loss: 0.1678\n",
            "Epoch 2528/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1734 - val_loss: 0.1678\n",
            "Epoch 2529/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1734 - val_loss: 0.1678\n",
            "Epoch 2530/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1733 - val_loss: 0.1678\n",
            "Epoch 2531/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1733 - val_loss: 0.1678\n",
            "Epoch 2532/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1733 - val_loss: 0.1678\n",
            "Epoch 2533/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1733 - val_loss: 0.1677\n",
            "Epoch 2534/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1733 - val_loss: 0.1677\n",
            "Epoch 2535/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1733 - val_loss: 0.1677\n",
            "Epoch 2536/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1733 - val_loss: 0.1677\n",
            "Epoch 2537/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1732 - val_loss: 0.1677\n",
            "Epoch 2538/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1732 - val_loss: 0.1677\n",
            "Epoch 2539/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1732 - val_loss: 0.1676\n",
            "Epoch 2540/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1732 - val_loss: 0.1676\n",
            "Epoch 2541/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1732 - val_loss: 0.1676\n",
            "Epoch 2542/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1732 - val_loss: 0.1676\n",
            "Epoch 2543/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1731 - val_loss: 0.1676\n",
            "Epoch 2544/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1731 - val_loss: 0.1676\n",
            "Epoch 2545/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1731 - val_loss: 0.1675\n",
            "Epoch 2546/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1731 - val_loss: 0.1675\n",
            "Epoch 2547/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1731 - val_loss: 0.1675\n",
            "Epoch 2548/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1731 - val_loss: 0.1675\n",
            "Epoch 2549/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1731 - val_loss: 0.1675\n",
            "Epoch 2550/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1730 - val_loss: 0.1675\n",
            "Epoch 2551/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1730 - val_loss: 0.1675\n",
            "Epoch 2552/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1730 - val_loss: 0.1674\n",
            "Epoch 2553/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1730 - val_loss: 0.1674\n",
            "Epoch 2554/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1730 - val_loss: 0.1674\n",
            "Epoch 2555/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1730 - val_loss: 0.1674\n",
            "Epoch 2556/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1730 - val_loss: 0.1674\n",
            "Epoch 2557/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1729 - val_loss: 0.1674\n",
            "Epoch 2558/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1729 - val_loss: 0.1673\n",
            "Epoch 2559/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1729 - val_loss: 0.1673\n",
            "Epoch 2560/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1729 - val_loss: 0.1673\n",
            "Epoch 2561/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1729 - val_loss: 0.1673\n",
            "Epoch 2562/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1729 - val_loss: 0.1673\n",
            "Epoch 2563/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1729 - val_loss: 0.1673\n",
            "Epoch 2564/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1728 - val_loss: 0.1672\n",
            "Epoch 2565/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1728 - val_loss: 0.1672\n",
            "Epoch 2566/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1728 - val_loss: 0.1672\n",
            "Epoch 2567/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1728 - val_loss: 0.1672\n",
            "Epoch 2568/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1728 - val_loss: 0.1672\n",
            "Epoch 2569/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1728 - val_loss: 0.1672\n",
            "Epoch 2570/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1728 - val_loss: 0.1671\n",
            "Epoch 2571/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1727 - val_loss: 0.1671\n",
            "Epoch 2572/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1727 - val_loss: 0.1671\n",
            "Epoch 2573/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1727 - val_loss: 0.1671\n",
            "Epoch 2574/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1727 - val_loss: 0.1671\n",
            "Epoch 2575/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1727 - val_loss: 0.1671\n",
            "Epoch 2576/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1727 - val_loss: 0.1671\n",
            "Epoch 2577/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1727 - val_loss: 0.1670\n",
            "Epoch 2578/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1726 - val_loss: 0.1670\n",
            "Epoch 2579/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1726 - val_loss: 0.1670\n",
            "Epoch 2580/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1726 - val_loss: 0.1670\n",
            "Epoch 2581/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1726 - val_loss: 0.1670\n",
            "Epoch 2582/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1726 - val_loss: 0.1670\n",
            "Epoch 2583/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1726 - val_loss: 0.1669\n",
            "Epoch 2584/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1726 - val_loss: 0.1669\n",
            "Epoch 2585/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1725 - val_loss: 0.1669\n",
            "Epoch 2586/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1725 - val_loss: 0.1669\n",
            "Epoch 2587/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1725 - val_loss: 0.1669\n",
            "Epoch 2588/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1725 - val_loss: 0.1669\n",
            "Epoch 2589/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1725 - val_loss: 0.1669\n",
            "Epoch 2590/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1725 - val_loss: 0.1668\n",
            "Epoch 2591/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1725 - val_loss: 0.1668\n",
            "Epoch 2592/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1724 - val_loss: 0.1668\n",
            "Epoch 2593/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1724 - val_loss: 0.1668\n",
            "Epoch 2594/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1724 - val_loss: 0.1668\n",
            "Epoch 2595/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1724 - val_loss: 0.1668\n",
            "Epoch 2596/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1724 - val_loss: 0.1667\n",
            "Epoch 2597/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1724 - val_loss: 0.1667\n",
            "Epoch 2598/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1724 - val_loss: 0.1667\n",
            "Epoch 2599/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1723 - val_loss: 0.1667\n",
            "Epoch 2600/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1723 - val_loss: 0.1667\n",
            "Epoch 2601/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1723 - val_loss: 0.1667\n",
            "Epoch 2602/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1723 - val_loss: 0.1666\n",
            "Epoch 2603/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1723 - val_loss: 0.1666\n",
            "Epoch 2604/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1723 - val_loss: 0.1666\n",
            "Epoch 2605/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1723 - val_loss: 0.1666\n",
            "Epoch 2606/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1723 - val_loss: 0.1666\n",
            "Epoch 2607/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1722 - val_loss: 0.1666\n",
            "Epoch 2608/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1722 - val_loss: 0.1665\n",
            "Epoch 2609/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1722 - val_loss: 0.1665\n",
            "Epoch 2610/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1722 - val_loss: 0.1665\n",
            "Epoch 2611/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1722 - val_loss: 0.1665\n",
            "Epoch 2612/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1722 - val_loss: 0.1665\n",
            "Epoch 2613/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1722 - val_loss: 0.1665\n",
            "Epoch 2614/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1721 - val_loss: 0.1665\n",
            "Epoch 2615/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1721 - val_loss: 0.1664\n",
            "Epoch 2616/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1721 - val_loss: 0.1664\n",
            "Epoch 2617/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1721 - val_loss: 0.1664\n",
            "Epoch 2618/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1721 - val_loss: 0.1664\n",
            "Epoch 2619/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1721 - val_loss: 0.1664\n",
            "Epoch 2620/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1721 - val_loss: 0.1664\n",
            "Epoch 2621/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1720 - val_loss: 0.1664\n",
            "Epoch 2622/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1720 - val_loss: 0.1663\n",
            "Epoch 2623/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1720 - val_loss: 0.1663\n",
            "Epoch 2624/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1720 - val_loss: 0.1663\n",
            "Epoch 2625/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1720 - val_loss: 0.1663\n",
            "Epoch 2626/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1720 - val_loss: 0.1663\n",
            "Epoch 2627/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1720 - val_loss: 0.1663\n",
            "Epoch 2628/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1720 - val_loss: 0.1662\n",
            "Epoch 2629/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1719 - val_loss: 0.1662\n",
            "Epoch 2630/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1719 - val_loss: 0.1662\n",
            "Epoch 2631/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1719 - val_loss: 0.1662\n",
            "Epoch 2632/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1719 - val_loss: 0.1662\n",
            "Epoch 2633/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1719 - val_loss: 0.1662\n",
            "Epoch 2634/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1719 - val_loss: 0.1662\n",
            "Epoch 2635/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1719 - val_loss: 0.1661\n",
            "Epoch 2636/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1718 - val_loss: 0.1661\n",
            "Epoch 2637/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1718 - val_loss: 0.1661\n",
            "Epoch 2638/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1718 - val_loss: 0.1661\n",
            "Epoch 2639/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1718 - val_loss: 0.1661\n",
            "Epoch 2640/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1718 - val_loss: 0.1661\n",
            "Epoch 2641/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1718 - val_loss: 0.1661\n",
            "Epoch 2642/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1718 - val_loss: 0.1660\n",
            "Epoch 2643/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1718 - val_loss: 0.1660\n",
            "Epoch 2644/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1717 - val_loss: 0.1660\n",
            "Epoch 2645/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1717 - val_loss: 0.1660\n",
            "Epoch 2646/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1717 - val_loss: 0.1660\n",
            "Epoch 2647/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1717 - val_loss: 0.1660\n",
            "Epoch 2648/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1717 - val_loss: 0.1659\n",
            "Epoch 2649/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1717 - val_loss: 0.1659\n",
            "Epoch 2650/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1717 - val_loss: 0.1659\n",
            "Epoch 2651/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1717 - val_loss: 0.1659\n",
            "Epoch 2652/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1716 - val_loss: 0.1659\n",
            "Epoch 2653/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1716 - val_loss: 0.1659\n",
            "Epoch 2654/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1716 - val_loss: 0.1659\n",
            "Epoch 2655/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1716 - val_loss: 0.1658\n",
            "Epoch 2656/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1716 - val_loss: 0.1658\n",
            "Epoch 2657/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1716 - val_loss: 0.1658\n",
            "Epoch 2658/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1716 - val_loss: 0.1658\n",
            "Epoch 2659/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1715 - val_loss: 0.1658\n",
            "Epoch 2660/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1715 - val_loss: 0.1658\n",
            "Epoch 2661/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1715 - val_loss: 0.1657\n",
            "Epoch 2662/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1715 - val_loss: 0.1657\n",
            "Epoch 2663/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1715 - val_loss: 0.1657\n",
            "Epoch 2664/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1715 - val_loss: 0.1657\n",
            "Epoch 2665/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1715 - val_loss: 0.1657\n",
            "Epoch 2666/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1715 - val_loss: 0.1657\n",
            "Epoch 2667/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1714 - val_loss: 0.1657\n",
            "Epoch 2668/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1714 - val_loss: 0.1656\n",
            "Epoch 2669/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1714 - val_loss: 0.1656\n",
            "Epoch 2670/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1714 - val_loss: 0.1656\n",
            "Epoch 2671/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1714 - val_loss: 0.1656\n",
            "Epoch 2672/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1714 - val_loss: 0.1656\n",
            "Epoch 2673/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1714 - val_loss: 0.1656\n",
            "Epoch 2674/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1714 - val_loss: 0.1656\n",
            "Epoch 2675/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1713 - val_loss: 0.1655\n",
            "Epoch 2676/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1713 - val_loss: 0.1655\n",
            "Epoch 2677/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1713 - val_loss: 0.1655\n",
            "Epoch 2678/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1713 - val_loss: 0.1655\n",
            "Epoch 2679/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1713 - val_loss: 0.1655\n",
            "Epoch 2680/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1713 - val_loss: 0.1655\n",
            "Epoch 2681/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1713 - val_loss: 0.1655\n",
            "Epoch 2682/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1713 - val_loss: 0.1654\n",
            "Epoch 2683/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1712 - val_loss: 0.1654\n",
            "Epoch 2684/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1712 - val_loss: 0.1654\n",
            "Epoch 2685/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1712 - val_loss: 0.1654\n",
            "Epoch 2686/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1712 - val_loss: 0.1654\n",
            "Epoch 2687/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1712 - val_loss: 0.1654\n",
            "Epoch 2688/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1712 - val_loss: 0.1654\n",
            "Epoch 2689/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1712 - val_loss: 0.1653\n",
            "Epoch 2690/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1712 - val_loss: 0.1653\n",
            "Epoch 2691/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1711 - val_loss: 0.1653\n",
            "Epoch 2692/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1711 - val_loss: 0.1653\n",
            "Epoch 2693/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1711 - val_loss: 0.1653\n",
            "Epoch 2694/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1711 - val_loss: 0.1653\n",
            "Epoch 2695/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1711 - val_loss: 0.1653\n",
            "Epoch 2696/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1711 - val_loss: 0.1652\n",
            "Epoch 2697/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1711 - val_loss: 0.1652\n",
            "Epoch 2698/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1711 - val_loss: 0.1652\n",
            "Epoch 2699/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1710 - val_loss: 0.1652\n",
            "Epoch 2700/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1710 - val_loss: 0.1652\n",
            "Epoch 2701/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1710 - val_loss: 0.1652\n",
            "Epoch 2702/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1710 - val_loss: 0.1652\n",
            "Epoch 2703/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1710 - val_loss: 0.1651\n",
            "Epoch 2704/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1710 - val_loss: 0.1651\n",
            "Epoch 2705/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1710 - val_loss: 0.1651\n",
            "Epoch 2706/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1710 - val_loss: 0.1651\n",
            "Epoch 2707/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1709 - val_loss: 0.1651\n",
            "Epoch 2708/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1709 - val_loss: 0.1651\n",
            "Epoch 2709/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1709 - val_loss: 0.1651\n",
            "Epoch 2710/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1709 - val_loss: 0.1650\n",
            "Epoch 2711/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1709 - val_loss: 0.1650\n",
            "Epoch 2712/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1709 - val_loss: 0.1650\n",
            "Epoch 2713/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1709 - val_loss: 0.1650\n",
            "Epoch 2714/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1709 - val_loss: 0.1650\n",
            "Epoch 2715/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1708 - val_loss: 0.1650\n",
            "Epoch 2716/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1708 - val_loss: 0.1650\n",
            "Epoch 2717/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1708 - val_loss: 0.1649\n",
            "Epoch 2718/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1708 - val_loss: 0.1649\n",
            "Epoch 2719/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1708 - val_loss: 0.1649\n",
            "Epoch 2720/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1708 - val_loss: 0.1649\n",
            "Epoch 2721/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1708 - val_loss: 0.1649\n",
            "Epoch 2722/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1708 - val_loss: 0.1649\n",
            "Epoch 2723/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1707 - val_loss: 0.1649\n",
            "Epoch 2724/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1707 - val_loss: 0.1649\n",
            "Epoch 2725/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1707 - val_loss: 0.1648\n",
            "Epoch 2726/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1707 - val_loss: 0.1648\n",
            "Epoch 2727/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1707 - val_loss: 0.1648\n",
            "Epoch 2728/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1707 - val_loss: 0.1648\n",
            "Epoch 2729/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1707 - val_loss: 0.1648\n",
            "Epoch 2730/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1707 - val_loss: 0.1648\n",
            "Epoch 2731/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1706 - val_loss: 0.1648\n",
            "Epoch 2732/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1706 - val_loss: 0.1647\n",
            "Epoch 2733/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1706 - val_loss: 0.1647\n",
            "Epoch 2734/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1706 - val_loss: 0.1647\n",
            "Epoch 2735/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1706 - val_loss: 0.1647\n",
            "Epoch 2736/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1706 - val_loss: 0.1647\n",
            "Epoch 2737/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1706 - val_loss: 0.1647\n",
            "Epoch 2738/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1706 - val_loss: 0.1647\n",
            "Epoch 2739/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1705 - val_loss: 0.1646\n",
            "Epoch 2740/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1705 - val_loss: 0.1646\n",
            "Epoch 2741/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1705 - val_loss: 0.1646\n",
            "Epoch 2742/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1705 - val_loss: 0.1646\n",
            "Epoch 2743/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1705 - val_loss: 0.1646\n",
            "Epoch 2744/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1705 - val_loss: 0.1646\n",
            "Epoch 2745/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1705 - val_loss: 0.1646\n",
            "Epoch 2746/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1705 - val_loss: 0.1646\n",
            "Epoch 2747/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1704 - val_loss: 0.1645\n",
            "Epoch 2748/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1704 - val_loss: 0.1645\n",
            "Epoch 2749/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1704 - val_loss: 0.1645\n",
            "Epoch 2750/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1704 - val_loss: 0.1645\n",
            "Epoch 2751/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1704 - val_loss: 0.1645\n",
            "Epoch 2752/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1704 - val_loss: 0.1645\n",
            "Epoch 2753/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1704 - val_loss: 0.1645\n",
            "Epoch 2754/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1704 - val_loss: 0.1644\n",
            "Epoch 2755/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1704 - val_loss: 0.1644\n",
            "Epoch 2756/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1703 - val_loss: 0.1644\n",
            "Epoch 2757/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1703 - val_loss: 0.1644\n",
            "Epoch 2758/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1703 - val_loss: 0.1644\n",
            "Epoch 2759/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1703 - val_loss: 0.1644\n",
            "Epoch 2760/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1703 - val_loss: 0.1644\n",
            "Epoch 2761/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1703 - val_loss: 0.1644\n",
            "Epoch 2762/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1703 - val_loss: 0.1643\n",
            "Epoch 2763/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1703 - val_loss: 0.1643\n",
            "Epoch 2764/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1702 - val_loss: 0.1643\n",
            "Epoch 2765/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1702 - val_loss: 0.1643\n",
            "Epoch 2766/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1702 - val_loss: 0.1643\n",
            "Epoch 2767/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1702 - val_loss: 0.1643\n",
            "Epoch 2768/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1702 - val_loss: 0.1643\n",
            "Epoch 2769/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1702 - val_loss: 0.1642\n",
            "Epoch 2770/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1702 - val_loss: 0.1642\n",
            "Epoch 2771/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1702 - val_loss: 0.1642\n",
            "Epoch 2772/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1701 - val_loss: 0.1642\n",
            "Epoch 2773/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1701 - val_loss: 0.1642\n",
            "Epoch 2774/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1701 - val_loss: 0.1642\n",
            "Epoch 2775/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1701 - val_loss: 0.1642\n",
            "Epoch 2776/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1701 - val_loss: 0.1642\n",
            "Epoch 2777/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1701 - val_loss: 0.1641\n",
            "Epoch 2778/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1701 - val_loss: 0.1641\n",
            "Epoch 2779/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1701 - val_loss: 0.1641\n",
            "Epoch 2780/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1701 - val_loss: 0.1641\n",
            "Epoch 2781/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1700 - val_loss: 0.1641\n",
            "Epoch 2782/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1700 - val_loss: 0.1641\n",
            "Epoch 2783/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1700 - val_loss: 0.1641\n",
            "Epoch 2784/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1700 - val_loss: 0.1641\n",
            "Epoch 2785/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1700 - val_loss: 0.1640\n",
            "Epoch 2786/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1700 - val_loss: 0.1640\n",
            "Epoch 2787/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1700 - val_loss: 0.1640\n",
            "Epoch 2788/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1700 - val_loss: 0.1640\n",
            "Epoch 2789/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1699 - val_loss: 0.1640\n",
            "Epoch 2790/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1699 - val_loss: 0.1640\n",
            "Epoch 2791/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1699 - val_loss: 0.1640\n",
            "Epoch 2792/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1699 - val_loss: 0.1640\n",
            "Epoch 2793/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1699 - val_loss: 0.1639\n",
            "Epoch 2794/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1699 - val_loss: 0.1639\n",
            "Epoch 2795/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1699 - val_loss: 0.1639\n",
            "Epoch 2796/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1699 - val_loss: 0.1639\n",
            "Epoch 2797/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1699 - val_loss: 0.1639\n",
            "Epoch 2798/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1698 - val_loss: 0.1639\n",
            "Epoch 2799/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1698 - val_loss: 0.1639\n",
            "Epoch 2800/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1698 - val_loss: 0.1639\n",
            "Epoch 2801/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1698 - val_loss: 0.1638\n",
            "Epoch 2802/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1698 - val_loss: 0.1638\n",
            "Epoch 2803/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1698 - val_loss: 0.1638\n",
            "Epoch 2804/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1698 - val_loss: 0.1638\n",
            "Epoch 2805/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1698 - val_loss: 0.1638\n",
            "Epoch 2806/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1698 - val_loss: 0.1638\n",
            "Epoch 2807/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1697 - val_loss: 0.1638\n",
            "Epoch 2808/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1697 - val_loss: 0.1638\n",
            "Epoch 2809/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1697 - val_loss: 0.1637\n",
            "Epoch 2810/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1697 - val_loss: 0.1637\n",
            "Epoch 2811/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1697 - val_loss: 0.1637\n",
            "Epoch 2812/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1697 - val_loss: 0.1637\n",
            "Epoch 2813/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1697 - val_loss: 0.1637\n",
            "Epoch 2814/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1697 - val_loss: 0.1637\n",
            "Epoch 2815/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1696 - val_loss: 0.1637\n",
            "Epoch 2816/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1696 - val_loss: 0.1637\n",
            "Epoch 2817/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1696 - val_loss: 0.1636\n",
            "Epoch 2818/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1696 - val_loss: 0.1636\n",
            "Epoch 2819/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1696 - val_loss: 0.1636\n",
            "Epoch 2820/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1696 - val_loss: 0.1636\n",
            "Epoch 2821/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1696 - val_loss: 0.1636\n",
            "Epoch 2822/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1696 - val_loss: 0.1636\n",
            "Epoch 2823/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1696 - val_loss: 0.1636\n",
            "Epoch 2824/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1695 - val_loss: 0.1636\n",
            "Epoch 2825/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1695 - val_loss: 0.1635\n",
            "Epoch 2826/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1695 - val_loss: 0.1635\n",
            "Epoch 2827/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1695 - val_loss: 0.1635\n",
            "Epoch 2828/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1695 - val_loss: 0.1635\n",
            "Epoch 2829/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1695 - val_loss: 0.1635\n",
            "Epoch 2830/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1695 - val_loss: 0.1635\n",
            "Epoch 2831/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1695 - val_loss: 0.1635\n",
            "Epoch 2832/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1695 - val_loss: 0.1635\n",
            "Epoch 2833/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1694 - val_loss: 0.1634\n",
            "Epoch 2834/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1694 - val_loss: 0.1634\n",
            "Epoch 2835/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1694 - val_loss: 0.1634\n",
            "Epoch 2836/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1694 - val_loss: 0.1634\n",
            "Epoch 2837/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1694 - val_loss: 0.1634\n",
            "Epoch 2838/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1694 - val_loss: 0.1634\n",
            "Epoch 2839/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1694 - val_loss: 0.1634\n",
            "Epoch 2840/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1694 - val_loss: 0.1634\n",
            "Epoch 2841/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1694 - val_loss: 0.1633\n",
            "Epoch 2842/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1693 - val_loss: 0.1633\n",
            "Epoch 2843/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1693 - val_loss: 0.1633\n",
            "Epoch 2844/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1693 - val_loss: 0.1633\n",
            "Epoch 2845/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1693 - val_loss: 0.1633\n",
            "Epoch 2846/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1693 - val_loss: 0.1633\n",
            "Epoch 2847/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1693 - val_loss: 0.1633\n",
            "Epoch 2848/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1693 - val_loss: 0.1633\n",
            "Epoch 2849/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1693 - val_loss: 0.1633\n",
            "Epoch 2850/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1693 - val_loss: 0.1632\n",
            "Epoch 2851/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1692 - val_loss: 0.1632\n",
            "Epoch 2852/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1692 - val_loss: 0.1632\n",
            "Epoch 2853/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1692 - val_loss: 0.1632\n",
            "Epoch 2854/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1692 - val_loss: 0.1632\n",
            "Epoch 2855/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1692 - val_loss: 0.1632\n",
            "Epoch 2856/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1692 - val_loss: 0.1632\n",
            "Epoch 2857/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1692 - val_loss: 0.1632\n",
            "Epoch 2858/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1692 - val_loss: 0.1631\n",
            "Epoch 2859/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1692 - val_loss: 0.1631\n",
            "Epoch 2860/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1691 - val_loss: 0.1631\n",
            "Epoch 2861/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1691 - val_loss: 0.1631\n",
            "Epoch 2862/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1691 - val_loss: 0.1631\n",
            "Epoch 2863/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1691 - val_loss: 0.1631\n",
            "Epoch 2864/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1691 - val_loss: 0.1631\n",
            "Epoch 2865/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1691 - val_loss: 0.1631\n",
            "Epoch 2866/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1691 - val_loss: 0.1630\n",
            "Epoch 2867/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1691 - val_loss: 0.1630\n",
            "Epoch 2868/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1691 - val_loss: 0.1630\n",
            "Epoch 2869/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1691 - val_loss: 0.1630\n",
            "Epoch 2870/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1690 - val_loss: 0.1630\n",
            "Epoch 2871/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1690 - val_loss: 0.1630\n",
            "Epoch 2872/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1690 - val_loss: 0.1630\n",
            "Epoch 2873/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1690 - val_loss: 0.1630\n",
            "Epoch 2874/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1690 - val_loss: 0.1630\n",
            "Epoch 2875/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1690 - val_loss: 0.1629\n",
            "Epoch 2876/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1690 - val_loss: 0.1629\n",
            "Epoch 2877/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1690 - val_loss: 0.1629\n",
            "Epoch 2878/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1690 - val_loss: 0.1629\n",
            "Epoch 2879/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1689 - val_loss: 0.1629\n",
            "Epoch 2880/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1689 - val_loss: 0.1629\n",
            "Epoch 2881/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1689 - val_loss: 0.1629\n",
            "Epoch 2882/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1689 - val_loss: 0.1629\n",
            "Epoch 2883/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1689 - val_loss: 0.1628\n",
            "Epoch 2884/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1689 - val_loss: 0.1628\n",
            "Epoch 2885/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1689 - val_loss: 0.1628\n",
            "Epoch 2886/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1689 - val_loss: 0.1628\n",
            "Epoch 2887/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1689 - val_loss: 0.1628\n",
            "Epoch 2888/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1688 - val_loss: 0.1628\n",
            "Epoch 2889/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1688 - val_loss: 0.1628\n",
            "Epoch 2890/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1688 - val_loss: 0.1628\n",
            "Epoch 2891/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1688 - val_loss: 0.1628\n",
            "Epoch 2892/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1688 - val_loss: 0.1628\n",
            "Epoch 2893/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1688 - val_loss: 0.1627\n",
            "Epoch 2894/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1688 - val_loss: 0.1627\n",
            "Epoch 2895/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1688 - val_loss: 0.1627\n",
            "Epoch 2896/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1688 - val_loss: 0.1627\n",
            "Epoch 2897/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1688 - val_loss: 0.1627\n",
            "Epoch 2898/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1687 - val_loss: 0.1627\n",
            "Epoch 2899/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1687 - val_loss: 0.1627\n",
            "Epoch 2900/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1687 - val_loss: 0.1627\n",
            "Epoch 2901/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1687 - val_loss: 0.1626\n",
            "Epoch 2902/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1687 - val_loss: 0.1626\n",
            "Epoch 2903/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1687 - val_loss: 0.1626\n",
            "Epoch 2904/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1687 - val_loss: 0.1626\n",
            "Epoch 2905/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1687 - val_loss: 0.1626\n",
            "Epoch 2906/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1687 - val_loss: 0.1626\n",
            "Epoch 2907/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1686 - val_loss: 0.1626\n",
            "Epoch 2908/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1686 - val_loss: 0.1626\n",
            "Epoch 2909/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1686 - val_loss: 0.1626\n",
            "Epoch 2910/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1686 - val_loss: 0.1625\n",
            "Epoch 2911/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1686 - val_loss: 0.1625\n",
            "Epoch 2912/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1686 - val_loss: 0.1625\n",
            "Epoch 2913/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1686 - val_loss: 0.1625\n",
            "Epoch 2914/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1686 - val_loss: 0.1625\n",
            "Epoch 2915/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1686 - val_loss: 0.1625\n",
            "Epoch 2916/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1685 - val_loss: 0.1625\n",
            "Epoch 2917/3000\n",
            "133/133 [==============================] - 0s 2ms/step - loss: 0.1685 - val_loss: 0.1625\n",
            "Epoch 2918/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1685 - val_loss: 0.1625\n",
            "Epoch 2919/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1685 - val_loss: 0.1624\n",
            "Epoch 2920/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1685 - val_loss: 0.1624\n",
            "Epoch 2921/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1685 - val_loss: 0.1624\n",
            "Epoch 2922/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1685 - val_loss: 0.1624\n",
            "Epoch 2923/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1685 - val_loss: 0.1624\n",
            "Epoch 2924/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1685 - val_loss: 0.1624\n",
            "Epoch 2925/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1685 - val_loss: 0.1624\n",
            "Epoch 2926/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1684 - val_loss: 0.1624\n",
            "Epoch 2927/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1684 - val_loss: 0.1624\n",
            "Epoch 2928/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1684 - val_loss: 0.1623\n",
            "Epoch 2929/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1684 - val_loss: 0.1623\n",
            "Epoch 2930/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1684 - val_loss: 0.1623\n",
            "Epoch 2931/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1684 - val_loss: 0.1623\n",
            "Epoch 2932/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1684 - val_loss: 0.1623\n",
            "Epoch 2933/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1684 - val_loss: 0.1623\n",
            "Epoch 2934/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1684 - val_loss: 0.1623\n",
            "Epoch 2935/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1684 - val_loss: 0.1623\n",
            "Epoch 2936/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1683 - val_loss: 0.1623\n",
            "Epoch 2937/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1683 - val_loss: 0.1623\n",
            "Epoch 2938/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1683 - val_loss: 0.1622\n",
            "Epoch 2939/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1683 - val_loss: 0.1622\n",
            "Epoch 2940/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1683 - val_loss: 0.1622\n",
            "Epoch 2941/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1683 - val_loss: 0.1622\n",
            "Epoch 2942/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1683 - val_loss: 0.1622\n",
            "Epoch 2943/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1683 - val_loss: 0.1622\n",
            "Epoch 2944/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1683 - val_loss: 0.1622\n",
            "Epoch 2945/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1682 - val_loss: 0.1622\n",
            "Epoch 2946/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1682 - val_loss: 0.1622\n",
            "Epoch 2947/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1682 - val_loss: 0.1621\n",
            "Epoch 2948/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1682 - val_loss: 0.1621\n",
            "Epoch 2949/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1682 - val_loss: 0.1621\n",
            "Epoch 2950/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1682 - val_loss: 0.1621\n",
            "Epoch 2951/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1682 - val_loss: 0.1621\n",
            "Epoch 2952/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1682 - val_loss: 0.1621\n",
            "Epoch 2953/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1682 - val_loss: 0.1621\n",
            "Epoch 2954/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1682 - val_loss: 0.1621\n",
            "Epoch 2955/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1681 - val_loss: 0.1621\n",
            "Epoch 2956/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1681 - val_loss: 0.1621\n",
            "Epoch 2957/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1681 - val_loss: 0.1620\n",
            "Epoch 2958/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1681 - val_loss: 0.1620\n",
            "Epoch 2959/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1681 - val_loss: 0.1620\n",
            "Epoch 2960/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1681 - val_loss: 0.1620\n",
            "Epoch 2961/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1681 - val_loss: 0.1620\n",
            "Epoch 2962/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1681 - val_loss: 0.1620\n",
            "Epoch 2963/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1681 - val_loss: 0.1620\n",
            "Epoch 2964/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1681 - val_loss: 0.1620\n",
            "Epoch 2965/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1680 - val_loss: 0.1620\n",
            "Epoch 2966/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1680 - val_loss: 0.1619\n",
            "Epoch 2967/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1680 - val_loss: 0.1619\n",
            "Epoch 2968/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1680 - val_loss: 0.1619\n",
            "Epoch 2969/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1680 - val_loss: 0.1619\n",
            "Epoch 2970/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1680 - val_loss: 0.1619\n",
            "Epoch 2971/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1680 - val_loss: 0.1619\n",
            "Epoch 2972/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1680 - val_loss: 0.1619\n",
            "Epoch 2973/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1680 - val_loss: 0.1619\n",
            "Epoch 2974/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1680 - val_loss: 0.1619\n",
            "Epoch 2975/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1679 - val_loss: 0.1619\n",
            "Epoch 2976/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1679 - val_loss: 0.1619\n",
            "Epoch 2977/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1679 - val_loss: 0.1618\n",
            "Epoch 2978/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1679 - val_loss: 0.1618\n",
            "Epoch 2979/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1679 - val_loss: 0.1618\n",
            "Epoch 2980/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1679 - val_loss: 0.1618\n",
            "Epoch 2981/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1679 - val_loss: 0.1618\n",
            "Epoch 2982/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1679 - val_loss: 0.1618\n",
            "Epoch 2983/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1679 - val_loss: 0.1618\n",
            "Epoch 2984/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1679 - val_loss: 0.1618\n",
            "Epoch 2985/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1679 - val_loss: 0.1618\n",
            "Epoch 2986/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1678 - val_loss: 0.1618\n",
            "Epoch 2987/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1678 - val_loss: 0.1617\n",
            "Epoch 2988/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1678 - val_loss: 0.1617\n",
            "Epoch 2989/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1678 - val_loss: 0.1617\n",
            "Epoch 2990/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1678 - val_loss: 0.1617\n",
            "Epoch 2991/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1678 - val_loss: 0.1617\n",
            "Epoch 2992/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1678 - val_loss: 0.1617\n",
            "Epoch 2993/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1678 - val_loss: 0.1617\n",
            "Epoch 2994/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1678 - val_loss: 0.1617\n",
            "Epoch 2995/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1678 - val_loss: 0.1617\n",
            "Epoch 2996/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1677 - val_loss: 0.1617\n",
            "Epoch 2997/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1677 - val_loss: 0.1616\n",
            "Epoch 2998/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1677 - val_loss: 0.1616\n",
            "Epoch 2999/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1677 - val_loss: 0.1616\n",
            "Epoch 3000/3000\n",
            "133/133 [==============================] - 0s 1ms/step - loss: 0.1677 - val_loss: 0.1616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW-eV7lWsBLT"
      },
      "source": [
        "## **PLOTTING TRAINING AND VALIDATION LOSSES**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_Y-VHqbsBLU",
        "outputId": "b20ca5dd-287e-4c9b-c23a-649631fce160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3ac7a8b080>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQYRIUaksBLW"
      },
      "source": [
        "# **MODEL PREDICTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfxqTwv0c7J0",
        "outputId": "31176453-890c-494c-c86b-3ddd5d15d1ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "preds_on_trained = tf_model.predict(input_parameters_test)\n",
        "original_distribution_trained_predictions = convert_label_value(preds_on_trained[2])\n",
        "print(original_distribution_trained_predictions)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDClL_9NfgwO"
      },
      "source": [
        "## **PLOTTING PREDICTIONS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qFniJAZsBLW",
        "outputId": "43188a70-901e-4b5f-f794-06d4b31bb5fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "plt.plot(preds_on_trained, color = \"green\")\n",
        "plt.plot(preds_on_untrained, color = \"yellow\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3abbddf2b0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOxdd5gURfp+awMLS45KkCCIAcVEUk/OjHrGO8/TU09PFAOiiOdPPc+AnvFO8VCRQzFgQs8IggJGREkrqGQlw5KWuAHYWL8/emqmuruqu6q7enZY+n2efXamp7qqurvqq7ff+uorQilFjBgxYsSo+8iq7QrEiBEjRoz0IDb4MWLEiLGfIDb4MWLEiLGfIDb4MWLEiLGfIDb4MWLEiLGfIKe2K+CFVq1a0c6dO9d2NWLEiBFjn8EPP/ywlVLaWvRbRhv8zp07o6CgoLarESNGjBj7DAgha2S/xZJOjBgxYuwniA1+jBgxYuwniA1+jBgxYuwniA1+jBgxYuwniA1+jBgxYuwniA1+jBgxYuwniA1+jBgxYuwniA1+jIxDSXkJ3l/8fm1XI0Yt4pNfPkFhcWFtV6POITb4MTIO1064Fpf87xIsLlpc21WJUUs4/+3z0felvrVdjTqH2ODHyDis3rkaAFBWUVa7FYlRqygsiRm+acQGP0aMGDH2E8QGP0aMGDH2E8QGP0aMGBmFeJ/t6BAb/BgxYmQUKGKDHxVigx8jRsSYv3F+7HGkgZjhR4fY4MfIONS1Dn/cmOPQY1QP1/FlW5ehsrqyFmqU2YgZfnSIDX6MGLWAtbvW4rDnD8P/Tfu/2q5KxqGuDfiZhNjgx8g4EEJquwqRY0vZFgDA9LXTa7kmmYeY4UeH2ODHiFELYCyWoO4PbrqIGX50CG3wCSEHEUK+IoQsJoQsIoTcJkhDCCEjCSHLCSE/E0KOC1tujBgxYsTQg4lNzKsA3EEpnUcIaQzgB0LINEop75ZwDoBDEn99AbyQ+B8jRowYNsSSTnQIzfAppRsppfMSn0sALAHQ3pHsQgDjqIVZAJoRQtqGLTtGjH0VzKjtD/MVuoglnehgVMMnhHQGcCyA2Y6f2gNYx31fD/egwPIYRAgpIIQUFBUVmazefo0HvnoA7y1+r7arEcOBWMN3I2b40cGYwSeENALwPoChlNLioPlQSsdQSntRSnu1bt3aVPUCo7K6Eu2fbr/PG8uHpj+EP/7vj0byqqqpwoLNC4zktb8ik1jssCnD8NWqr2q7Gklk0r0xiV+3/Vrr12bE4BNCcmEZ+zcppR8IkhQCOIj73iFxLOOxdfdWbCjZgFsm31LbVckY3Pflfeg5uieWFC2p7arss8gkSWfErBE4bdxptV2NJOoiw5+/cT66P9cdT818qlbrYcJLhwAYC2AJpfRpSbIJAP6S8NbpB2AXpXRj2LLTAdYh62IjDIpZhbMAAJtKN9VyTfZ9xJKOG7XNgqPAyh0rAQAz18+s1XqY8NI5CcBVABYQQn5MHPs7gI4AQCkdDWAygHMBLAewG8BfDZSbFrAOWRcbYaZif7jX+8M1BkVdJFeZck2hDT6ldAbgTVOo1boHhy2rNhAz/Bgx0ot4MIwO8UpbH8QMP/3IBF27rmP418Px34L/1nY1hKiL5CpTpLvY4PugrhufnXt3YnTB6Iwa0EzXZcbaGVi1Y5XRPMOitidtH/zmQdw46cZaKdsPmdQWTSFTBrHY4PsgyfAz5IGZxvUTr8dNk27CnMI5tV2VyHDyKyfj4JEHh86nhtZg1NxR2Fu110CtLGQK88sk1NW+BtT+844Nvg8YA6uhNbVck2jAojbuqdpTyzVJIVPfqt5d9C4GTx6M4V8PD51XXWSxphDfm+gQG3wHKqorcMm7lyR3KIobX/qRqfd8195dAIDte7aHzsuUpLO4aDGmrZgWuj6ZhLrM8Gv72ky4ZdYpFGwowPtL3seGkg34fuD3yeOZaoR0UV5VjrycPNfx2n7V3BfAOmsWMceTwt53tpMWfaButE+g7vQ1hhpag8LizFhnGjN8B5h043THrG1J557P78GQyUNC5zPok0Ha58zbOC+5cCQsvl/3PbIfyk5KSSJkqqTD2oBJgx/DDV0WvKdyT633Ty88Mv0RDJ0yFEDtE6u45Trg3JgiU9jG4989jufmPhc6n2/XfKt9zvFjjkfXkV1Dlw0AT818CjW0xrMemXLPnXCSgTDI1Gvc11BdU438R/Nx66e3+qatqqnC5tLNaaiVHVNXTk17mTLEBt8B52s7+17b2hvDnso9oYxFdla2wdroIx2GjlKKsfPGoqS8xHi+gFmWlqlvMzr4ZvU3+PTXT43l59VGVu9cjR17diS/V9ZYm8C/OO9F33xv/fRWHPjUgcbaRVlFGVbvXO2brrZZPY/Y4DsgY3G6hmrG2hl4/afXjdWLIf/R/FABmDKl8UVp6GasnYHrJl6HIZ+Gl8B4mPSdlxGIHzf9iIvfuRiV1ZWhy1Cqh4EB+JTXTsG5b51roDYWvMhVl/90Sc5b8FBp1x8u/RAAUFpRGrxyHAa8MQBd/tPFSF7pQmzwHWAdIMnwaTCGf/IrJ+MvH/3Flffuyt2h6zh+4fjA59a2/qxzH4Ma1rLKMgDmg7uZ1PBlbwtXfnAlPlr6EZZtWxa6DIbK6kpUVFe4ys5U+NVvY2kq7mJtXst3676rtbKDIjb4Djg7dVLSMdCwXp7/Mho+2hArtq8IlY/IEG7dvRWHP384lm31NhSqRnTZ1mWRskwVRhb0nke1WM6owZfULfmGafBN7IhRRyDvnynPLCaDeNWjNqFTp0ysfyYjNvgOyDqciYb1wVJrq4ClW5eGykdkDD5e+jGWbl2KJ7970vNcmbHir2998Xoc9vxhuGPqHaHqWdswzf7Cavi83pvMyykdRuD6uXz7ctt3fiDPRLavUyeTE+n7A2KD74BTp01KOhnUMUSNW3VAchoSkfEqKrO2lpy+ZnqA2iXqQynKKsoCnx8GUUU4Davh83qvjFikw4Dx8k4mQovhZ1C/VEFtD0yxwXfApeEb9NIx1TjDvO6rMEcTk5P3f3U/Gj3WyOURoXIPwnaKqFxq0yHpONtfFMh4SScIwzckgd0x5Q6Q4WaNcm0beR77vcF/Z+E7tldtqaRj0HiENmgihi+RCFznamjnP276EfmP5Et/98J/Zv8HAFyBxlQGk7D3OiqGb9LgyxYKmShj2oppnuEW0uUBFBQ6z830gqunZz0dSb4Mtf1GYmpP25cJIVsIIQslv59CCNlFCPkx8Xe/iXJN4LL3L0PvF3snv0slHYPGI7RB8zDafgbdaUhE18UfCxpUraSixFVecXkxJiyboFTPMIiK4Zv0w5dJNyYY61lvnIWz3jhL+ruN4UdogAZNHIRWT7bSPk+nTqb65ZKiJRj307jk9+qaaiP5ZhpMxdJ5FcBzAMZ5pPmWUnqeofKMYuvurcnPMi8dEzD1ahcmH9m5vIFRZTcq9eDv3zervzGWr8r5mabh2/KSGLV0xMnnGb7qxPzUFVOxaMsi3H7C7crlqCyGEiEIw9e5X6L8e4zqYTteTauRi1zlPL3A9y2veg6eNBjvLXkPm/8W3WpgIwyfUjodQPgQghkA2St1bb+K8RCxv6CTtiKYvFY+L9VOaeoNKBM1fFYnv0nbdGn4z855VumcAW8MwLCpwwAAT8x4As/OVjsvCPjntrl0M8hwgk9++USYVnQfL3vvsuSbpHKZsL+9VdVUaZ1vAqMKRmFL2ZZIbU06NfwTCCE/EUI+JYS4l8olQAgZRAgpIIQUFBUVRVoh0Y2VxdLJpOBMYdifzqStCajm9e6id5PeQWERFTs2IbewPPwkHV2Dv7dqL26YeIPSPQyr4d/9xd249TP/2DVBwbeZeRvnAQCen/u8OK2jD5dVlOGdRe/gwvEXBiqb3Xcdg2/aQO/Yu8M/UUCky+DPA9CJUno0gGcBfCRLSCkdQyntRSnt1bp161CFVtdUY/CkwdLt7bz06ygknXR46fgZOxU//CgYxqbSTTZjxNezqKwIf3rvT7hg/AVGyopq4ZWOB81L817C+uL1ruPMkPh56eg+g/ELx2PMvDG46/O7fNNmvFsmd+1O5u2Ec+BkUV1bNGghzd+r/7Bnq6PhszpOXTEVS4qWuMtTJCB52dbiOFG7MYW0GHxKaTGltDTxeTKAXEKI/myOJmatn4VRBaNw5YdXyurlOiaNpZNBWn4oDd/R2MPIQypg97jtU21x7YRrhWmYAVqzc42RMp0T7qagqq8Xlxfj+onX47TXTnP9Vk0tQ+In6eg+A503UVaHdKGG1mi9VYjIh+yeO6+XGfwOTToo5e9EEIbP6jDgjQE4YtQRyuc5cWCjAwGYDwnCIy0GnxByIEk8MUJIn0S529JRtheEDF8hPDIZTvDg1w9GWjcvCI10op4vznvR04847Rq+guGSdeagA08mMHwAWLPLPYAxQyIzzIGvWYMEpFuevHD8haj3z3qBzvW7H87fi8uLAQCN6zV2pdWR4mpD0snJsnxoovQQMuWW+TaAmQAOJYSsJ4QMJITcSAi5MZHkEgALCSE/ARgJ4DKaAbOgXgzfT9IZ/k34fU2DYl/S8GWI8s0iKoavquGzckXSCevMsrolGX7Auqvcw3R3PdmEqwxCkuUn6TgGeX5iOpmvyr1JpNF5C4rKGywKGHHLpJRe7vP7c7DcNtMKXXYA7Bu7GkW90tYkA1RaWSu5nsBGL4K1E4C6C6DX/XMyfNmkrW7d//rxX5XTZpIDggg680muHeoS6b0Yuso6Fh2Gf/VHV+PcbmrhoaMMGqiCzLVqBuHHDnjIFl4FxcaSjcYnySJn+GmQdHR9+HUQliXLoBrYzKvejDmanrR1nu+FjDf4oklbmeznuF52bV4G2+v5sN90DP74heNdodB56BK0KBn+fmHw/ToXAOzcu9N2TCbp6HbEdk+3wzUfXeNZD12IDI5q3lEaWhF2V+7GV6u+UkprykBHtUuZ6kpbLYYvmbQNCh3ZQhUPf/Nw0OoEgnDSVpG0eRlslfUZKm8IYVDbktt+YfBl4G/+sCnWopIfN/0IQN44ghgRttOOKUQePE2xwamku/GTG3HaOLe3Cg/ZytigDb82GD6lFAUbCmzli8A0fNOSjg50BpWRs0fi/q/TGwlFqOH7eOk4+6vIYOvc09oIrRDVCnEe+4XBV9GI91RZe8U++b0VT17UwL5Z/U0gI5JNsj3rkU6o3Au/BqcjKS3cIgyvpFangA2/NjT80QWj0fvF3vj010+VGL5faIUoJR3VvIvKinDbZ7cFqkcY2Bi+5jxcWEmHwSTD59tLrOHXIpwPnt86TSTpnPLaKUJXOz+Y3jhcd0KZN0DpnrSVIcjgRynV0qhNdJxxP41LxgDy8tJhA9vKHSs9y/Xzw49qsOKh+nyZm6AMG0s24roJ15mokg2BvHQc7NjT4Cu0i9oIrcCQ8V46mQq/B2tjtZTil22/JL8797RlYFq/DhjDNwWv8MhObNu9Da3+lVrjJjP4fJ7Kko5Da62m1b5GQlSeNH9HPY584Uis3bUWJfeUSM6wYFIWufqjq628HkgNNia9dHTOVYFJDd8v3eDJg43Llc5y/e65zqStyvqMIG6ZphEz/IjgfPAsbgcgZxRBRn4Rw9+xJ7p4GTwKSwpt36WhFTQkHdE5w6YMQ+7DuS6DFcajaGPpRvzftP9L6qmLixajtKLUv16J+hdsKDDqIaXipUNBlTR82T0O7Ydv0EvHL6+wLLiiugInv3Iyvl/3vbRc1dAKznPDavhGJZ3YSyc98DM2zkiO/C70Mi+dQAY/wfBZXq///DpaPNkCP236STsvvm5eYNfmZNwqq1pVJ6z4c0bOGQnA3QFljX3isol4e8HbwjozXPvxtfjX9//S3mqRr8NHS6Vhm7QhW6OxuXQzdlftFpbvvKahU4Zi6oqp+8SkrV8dwr6NPD3zacxYOwPXT7xeqdyjRx8trYOTvWeqpLNixwpXu3ciZvgRwdkxbcG9JF46Jhj+1BVTAQALtizQzouvGw+Xh0vie26WWkxv/jqDMEDZ/eLnRXiM/mE0/vzBn211LdpdhP8W/DeZhrF53TkLvg4mvS1kuvuBTx2IV3981ZUOcK+2/XLVlxjwxgC5hh920tag259furCyxz1f3ONbLv/5580/u9ManrSN2i1z3sZ5yXYvrUPM8IPBV8N33Fh+Oz4ZEw7Cyp0aPjNgQRmSiobP8nYyfD/vEEC9I/PnsDoFuSa+TjdOuhFrd6215a86L8DA10G3Pt+v+z4ZrdAZ8EtVw+fvi0yC8gutIMPv3/k9er7Q0zONHzKF4euU6+uW6VgoKQrWprNPQjrcMmtojWeI9ihQpw0+g+qED2/wZZJOkDjg2VnZKK0oTRoS1vACG3wFTbDZ482wfc92ZQ8hYww/ADtxnuM08LoGn89P9x6f9PJJOPS5QwG4t3dUXWnLlykz+EElnQ+Xfuj5ZuhlLHqM6oHqmmrlZ+R372RG8eJ3LkbzJ5orlQG46xxKw1eRdNLslinC1t1bkf1QNp6bk4o4E1XQPx77hcFXYbWAxOAbGG2zSTZ+8/Jvkq57YcM2qEyEllWWoWBDgauMxnnuKIJAMCNpiuE7Edbgh2H4gLU6GAD2VNoNvmqcJR2D70To0AoexmJx0WLsqdqjdE+mrZiGtxa85ZlGls9HSz8SerMF9f4CzHjp6HgwRW3wV+9cDQB49adX3XWIkOHXabdMP3gxfJOLpLKzsvHT5pQUFHYkV4002SSviVvblw1+AXRvSikWbVmEto3bhnpreePnN+z5+jB+P9jmZkKwJRfDVwitQClVMvjScB9Mw4+I5clkBCe8NkFn0NXwKahxjxXZSlsVnd7rN5NumaLBivUxkct2zPBDQjXeuoqkEwQyDT9Khg9YG8CUV5XbjsncJoOwYgqKI184Er3G9ArF8J27NDnzyM3W20w6iDwlgozhe+HWz27FZ8s/S373lXQMr772nWitqTamvevmE2ayWHXhlVeddIhW1Ayf5S+SXGOGHxE8Gb7BmOrOhxp60lbRSNw+5XZMWTHFdkxl4w3lSdvEvVm1cxUa5DTwzF8Hqq6dKueHeX5M2knmpTj43z7l9uRn2b3UWRRoEtXUnMHXndisoTXIhj+j1QmP7HWu9ByPPAkhoJRG7ofP4vXvkwyfEPIyIWQLIUQYOIVYGEkIWU4I+ZkQcpyJcv2g62UQmaQjWWkbWNLRWMzkdGXz04690vR9qS8ufz+19YGo/iYMVdiAdXx60UYYqmCSjlOu0qmPnzeO6d2+/M7TmbT1gzbDVyxXJzyyTNIJChW3zGkrpmFjidjdWBXMiyjdDN+UpPMqgLM9fj8HwCGJv0EAXjBUrhJUgnPV0BqbcTAq6UgYfmBJx2OLQyecLEy2MlFl4dWcwjkYv3C8sEyTk7ayOgY5nx/EdcHOpaDYvmd7oAlVvxW1pjd/8YMXw7/igyu07peuzh3EGcBv3sSZp0oZSqEVPN5eznrjLPQb28+3HC+wASVMqPMgMGLwKaXTAWz3SHIhgHHUwiwAzQghbU2UrQLpBBnXqcqr7Vq3aS8dUd4m/fBlcHbKMAzfdQ7vpRPS1ZRH2DxMGXy+0184/sJAE6qqHmKmoKLhy9K8teAtTPplknJZQSQdFQg1fEUvHVMLz/wkHbZWRAWiuosknai25uSRrknb9gDWcd/XJ47VKvjG4ZygCxMDxgknww/LhnXkJmen9PMOAfQ1fMAsw3fWsby6XCtEwvLty5OfZas5eSwuWiyMxMnfh8VFi4MtKvNj+IYlHT/4afiFJYVYt2ud9HdnXjpQ8RADHAxf1UtHw1iyPF+e/zLIcILNpZul+UYFT0kn0xm+SRBCBhFCCgghBUVFRf4nqOQpMJAfLf0I//jyH8nvTiaYFi+dNGj4TqYSNcM3cb+c5d/75b24+J2Llc9/4OsHlNPOKZyDHqN64OmZT3vKAzW0xmjYZb97TCnFN6u/wSPTHwldFg8/Df+2z25Dx2c6KuWlaxRDMXw/L50Ab5hj548FAPy6/Vd3HRRUgTDwnLStA146hQAO4r53SBxzgVI6BsAYAOjVq1dkV+40IE5Jx9QkECBg+CHz1tH9lCUdBDD4UTF8x31ZuWOl63dTb2As77kb5rrqzr8d8YbSiKSj4H1yymunAADu7X+venl+k7a16KUTJCyzbOHVnso9yH80H6d2PlW7DNX1FH5188LkXyejb/u+aJnfUvi7k+H/su2XZHj2usDwJwD4S8Jbpx+AXZTScNPchuFk+LrbjVFKXYaJwTjD15B0nK6FKn74QaJlRqnhy1ZTmgBvUJyDI/+dX7AkC+4lzD/gpG1UqE0//CBEQhZaga3k/Wr1V9plOD1/KHUvCPN7bl4oLi/G7976Hc57+zxpGuek7blvnpsqO9M1fELI2wBmAjiUELKeEDKQEHIjIeTGRJLJAFYCWA7gRQA3myjXJJwavt/yeWcDGffTOHQd2RVfr/7alda0hh8GRiWdNGn4zu8mV0Hy4RK8JB0ZM/YbtAO7Zfp0+ufnPI/CYvdLskqES1MGRfQcVFaxuo57PG/ZOc77pqPhT1sxzTqHIynO/IIGtwNSxnzp1qXSNE5Jh4+qGiXDNyLpUEov9/mdAhhsoqyo4GL4mrLLnMI5AIBFWxbhlM6n2H5zMnzVvCuqK7Cncg+aPdHMdlw3XDAPowuvRBp+GvTtqpoq1MuuF7ocviwC4nqzcUo6Ij/8oAOc70Dh8/stn96Cl398Wfu8qBm+17oHlXJraA1enu++LlUJT8VYDp0yFLf1u81zr9kwDN/ZF4QLrxySjs5iszDIuEnbKLG3ai/IcIIRM0cIf+OhK7uw9CJjKfXD98n7nDfPcRl7QG+LQ9V0YRm+7rle8JN0vCQn3c7Cv967NHynpMM0fI17FaUf/vY9Xp7QYlRTcwuvRM/BGcqDh0q57yx8B6/8+IrvOc77FkZSpHDPCb214K0kibOlVXguKgv09umVtpkK58Nh2wo+8d0TrrQigz9r/SyXBi4DM+qiBhfUD//LVV8Kj4fRfZUYvo+GL1qsFeWkrbMDePlIB43vQiDQ8HmGz0khw6YOw3uL3xPWVZZ/2HqqorZj6XjlrVLutj3bbN9lLPn9Je8Lz9eZX/F6K525fib6vtTXdVz1LcWvfBfD16h3GNRpg8/AjJHXa6HT4BeWFOKEsSfgugnXeebJ4GXEjcfSCeGhYlLD59NFOWnrnAz3kpz435rmNfUti49x77dqkx94/vi/PwrTAHbjFNS9L0o//Cg1fK/nTynFpF8mud4CVIyds83f99V94jI0fPh5xwxVEqXSvtl98QoL4WT4OvUOg/3C4Ks0cKf2uKt8FwBg2bZlwvTOBpKUdATs2PTyedXwyCKY1PBtBj/CSVsnVBn+VT2v8i+L99JxavgK90Fo8BUGZHaeygCsg3Rq+KK27pX3d+u+w3lvn+eKjspDNRiaS9IRtD9Vhs+fL8OWsi0YXTBazeCzjeo9ymeTtDHDr2XcdZLVGFW8HcoqypLf2UgtahAfLv3Q9p1nFjpLtJ3n81BtJNJYOoYYfhQLr5xYt2sdTnn1FLy76F3Xb7wRUtnti3f78/LDB8T3WHS9Nobv45misvJZhiDSnlE/fE2Gv6l0EwAruqoMsvNlBt4JkUunDF5umU5c/v7luGnSTVhctNgzHSBg+IK8kwY/1vDNw+Vy5XFDh/YbimySrXTT75x2Z/JzEJnm9Z9fR6dnOuGb1d8onwOY0/D3VO4RMk3Va+ANYpQavhPzNs7DN2u+wf1f3e/6jS9fFqVUlF6k4T8z+xnl82Xwm7RlIR3mFs6NJNKoE1FHy/S6H8zIeW1o4zdhLzsukhSVNXyF+8EmyMsqy3xSqmn4TNZK90rb/cLg66B+Tv1kTGw/FO1OhX7w8tJxgjU0xhbY1oeqCGPweU+T/Efz8e3ab23HAfWFV1Fp+H4d8D+z/6NUJxX3VV7S4c9duWOli82J6uUn6fhN2lJQvLXgLfR5qY/tjSUySSfilbZeebOJSqfB93JzlengKtKkzqJJP0knN8vahMfLC4mBSY5e5X++6nMAErfMmOEHQ5AbVz+nfiCD6uWl4wfdSVihpKOp4TvnLHgDo7r5Q1Qavh+WbF0CQMwU+QFXV9LhDZipuC9+k7aU0uQCHba03us8WzkBJu+9omWqwE/68zT4NWKDv3z7cjz27WOu/Pnvqn7yWl46GpO2bNc1FoLFKz17k/Eqn+1TIYrKGzP8kGAPR2VxUF52npVGc7DQkXTCxoExIenwK/sA+/WqGnzeuJpceKUKkUHXZfiylbYqcpCzPAaVtuPnq60U9VE0p6Aw9xRmUPab3Pe6di9J5+9f/h2Auobv+l1AOOZvmo/HZzwuP0dj0tbJ8L3SJw2+QjtIt4a/X2xxqBr0Ki87D4QQ4SIcYb5c5/Ly0nEibPwUE26ZLoO/DzF8BlFnsU3aKhhtWSwdlbcDwP96Zes4VHTeKBBWw+frG1TS8Xouql46Mg2fT3/C2BMAWI4Yoj7Djq3YvkJaHwbG8Fm/8erD7DpVnm280tYgXK+BPjeSMQ8CNQ2ff0hhGL7uAGCC4bNGyRDWLdPrWFTwY/hhvHSEEUkVvXR4Q3j1R1d7lmubZDSg40at4fuFlTA9acvgp+GvK14nnfh2khvA7plz8+SbhX2KbwOM4Y8qGCWtOwOTrrz88EX1SX6ONfxgcN44v4bOZuCDMGgvt0zTqKipwEEjDsLEZROTx3TdMk0wfJuXjsFJW1X4afg6k7ZZJMt/hbHipG26JB1h2T7nbSjZgJfmveSbtwp03TJlGr7X+bIQFKL79uK8F4Xliwy+M52oz+dl52HQxEEYOXtkkuGzcAteNkKH4QeR5cKgTht8BufrnlLMbJU0IknHYCRHGTaUbMD64vUY8ukQ7XMppSgqK3JJDUE0fJGkEyU7cUIkDejq8DwLc8bOUUHQAc5P0tEZNHTOGzx5sHQxoQpCTdpKvHRk+fP5qUazFF2/c68LwOqnXsHTACAvJw8vznsRt312W5Lhe6VncDJ8L4gG/pjhG4LqyBm5pBNSww/zNlFWWYY2/26D6+12QAsAACAASURBVCbaQ0b4abMiiCZt+77UVxi2NwroTtp+uORDZ3KbF4iOD7duOtl5Monk2o+v9c9D8Y3DJPz80FUYvtdArOyHL7h2Sqmw/L9+/FfXseqaat9+yBw4APcgpcPwPTdakVxHVNivDL5qZyCEaI+yOm6ZfpIRpVQaOA1IdZwgbxO79lohI2asnWE7zte7igZn+ADw5oI3tesVBL6Tto4B4ffv/t6VnmeQfm6ZJqODihg+Lz2s2JGaSFRdfBSmPqro82Ifz99Na/gySUcnJMUnv3ziemt1MXxBn+RDcDvDcSu5Zeow/DRp+HXaS0cWdTGotuaVJkxANL6xfbXqK5w27jTP9Mw1jDdQqo2ktKJUeDyspMOHiBBpplFAZDi0F15JJm2jlnR4eZE9f9l9k/mJ62roJiDa/5WHSvwYpocLz1ecd9OVwpZuXWrrZ863WNH95duXU9LxgteeAE4EmYcJA1M7Xp1NCFlGCFlOCLlb8Ps1hJAiQsiPiT9xCEqDmLhsoiuGjY6ko+SWKZB0dPf5dOKWT2/xTcM6ThADJWuMYSdtRfWLGr4Lr0K4ZQpftQ1KKH4MX1RHleNh218YyCQVhiCSDnsmKuFRKOTlO+esVuxYgcm/Tk5+FzF8PuZPEElHJa1I2stohk8IyQbwPIAzAawHMJcQMoFS6owy9A6l1N+aGcIF4y9wHdORdHT98Fkj3lu1F0/PfNo7/5AaPpuEshkohcEsNytXbvB5t8wAoRVs9VNYfm4CJtwyZQuvlFfaBuycosk6p6HwK6M2NHwveBlcwD5pqzqIsbao2me88uV/++SXT2y/++XvfJtSmbT1qxMgkXQiZPgmJJ0+AJZTSlcCACFkPIALAfiHlUsTnB4kQT0gvMAY/kvz/V3ewvrhMyaoK+k0qtcIO/buEP4WiOFL5hBEXhFRwM9LR+W+ykIrBI0+qooX573oOl923/zi8djScu1gS9kW3P259cLduVlnrN65OlBdVeHH8HkN3y+onPP76B9GC/Nylk+J2uDoJCV+82rOPqHD8L0gskmZ7qXTHsA67vv6xDEn/kAI+ZkQ8h4h5CBZZoSQQYSQAkJIQVFRkSyZFkQhgL0gipwoQ1FZEQZPGqyl2/mV7QfWWHUZaeO8xtLfwmr4ovrVBkQRPL0gC54W9aStKE8vDV8EvzreOe3O5HaB53Y7N0w1leDL8GtSuzypDmKzC2dr1UFWfg21b1TuHFxNMnznc/Rqh/ukhq+AiQA6U0p7ApgG4DVZQkrpGEppL0ppr9atWxuthOrIqSzpgGLY1GEYVTAqueWdUv6Ksb1lSDJ8TUmnYW5D6W82t8wQK20BYG/1XuFx0/CTNHQYfhbJCuSHH7Zz2iQdhfkVHqyOd554p+sYYDc8XhOlpuCr4XPMV3UQk21lKCwfVFkqcu5w5wdVEgRYK3dVkW4vHRMGvxAAz9g7JI4lQSndRillQ+pLAI43UK4UB/z7ANv3IHFeVDV8xijTseCKgbETvhGqSjoyBAqeJtH608XwhZOWVJ3h767cjSkrplhpnX74EU/aJvMMwfDZuR2bdhTWhzewXq6QpuDH8PkokmEWnHmhBhKvHsdgEKWk40Rd88OfC+AQQkgXQkg9AJcBmMAnIIS05b5eAGCJgXKl2FO5x3Vs/sb5OPz5wwH431CnnuuZ1nDQMJWGxNgJ34lVGomXwbf54YeUdBYVLVI6PyzCMvxbJt+SXO+Qbj/8ZJ5QMPg+xpF3P7UZfO6NQcetMCgopZ4Gm9WnhtZg4i8ThWlCvzGpMnzHW6ivpKPgxhkE6V5pG3rYp5RWEUJuATAFQDaAlymliwghDwEooJROAHArIeQCAFUAtgO4Jmy5XnAukgCA/y3+n/L5qpLOpF8noXOzzgD03OGcD5Q1ntnrZytthlJcXgzAvhJQpb4N66lJOmENPov1HTX83BL9Bk8+/rzKStugcXO8wAfxCqrh8waff8PhGb6oT5iGKsP/afNP+MdX/xCmCTOAUsgHHJeGH4Dh815uYUOcM6Q7lo6R9zxK6WQAkx3H7uc+3wPgHhNlqUCkV+o2eNWGxzwfTMhF/cb2U84DsF+TiuHhBwgngrhlplPGEiEsw+cNpYqGH4mkE4Lhiwy+jOGnxeAravjb9myTpgl7P6ULtZxeOpqeZFU1VcjN5gy+BsNXmbTdlzT8jIOocesYRx0vHQadhmpqBK+fU18rT69Ob5Lhpwt+LNyPhfGGUsVLRxTb3qSB0vXDl4UdYOAHkEzS8L0W5oVi+IK5gUt7XAoAOPW1U23t2jlpq+KlE4UsJpR0MlzDzzj4GXw/qEo6PLQMvqERnF9YpJKnp8E3OGmbLhSWFGLRFvt8ARuoH/ztg1oM3+WHL7if09dMdx0zqTkHXWkrY/h8flkkK3Kj78fwRc4GTph8YwKATk07JT/zRj6QpMMpB8YkHUXnAFOokwZfNBJHJekESW+KGbMOv7Fko1KenpKOQbdMHYQxmD9v/hlHvnCk7Rir06ldTtVi+EFX2oa9B3M3zE3ebxMaPn8/+TcGQkj0Bt+H4TMj67UwKbSXjqN8vt/zA7quHz7T8BlU4jSpYF9caZtxEEW203kd0/HSYQhj8IOyBQqaDLZ2aMtDfdObZvhGDL5BNnPTJzclV2RmkSwthg/YryfqlbY8PljyAQAzXjq2SVtOwycg2r7nulBl+LLr/GDJB8a9dGwGn7s3s9bP0srX+XZnyksn3bF06ibDF0za6nTmIJKOjuZvkuHP2zgPAJQ2tTCt4df2pK0T/PL7bJLtOZDOWj8L01ZOS353enhEHUuHB5uLCcrw+ev0knSihtfCJ4Bj+JIFZtd+fK3xSVu+zessnvKDKUmnrq60TStEhk03gmM6J22DsgXdzpGRDD+ixu3H8NkG1wwPT38Y23anvEfSJekAqQlV3ZW2Ig2ffzPl27wpA+UFVYYvW5hXXF5s3C1T1eBH6YDg1cZjDd8ARIZNJ9aNanhkHrWi4Ws2jLwcuYbP10nZLdPApK2Jxl1RXYG7pt1lO5ZFsrSN3DdrvtGul4lnyaQWmSH0i5YpdcvktPJ0MXyV+yHydtI537MOHpKOF3QJng5J82pL6dbw66TBF+n1PNvxdcuM2EvHpKSjY9SMu2VKlrHrwETjfvPnN/Hk90/ajmVnZWu/OfGGKF2xdAB/bdsv+J9Mw+f93U1pzl74cdOPOPvNs33TyQw+EI4AiN4wVA2+bp/U6XdK4ZFjDT84hAxfI2QpoM9eQ620DTFpK8LAYwcKj2ekpGOgcYvqEYTh84aIddIx542xrXdQKVsXLBSINDxy4h7JypJJOvz1hGH4p3c5XSndqz++qpTOy+CbdstUddZQ6b+vX/x68rMphi8azGOGrwnnpC0hREvDj1rSMfVAq2qqcMfUO1zHZY1RleH7XQszpEYkHQP3QjRJn030GT6/QTe7B91bdsf9/e+XnWLE4LNyZV407B7JyuKvU5omhIb/xBlP4MHfPuibTlUW8UoXiuELJo1VBzqV58i7tZpm+Lb0McPXg9OwUUptGn6meenIDNPdJ7l2i7RhS9kW4XFZY/Rq/EE8VDKF4YtYXFiGz3vAeN03E/fAi/ECqXsku1cySYdHGEknJysHbRq28U1nggCY9tJR2fVMtVyVLTNFoKDo3a43+nVwh04RboASM3w9+Gn4KojSS8eZtppW452F79iOZZNsdGjSQasODDID5RmmVYPh+zFOHUTF8FX88J3gg77xE6Ky+7mlbAu+W/edVhki+PnH+91v2aQtD1XDJ8tfZfA04aYbpk3V0BrXoKhqpFXqzt9DlbbF3gi85trSHUtnv1h4Behp+FEvvHI+0BcKXkj609vqEfA1PAib25cZvmgFaXaWtx++H/g4NTKD3++lfraNrqNCUA2fR1B2CljtUKVNmfBzD0MAqmuq08bwlQbAxLOgoNL7F/vhG4Brpa2uhp9mL53NpZvF9Qj4Gi5l+B6NdOz8scnPaTX4Jhi+TNIJIWPwPu6y+5kOY8/XRXavZAuveISZtCUgWgYuDMIMGlU1VYE1fJW62zR8n7bF9u1lAd1k9RCGR441fD04DcDs9bPtGr7CDdXW8HW8dBQbZWCGLznPq5Gu3bU2+Vn12jNlpa1I0snJyjHC8L0MfrpRW5KO6n000R74iXNdVNPqwJKOEsPPUmf4zAaxtQWyt6Q4WqYBOA1AWWUZJv06Sfl8AoJd5bu0ytyxd4dyWmfjCqK5e7mbhfW5zlRJp2Eu0ESwdkwo6QTw0uGhOmmbDmhJOhKjG0rSgZqkY4Lh88RDF1U1Vcp9ywmVdmiTdHzuB7NB1TXVnpJOctJ2X4qHTwg5mxCyjBCynBDici0hhOQRQt5J/D6bENLZRLkyiBr39j3blc+Pehm684Gu2bVGWAevxuoV+TDsG0M6Df6CzQt807RtBIw+D1h7O7DL23EpCRnDb/Z4Lsqr3FtgOqEyaStC3/Z9ldMCan7iOpO2MqMbStIhipKOY7Dp1BTop+l34LfjW04W8MbFwDEHCsqvqXax4zBvNk7o5NWxSRaySWIi2WPS9stVX2Ju4VzbsYxm+ISQbADPAzgHwBEALieEHOFINhDADkppNwAjADwRtlwvZGdlo3c7oPQe4PBW7t+poqHKSjyjNg2BQ1vaf6uXDZx5sPi8ZvWB+jnAgY2sBt+As831c4Bm9S2d8pTOQF42kC1oC5RSNMgtQT1JGxPJGAx848oiQCOfxYYkcT0W9uLyIyuRRazrFuG4tjuQRfwZ3dndgEdOAxonys/NAs7qCvRuZ3Xco9oAj804ES0aeNfv62uAG46HK91xba37KTKEbKVtThbQvjFw+ZHAIS2AnXdXobRimGd5PVoDTfKWoFNT4LBWA3Fpj8elz5rHkW2OxAkd7DF6/tQDGPU7+TnsWT10KjDw2NTxBjnARYdZnynKAcxEdpY4wqMSw+eMVaem1vP+bSe7QT7mQOD87sDBza02zJCTtRst6m9Al2ZWm25WP/VMefD6+2GtgNVDgZkDgZ4HAGd3s1bgntoZuOMEoCX3LJvVB1rnC6ttvwYCnN4FuKInMOpc61jHpkCrxLkHNipBFql2nJOdPPfKnlZ/qJ9j/XkhT9Dv8rJ3J89bV7wOWcS6TpJIn5/oko3qAQtu3okx56dkJifDP7Uz8I/+Vpu+54s+OKsrF9wRNUBULJ9NKgT9A3ACgCnc93sA3ONIMwXACYnPOQC2AiB+eR9//PFUHzX0u7W9bFnV/ydozkOggyeBHvE86JZS6/g1H4HiQdBGj4IOmQw6/GtQSgfS3RWE/uNL0Ioq0H4vgX72q5X+0v+BHv2CdY6VFnRpUep3SkGPHS2+nHu/AM0aDlpYDLptN6FHv2D/Pf8RK99Hplvfh39N6N7KBnRzKejjM0B/+wrorZ+C3jUNtPMzoI9Mb0Af/gb09Z9AH/sWdNgU0M9XgLb5F+jMtT3oMaNBGz8K+u/vrfwa/BN08i8303kbQCcstY7NXt+CTlyWqsPs9c1c9R76mVWvBv8EPfsN0LNet46v3Qm6ubQ+LSwGnbMe9ONEnpXVoH1etM7h8/l6lf0+Of+6jbTOYX/frAb9ZBnoq/PF6W/71Pr//mLQ2ev+QxdsBn1iBuhL80A3l4KWVw2gP226UnhudU09umgLaFGZ1QZyHgI9apRVbo/nU+nG/Zj6XFltPT++jkM/tef71arGdEzBRfTEsaBvLwDt/4r991fngzZ5DHTqctAvVoJeNB6028hc+v7iVJp+L4E2fAR0wWbr+2s/2vM4+D+gzR4HzXsYdODHVrsqLD6D3vQJ6MjZoA0fyaZ40GpP/1sEetl7oPUeBv1hw3W020jQQRPd9+PxGaB7Kt3HT38N9KFv3Me/XGn9vzFRZr2HQQ/8N+iHS9olf3P+fbGyHT302dT3BZtBO44AbfdU6tjrP4GWllvPsfuzoNnDrWfT6knQ5+fY8/tkGehT36e+v/mz9f/Hjc2Sz2dTibseT89kzwr0tNdA75ya6tPkQdDv14JO/sVKU1KeOu+uaaCV1Q3p8m2gZ46z7vv8jak+MnV5qh5/fj91Xkl5Mf3tK/3puW+eQH/e1IhuFNSJ/S0psu5peVUOpfQ5gW1TA6y9xMX2Wlq64h+ASwC8xH2/CsBzjjQLAXTgvq8A0EqS3yAABQAKOnbsGPSSbX8DXge9Y4q7+qXllqFnnSvqv9s/8/59+Ta1fLbvTk992d99X+qfc8tk/XPunGoNUEN97lO6/jaXuo+NLkgZl0z8W7PTMpjpLPO019TS/bLVXJlbBM+G/e2ttAy6Tn6j5oL+8V3z92ZPxd8DnVdRdTQNin3K4PN/wRg+dWU1ez3o3MJwlzpnffiH/85CtXSMhWzf3T50mSp/r/9ksV1Krf9OgyZiSmH/lhappz30WTfTlf3NWBP9/ZL9VVaLjy8zaOhM/DFmSqk/edhYArqtbKhnmm817/m/v5f/Nrog2DVNXQ76yPTDI71vZRXdPH8XvT35/Y35AfTmSfZjeypBJyzNo5RW0iDwMvgmJm0LARzEfe+QOCZMQwjJAdAUgHzresPo0x7o1U7vnCqHLPyr+pxvEhWcnLhgM3BpD3naHzakPv/9C+DoF7Iw8ZcHk8eyHwJu/TSVZua6+qisBrZyq/KHcL/zeHm++1jvF4FXf7RE492VwI+brONDPwOu+AA4cSwwaKJ1rFwi1c8tbI76/wTGzgeGTZFf27Nz3MeemilPz6OwGFi2Dbj2Y+Ckl4EagbS5qfREdH4GaPsUcPIrqeOV1fKgZ7ro+QLwsHtL2yTOfxvo99Lxwt96jQH+/L783Osn+pd//Bj/NCrYUnYB+nP36EbOee28t9zpP1sO7Cof5JnnbzrKfzv/beDY/wJfrkpNFjwvaA+A9WyXFKW+FxYDHy0F/vKhOP1F44HuzwIjZz2CR77tj+Xb7RMBby0AZqx1N8zt/nP2QmwqvSH5ebrbzwIvzwdumeydR1kF0GNU6vugicAobs52117gkGeBGye1RBTrYk0Y/LkADiGEdCGE1ANwGYAJjjQTAFyd+HwJgC8TI1Gtg29MvGFcvh046gXgn4lO3t0xaXv6OOCJ76wOwdDqSeDzlcD7i63vR6c2YMJKH6/Ns94AFhdZDWlvFbB4axYoTU3M1lDLMDO8+lMLNHncMiYMqyRlPMPN9RVsAK760Po/p7ATVmwHRs5ODXC7EgEbu7W4Cud1tx5Zx6bWsb9NtRrkDxusA9v25KK8GrhuAvDdulQZs9enrv/ZOcADX7nrNG0lcOUHwDerve9LYYn1v5oC368DfvdmC9v1XPMRMH/jMKzZBWwqtaa67phq/VZc3hnH/dc+CDjx3x+8y2dYsAW4/yvL8DvR8kngk1+sifT3Fp2LSb/Yfy+pAN52OJ/w7e6leQAZLi+7/yvAvI1AdU0z2/H7bff1XsxY2973OvZU3ooSbg3iplLrf0U1MOlXd/qnZgKENMCCzdbM85xC4L3FQJf/AE/PtIiMF9bstMhEwYYDAFhtYtVOa3BmOOoFoOnjQIenrefMkJMFXPwO8PrPVpkMvV8EznkT+HiZRcSqaQNkkWys25Xy2V25A7hpEgDk47DnLBLF0GOUZZg3lnjXHbCID0N1Tdvk558T1z2R22iuqsZ6lgy3febO75NfgJ0ekTROeQ1YX+zthRcGoQ0+pbQKwC2wJmaXAHiXUrqIEPIQIeSCRLKxAFoSQpYDGAZA0bkuHI54PvVgeAz8OGVIp63kjnPDVHUNsHCLZdQB4Lk5wO+5cDdfrgLu/hy44O3UsW17gDNfBy59D2jzL2DpVuDIUcCF44FHvk2lGzy5vs14Axbr6DEK+O2r1ndKLVeu0QUphsyfM2tdM+ytsjeeLdyaFd6glHIdfN2uLLyRCBlTUtEI3Z4FFhVZdQWA4oTB796yOzo2TTlbzVpvdf5mTwBbd1suGjv2pBolY03rdvXDxe9YnfjnzdZbyY69ltFlg+cnvwCrdwJvLgD+M9t+H+r/031fePy8pT5unwL0ewnoOhJ47Segmtqd89nAR5GN+ZuAGWuBbYk3od4vptL9sAG4TfJWVF7VCOMXAut2jcK7i/6WPL5AEK9uR6KOuVm5mLfpaNzMsTwRM/9seWog48EPTE9yIXq+Tbimby59Cws2W0bl0W+dbxzDUE3l3fmXbdcAAGqo9ar73mLg398DmxMGX+YNtnCL5XNeXt0YgDWw//F/1vO7YyrQ/1XrGlnbPHEs8Kf3UgMBa5/fr2uPJo+l+uOmUouhz1xnEZ3icmBjKTCFI1C5XJ2e4O5HwQY70WKus3uqUp4w571l5ZlNsrFsG/DYjFT6TaXA83OBCY6BmWHextRn9uZroWny092fW/fhD+/az+Xfhkdybfvf3x+eqGuqj4nA3tijMvhGcqWUTgYw2XHsfu7zXgB/NFGWDpZstV4nswgwpA9wxsEWG925NwdjL7Ra6KZSy7ivL2ZnDQIwJikdlFZ4s6/KBDPmGUgNBYoSD25RkfUHAD9tAo4+ECgqI2j0KNAgFyj7uzxvApJgKRb2JLzeVu4ACLEGrTJuEOCN4+s/A9cea7ms8WkqqrOBxMYl/HqFuz8HZq5PvapmkSxU16R85/jBrppaHWthUUqHWr7dGtgGHjsYG0tnYWOp/VpmrE0tmuLlsg+XAgeNsFwsuza3OsyanUCnBJkd72DGrCPM5kRDp1tm6npTBqDbs5br3GZuUDz3LbFc9fB0oFvz/+KKD67AksGnYXOpfbn/qLnAzb0ttnrSQSkHupysHGSRrGSnnbjMbjy27wGa5ln3qWtz69gGzvC/euFy7K48H/m5S4QDy97qQ9FztPu4hUYY92NPTF2xDr3bWS6dN00Cbu4FjP4BuPiwK9C95csgxHrAf/yfdVYziep18TuWCyZguY7SxDPPcrgQ79xrXePaXZaL4k+brXY0e73lPrku0a8oYHuzACyG/rFjK+Zft1tvNNP/ah+EdnjIMGzNSjWtxoRlrVEvuwhLEgTGy3d+yGTL3deJ3i9abrFdmqf6nFVO4+Tnskp7n/fDN6vb4ugDivC3aVtRJojyctprlrsqe+vIaIOfaXhrwe2YUzgCgGV8aygwYpb1B1gP854vgHO7Wd+bPs5rw1cAGGN7teSxt8oySDzq/zNl+L3AjEtZBQUFXCyfh2ixy55E+hqaahC88XSy4VNfs/435Fz2KXIAWBnxBr+8Gnh3USpdFslCDU1porwBz8myCt3leDWdsAz46zGNpNc0bQUw5ge3Fr6+mB9wrXsMWLLZl45wNaKOIFMHKU1dH/8mdMm7p2Pyr1/YOjPDYc9ZcwavX1wDioSxc/hED55s/QH2N8jc7FwQEOyuBPq9lIefNtupHJMxKqqBX7ZZA8cLc3MBVOKI1kega4uu2JtgqYXFcMF7oVs9FFc0wMvfWgvVNpYCY+cBowsS13x4NiAIBMfui1OT/mhp6jMBQWWN1RZk7PSs14HLjmyH3ZUWCVizy3oLCYIdiTrlclVdlehzKwRzaYzh19AaPDy9Ewo2pCYC+DZ+8yTrzYRB1GcHTrD6V1ml9XbDg8Ay+BUOknDB29bzZDhjHNCpWS8ABdhb1RH1c9Zi+toC7Nh7FNbu2iq85q9WW38MscHXwLbdXVxSgROPz7D+ADsDBizKUy3pW00ecy+JkE1qOsEMWbXi9IVzsQYzUNU14oVXrPPuqWwMIEUd+YHlhA49YHm9eq++5A1+iaOTZxNqK8/+m5xRVdYAN3wi/TkJdj9FrE6Uv3t/AQtU0rw3lOwWGnvAMvZAalGZzgpVfnXvoqJc7OX2qO3UtJNtRXU1tQaNvGwr/3tPvjdRd6tcZvT4e++30I21l42llnHjwa5DdD2HPJvS8ts9ZWnntnwJwaodJ+PDpWPxnGTCdV0x8PEy+WCvA0ZceEmnhlrELFfwOLJIFrKzslFDa1zB1/jrfaHAfe6QT4HLegAnJSaeXxE4OKTyaoyWT7ptw0SHNPTFKuDMg61XuHcW3oEHvr4NxeXFNgL38VLgsxXysjJWw89E+C2BdjI2O6ynKfIGASyj5fTgUQXrvIwhA8Dl7wN9XnSnpdQdYY8x/GoqXpJPYb2qf7XqUddxhk7NUjqk132yDL5Vxi6Hwc/JturPBsox56WEahNL2a/92Jr8XlTk/k3I8B3P03oruBYLNw8W5i+Lk8SzR2Y4CIj0DcKJ3Kzc5DNzDtZX9rzS81x2XmWNpbGXVViT2sdxcwBFu903hJ949Ap/wJ6LyOAv356a59lYmpJh7HXLwb+/T5EWEUzE0gFSA71TPiout+bJnOAZflVNle0a/drjc3OA37wCXPaeNbfk9aSzs/KwfY+7P4jACFleThusETS3i95JvX0JywoR+8gLddPgh7pZ1sg8b5NPsgC44RPrNf7r1amWPH4hMHeDOL2zAzPmK2P4gKUr5mR396hF6p3W6z5lkSxU1rTCyNnA2W/Yf8tJMPzKRH34TmUi0NgPG63Jb+ers7MsBifDt17Vx2Jv9QHC/Hfu3Sk83vel1OfrJl4HwLoeb4KQApN02Hk6YOdtKXsSV35gadlvLrCMMcPJr5zsOu+IUcCCzRNteYjA6hOkbyiHRzYUPXVPlTVPdZ3T108CtmcBM/g8GVK93ncWWS6kXtBh3awObB+Op896Wvlc3bK08o0k11pGOJZ5KC5/vz0+XOJcShAehSXWa3xulr8BEYVTZYyH1/BFaJrXVPobkDKCfpIOQbbQtSwny+rYzCDznSoqZuKVv4yBywzgrr1ihi9jj6pgk7aAfgA+dl4NbYY3/ePJJbFzL1BV0963THbfggzIyuGRPRi+rhd215HqaZ0MPzc7N7khvIk3zp17rcltnbbNCBkLy96jTQ98sPQD5fNjSUcDYcMDzy2sr6zLB4FKlEnmlsmDvep+t87e+A59zvJ0YWiSsoxFHwAAIABJREFU18SVX9Zw4KtVNwMYlzrmY/BleGdRawAplzW+U5mMTiiCiqTDIDNUzpjrPV+wL4Zx5qEj6bAynffPLw92XpC266XPM3hJOn5QDY9sYserIHAZfI7he13vjrt24N9n/ts3/24jrQFIp207Gb4uEYoZvgb8GInfHqImwv56QVUicHayNbssN9NFW4AB3VIN6BfHmuVG9dyTZxTAml29AaRWkHk1YK/X+C9XNba5qqaT4Ys6gux5qRpPkQskg5akw2n4TvjlEfTNgD9HRdLhpR1VCUY1PLLqfTINZvCra6qTDJ/Bqz02q99MSI6c2LbH+gvC8NkgqLsDW8zwNRBWR47c4CswRlkn+3GTpVF7Nb68HMEuIXAbBD8NX3UfTtMavhdEg5RU0vEwUipx6AG9SVv+nuky9aDnsXIBPUlH5zmpGqvaWjxPCEE2ydZm+OxcVQRi+AlJR7dfxAZfA2ElnaiZSlCGz8OrAYk2cQfcjdvPS0cGl8EntSvpBGH4XvsJ8NDpqNW0Wmp8/YxhmIFS5hkkSpNk+BrPSXXStrYZPq/hM/hdZ1Ss2yXpCOqhIsGZRt00+CF3rMqQMD9KbnYiyAy+E76TtpLynVIAny6MpNO5WWffNCp++KJ6OaHK8HUkncqaSrmG75NHUpYJ0HaVGL6jvegMMLL9WJ3w6jdRDgZeGr5fe9Ri+CEmbUX3O+iOdmFQNw1+mvZ0jRpe1+Ep6WSLJR0n/L101CQdfrIuDFP9+LKPfdOYYviqg6LOpC3vA67aBp0DRJC2qyIHsfbCDG/9HPVIoqp1qq1+w7tlVlZX2hi+r6TDXVv3lt3x2OmPSdOanrT16sOxwddAaIZfS6+mPEb/bnRghq/aMP00fBmc7nesUeuUHRSijiCbfPRk+BFIOpXVlfLNqv28dBAtw2dpGtdrjPv634fp13jEenbWbR+ZtBUyfD9Jh7uuIX2G4O7fyOM66jB81k5jhp8GZPqkrQoGHjcwsIYvg9Po+Gn4sk7uXujEGfwQko4KkxTVWeb/7anh60zaakg6Ug1f0UsnCFTeDth9I4TgoVMfQo82HpszCPLP5ElbTw3fT9LhrsvvGnUG46Skw2n4zvNjg28IdUbSUfC6CIOgko6TUVdUp8L/hWH4Kh1KS9LxyE9nnkNH0pFp+H6I2g8/zICS7pW2uki6ZdJqVNNq27PV8dIx6WHG6sC7ZToRG3xDqDOTtgE1fFUElXScBvaQFoconecHJYYvqLNU0kmzl05ldaWUbat66YSSdCJqL6qTtl4Lr6LsU8wtkxEP/u3N737aGH5Iu8GDGfygkk5GxtIhhLQghEwjhPya+N9ckq6aEPJj4k8xQkaIemW4W6YJBGHSzusKKunwEsquu3fhsFaHpfKMOrSCQiwdBiN++ITgxl43KqWtqqkKrMWH8cNX8fAJ9ealWCeV4GneYT+CgTF8ZvB5dqwj00TB8L0mbfdFhn83gC8opYcA+ALynaz2UEqPSfxdIEljDGFHalVJp1uLbqHKUUXjeo1dx0w0TtYIRZ1C1UunSV4TreiEXggq6QTS8DUYftP6TfHBpf5xUJyRGnmISMT9/ZN7BKXNDz9o/irPhp/LkeGaY64JXA8ZmJdOkuEH9NIJSxR5iBi+a+GjR1/JVIN/IYDXEp9fA3BRyPyMIDTDV3z9bJDTwD+RAfTv1B/tG9v3KzWp4csWhXj54Z97yLn47AorspoplqTy3Exp+DqTtoDaQMb74TvhbFND+gzB8FNT8Ski98MP0V5ysnKUno0KUYriDbCiusJu8HUknYgYPnN7ZWFcRJO2Xvc0Uw3+AZRStonbJvChGO2oTwgpIITMIoR4DgqEkEGJtAVFRYKA6ApIl1tmVC6IA48daKuHSFYwUTa7T7qvm1t3b8XBzQ7GgG4DXGnDDLZKDJ94u2Ue2vJQ/DDoB9+66C5Oc94jXsZiOL/7+cr+9M4BIIwfftQMX2SswuRlGnur9ia9dAA7w/eVdCLS8NlbOQvUlymTtr65EkI+B3Cg4Kd7+S+UUkoIkVnKTpTSQkLIwQC+JIQsoJQK93uhlI4BMAYAevXqFUhMlz3knKwcpYh+qpJOFGylW4tueOmCl2zHRPFcTLARL+8OP1c8mZE32WlEEBmMO6fdmfzct0NfHNf2ON+66E7aOjug8w1h651b0bxBc7z4g2A3G7hJhPN7GD98lXPDGFrdwF8isOuNwpAxg8+QCQyfBWUrKS+R5p2RBp9SeobsN0LIZkJIW0rpRkJIWwDCuIOU0sLE/5WEkK8BHAvAY4OvcJA95Po59VFaUSr8jYeqwY8iUJh0f1bnhGuAwcaZt9dmHX66bRQB04J66fBQfdvQWWkLuA2m83vL/Jau8nk4773JAVzFLTPqyXRVRFEPl8EPyvCDTJhL1mk0zrMYPrM3wpW2XosnM9FLB8AEAFcnPl8NwLU2nhDSnBCSl/jcCsBJADT2e9eHrOGrdiqd6IhRwqseJsqWGTOV/G2G1RCrV8nHj5lnQa1equEnkhq+owPKQhOo3gvXPrwG/PCjknQAc884CkmnvLrclm/QaJlh5k+cYJJOSUVmMfywVuNxAGcSQn4FcEbiOwghvQghTJc4HEABIeQnAF8BeJxSGqnBlzV81c7ERuznznnOM10kDF/AFkTxXEy4ZcqMGeD/Gs+fY0zDN8DwbR3YIz9ZCGlXeYn77LzfsgFD1Z8+OT/jeMtKV/A0XZjyYImK4fMI6ocfpD/LzmGSTpLha5KqjNwAhVK6DcDpguMFAK5LfP4ewFFhytFFUDbyxV++AJBiX63yW3mmj4KtyOQkFUnn/Uvfx7EHHqtclpeh8JN0otDwVc419eahO2nr7IBShi8xjC4NXyKvBTGs7K1nX2D4URiyVvmtbNtWakk6igRB5Xwe9XPqIycrx6bhu7cs3fcYfkZCyvB9Gu1pXU4DkOqMqsbl4OYH61ZRGyoMv0frHujSvItynux+iKQjHcPKf25Wv5ly+UHgN8iqvm2oSjrJcjUlHb+Vts4BIKhBbpXfKrnDWZShOEy5OpsmScNPGY4bjr/B5ozBD+a1xfBzsnKQn5tf5ySdjMQRrY8QHteVdFSNnklpR3XSVlSmbiNh90MkI+l4ZvCdqkleE9x4vNrKVFl9vGCK4fMGv+zvZdJ0DC5JRyIJBZ0nCuqHzy/+E92/P/X4k1a9rjv2OuFxYxq+YUnnkiMuQXZWts3g5+fmJz/XloafnZWN/Nz8ZL10XZ/jDVA00LVFV+z+++7A5zNZRdW4EBBcfuTlgctTgYvhCxqQqqshgx/D9+oA/CDhvE8tGrTQqoezPl7QMviKXjq8gZDBeb9lbwjKko5kANdl0gc1OShVtuD+jRgwAtX3Vysbs6jdak0zV3a/+LUYDXMbun6XQfamqgo/hu+VLmb4BtEg170KVteDQtngE4K3/vAWnjzjSc1auhFm0Zff6lGZbixj+F7g5xpMTeilleErTtoyODugrEPK5kX83DKD+uH76dXZWdlahky6P7DGM76v/33S30wzV3a/ZAxfK3haQLdMEbJJtq0emTJpW2cNvgi6r9t+jdO5MbTph8QbYhVJRzTIeYHlIZoo9pN0eMPgrEuU7qqm4purTtomy1XcIlCZVMB+z4PeMz+GqmvEZIRD9bpuOP4GY5uIqEDI8Os1lCV3nx9y4ZWXpON0D3Xew3jHq4gRlYavE2/Ft2wBwxKttBU1FuYKBgC92vVy5+10y3RIOud0Oyf5m5+kY2P4zhghAWWBdHrphJ20Zd+H9BmC7f+33bd+ynvaahpov+vVNWJhGb6MKARZaXvvyff6pvFj+L7nh/Qwk52Tk5Vju9a6Ei1zn4RqJ+DTiSaCnZO26VzN6PeK+MVfvsCSwUs883B2TJKIK84+e4E3YCrGYMddO3zTGJd0DPjhMzg7ILs/LRu0RPMGqajgqlscSmPpaBodv+vVNvghGX428Y67o0OKVNpDkuHXiDV83/OjYvgk23c1emzwI8ZtfW8DoO466DSgTvDbxgFmHpKsw+mGVmiS18QV4Etk4Pm8s0hW8nU4jKQjOk/lnmeiHz6D01Cx63c+c9XJV9dK24B++Hw7MMHwWRyioNBZsKeSlx+MMvwAGr6XtMe3DV2Dn6mhFfYp3Nv/XtAHqNSH2glV9pRk+IYlHdlnINjrp2wegJ+kZrKQjpdO1J4dPIwx/JCSjkyikIZHlnjpsPQmNHzR9Xo9m9nXzXYdG9x7MMZdNM6dj6Ix9IusqXOdOu0qsMGPiOED9rYhsg1X9rxS6VyT2K8MPgO/B6sXVPVRrxAFujHzpaEVItiFi9WbGXwCktyRSMdLx5WvT0ctuL7Asz5eOKjpQZ6/qzJ83cFZxvBVJ3OdMOWHH0bD79O+j2tlNiEERx3gXhivWi8/hi+qj2xFu46kwxt8VULnLCNMpFIR/Hbe6tehn1R2jQ2+QbBtx0b/brRnOt9FG7Czs6geEuAf0E3WaXoe0FOaB2vgvzvkd7j2mGvx/LnPJxk+v12fbn1k5/Vp3wcAcHy743Fzr5vd5yl0uBYNWoA+QNG7XW9x2YpL5XXZnPPZShm+qoZvyA8/rIav7J+fyLtBTgPc85t7pOn8NHzTDJ+l4b10dAx3WIbvVRZrG+xtWbT62suPPwrslwafwc+N0aaPerwue0Wd1IXqSlsn1gxdIzz+xV++QPeW3YW/sWvKy8nD2AvHon2T9mha32L4xeXFyl46qvjyL19i3e3rAEjeZDQmbWX3Q5nha2qkzvTs+qUavtMPXzWWjibLNK3h83WxHeOkpy7NukjPzSJZnmVqGfyAk7Y6g2ZUGj7gdtt2gu3UJUJs8A2C3WQ/ucXPeLBOu233NgBiI2JK3/bz8pDplq3yW6F/x/7C30QrbRnDLy4v9q6PxwAke6VuWK8hOjTpAEA8YJiYtLXFUfHowNqG1SnpaGr4TjivX9UQXn301bbvYf3wdY0cIcRXKhO6ZXrEpwqzpsE5aTvlyilpZfgqGr4sTXl1eWzw0wHWef20Pj+2UrDB0qLX7LLYdZReOlFA1DHv638fujbvijMOPsPTGHgx/Fv73oprj7nWs2zVPQecSDJ8yfmqgbNkG5/LoMvw/SBbE+FngJ3eRVFIOsJjSHmi+UllOpLOMwOecd3budfPxcKbFuox/ISkk5uVG5zhG4ylA6TahtPVmX0vr5Ib/DiWjkGwG+4n6fATUKJGxKIUJvON6CEB0Q4EfEM/ss2RWH7rcrTKbxVY0mmQ2wBPnPmEZ5lRSTq2WOge+VXWVPqWJSqXQeaW6aXhr75tdTL8RlA/fE+Db0jSEYHl3SCnQSipzFmf9k3au55lr3a90KNNj0AMPycrJxKGL/vt7pPutsUz4iFj+PwG57L7FTN8g2CGWUXS0VkQI3pI2kvbeVdMPrRCQEZsy9sngJdWXj718btu4YpilQ4OtwzFwxZbxiM/VU8tBpmk4+ywrL043x4pKDo164ROzTrZzk/WVdEPX5fhm5IUWd75ufmhJsOj0vCPamN5FrVu2DoSDV9W754H9MTa29cKf0syfLZeh018J4jmPifpEEL+SAhZRAipIYS41/Kn0p1NCFlGCFlOCJEH2kgTkhq+36StT+Ap3jMAMLNYQsZ8ZRKACgKHOggo6aiU6dzxya88Bj+G7+cKx8A8tVRRL7uebSFb0pVVElbCz9XQ1J62/EDkJcXIIBwkPAaOBrk+DF9jvwLAug/ScA4aDH/EgBGY8dcZOKzVYYH7RhDvIlUvHR7/OvNf+FOPP+H3h//edv7wU4bj0JaH2s41jbAMfyGA3wOYLktACMkG8DyAcwAcAeByQog4YH2akJR0fBh+blaup7sc04FZaOQovXRMgOV9zIHHKKVXXXgVBKd0PkWrLgzOxWJO2Ay+R/2DSDq8zzS7l852wXY4chp8xsydq5uddTUdWsEvP9Hv3Vt2lz6XoAxfFp/KizgorbTlPM1O6niS7ZgK+LRBJB0VLx0nEWzfuD3GXzIe+bn5tv6en5sfuYt3KINPKV1CKV3mk6wPgOWU0pWU0goA4wFcGKbcsGA31S9+fG52rmdHZAz/mmOuASCRdCL20rm0x6VYfLPeFsGzBs5CyT0lye9B3NF8Gb5Pnlf2vBKb/7YZfdv3TZ2j4aUjGxhVGb6upMOwdPBSrLx1pWulLMPW3VsBAK0apAz+nSfeiUdOe8RWJ6mGr/ksVN1QZRCVl5eTh/k3zLcdY/crPzc/lIYv9HaTxe9RkXQUJ51Vzg8ykKksvHK91XDX61QJTIZpESEdGn57AOu47+sTx4QghAwihBQQQgqKiooiqZDqBh2qDN85Gx8GMt3e2SmYwW3bqC0Ob324Vhl5OXloVK9RKB1eNfqjF9o0bKPc4Zz5Kkk6gjrccPwNAPQlHYZDWx2KLs27SBk+27T6wEYHJo89eeaTyfUNsjcUVT98LynI1AStCHsq9wCw3oq92rmuhu/VjnTmdPyOqZwfJLaNs47LblmGWQNnAfB3ywTkxKnWYukQQj4nhCwU/EXC0imlYyilvSilvVq3bh1FEfjgTx/g0dMeRdfmXT3T5WbnemrGvCsYYEbSefz0x13HvFiRzsSWLsIsvFIt08st7vrjrnel9zMoXgx/0p8nJdcB6Eo6Tsg2ybmp900Y0mcI7jzpTuF5Ls0/UceoYun4wesZjxgwApP/PBkAsLvS2kGuQW4Dz3bu1weCGmNpGpMMP4CG7zzevWV39O1gvbWytuhUEvhBmyeflNLkNdeaWyal9AxK6ZGCv48VyygEwPstdUgcqzV0bNoR95x8j2/D4Bm+iA07GX5YLx36AMXA4waKf5NIOlGyOi8MPFZcT13InkHFPyrwwu9ecB3XknS4vO/rfx/OPeRcXHvstejRugcGHT8oTLWlkk6jeo0w8pyRLpfdZJ2YpBPQD98J2Urbe0++13cHNL/yhvYbinMOsfZI2FNlMfz83HwX++QXg+m2R88QHYK20blZZ4wYMCKVJk0M30/S2fy3zclV5AxJg594DqLraZLXBLf0viWVX8B2oIp0WIu5AA4hhHQhhNQDcBmACWkoNzR4hi9itIzhm5R0ePTv1B85WTm444Q7pJKOTgfTjXUua3QXHXYR+ncSr971y1MV/L3nEdRL54qjrgAAtGvcDgtvXoiOTTtizdA12HjHxkD1CzrgsvsiW2lratL2vv73oeK+YPMUIjCGn5+Tb2OfO+7agbEXjE1+l/UBmWH3DMInaH/dWnTD0H5DU2nSpOG3bdxWeJzd/zYN2yTfHhnYffILxc1ceNOx6DKsW+bFhJD1AE4AMIkQMiVxvB0hZDIAUEqrANwCYAqAJQDepZQuClft9IBftSc0+E4N3/BrWOuGrVF5XyVOPOhEV4eRuQWKIEsTVIcvKvOfWwki6aggKMMXTdB3bNrRprXrgI8wqgPZpK2qH77XVpeq8oStXMV0fzj8Dzi81eH424l/c8WY4uvg5wghQii3TIMMX4azup6FqVdOFZ+v4Jbpd090JrLDIqyXzoeU0g6U0jxK6QGU0gGJ4xsopedy6SZTSrtTSrtSSh8JW+l0oV52veSoLWJybHUfe6CRRsuUxVPXkYwMbFANAFvKtmil94JXh/HyK1dh+Pwzi2q/YV1GLpt0VnlT+OyKz1zHZAxf9c1D9dm3btgaiwcvxiEtD3Ht5MTfA5mUJYPnpK2gbrLJctt5Ad8uZXUZeOxAtG8i9jNRCa2gutkOr+FH5Z69X660VUVudi4+veJTjLtoHFrmt/SNp1IbwdOi1PBlnWpz2Wbh8XMPOVd4PEgZMugwfF7DNm7wFQyPCFKGz0WjBCCMSCmS0aQMPyINGPCO0Klr8AE1qfHUzqfa0npJYPzezn7g39yDRID1MsyyuT3ZKut0oE4b/K+u/irU+dkkG20bt8VVR18FwApBzG/e4dLwI4yl40QQDT8oG3WGCbjrpLtcaavuq8LEyydqlxVUs5YZCd4Y8a/SKhOYOgjK8GX15w3YwpsW4tMrPnWdK2pftpW2Hh5PJiErEwjA8BX2VbjosIuSG5o7N54RGcuWDVq6jv3h8D8AAAZ0HWA7zhv5IPMM5dXl0t+YXdAx6G//4W1c2fNK9GjTQ/kcHUSnQWQA2GrOoHB2mvZN2qN9k/YY2ncoRhWMUvLSMQXZpK1Ox/YLsSxD07ymuOH4G3DFUVegd3vxxiNBBzvdNxQdhs+/SkfF8INO2so0fADo0aYHNpa4J5OzSBYe+O0DKCkvQWVNJV7/+XWpH77yHEqAgYEfVJ3X72fwneVRUNx4/I3457f/dKUVvb2oMHxX3KMHHPd6eOocvl/JDLtXPymvkht8Zzx8lfmZHm164PWLX/dMFwZ1muFHhRFnj0D5P8ptEfoA8YMlIJj858n4vxP/T5iX6haIsh2TTPjh+3npEELwzNnPSI29CKqDSZB47ICahs+z+iCTiV4IOmnL4KfhiwaoLJKF5g2aY+yFY9Ewt6HrvECTtgHq7xW/p3G9xlp5UUrx0KkPofI+97oIL4kq6MpkJ2wMX9KmRAMB859XYfiqIaqjDKvCEBv8EHAuvJLtc3rOIeck43w48fSApwHoe2cEYZi6M/9RygKiMlQavB/D79I8pX3zRt40w2eL9lrmu+UDL/jFAmIQvTGJJBvd4HMm4LUTnIzhy9oeBQUhJPl8+M3lRZ5LznYfto2KNHzn9pmiuv/1mL8CQHIPaBGUDX6s4e9bYA/WS1dn8o+TAbEG7ieJyNwylQJMhewUUTbIS3tcqpXeS8MvvacU7Rq3c6UFzBv8J898EhMum4ATDzpR6zznpK3s2fg5AIhCMQSKpRNE0vFg+CoaPv8s+Ha9YdgG27oI0bXJwlI7semOTdgwbINvXWzhSxKf51w/x3YdInLx2OmP4Yu/fOH51pvU8NNAnFQRG3wDYA9WGPLXsdDm9INPt52bl5Nny0MVTq+OIPD1ww9h6FUbeZ/2faShhEUQMfyDmhwE+gBFw3oNpeeZXhSXl5OH8w89X/s89tbht9uab4gCgQxQGwzf2f68ngFD5X2Vrq0aAWtxU/MGzZPf+UHNOVD6vSkd0OgA6WIpAElJTMVLR3Q8NzsXp3U5TZo/kAq/7ozbFHTfahOIDb4BMGPNvAN+f/jvXWmObXssAOCqnlfZjrOO72eQnI1h2AnDcP1x1+P2E24PVmkOURiKRvUa4ZkBzyilbdvI6pgqE78ihu9nPIHMYVn9O/XHP07+R3J1KhvsnPXzjTopWI9gKlqmH7y8dGQ+5xcdehEAa6Us4D8Xw6cRpVeVxkTY8rctKBxW6Drfdi95GSmgIWbuoUznl86VxRr+vgXG2lrmt8Tmv23G42ekAqCxhnNw84NBH6CuwYBJOn4M39kYmuQ1wZjzxwTye9ZFUGN5W7/blNJ9duVnePXCV5WimIr82NlbUhiwQeeB3z4QOi8vZJEsPHzawzig0QEALNfhF373gus5+rUHUww/iCeblx++DDf3vhm77t6Fg5sfbJ2nsMCI1/Cd13bCQScACOZu27ph62T0UhUvnSCDCpCSb/dW7fVMl04Nv067ZaYLfOds07ANNpSktEOv10pAXdIx8bqXDgYRBO0at8PVx7hf8UUQMXx+oi8o5t0wD79u+xX1suth+DfDQ+enis7NOuPGXje6jvMsunG9xii+p9j2u4jhB4nxf/9v78dVPa9Ct2e7KZ8jYvjPn/s8erSW+44TQmwLovxWTLNznGBtePwfxmPJ1iVJwx0UMklHFqZ8wU0LlFfOsuv1M/jpRGzwDcCpY/IjdqemnTzPZY1Hl+HrQMYg/PJMh6aoC9GchYqk44cDGx2IAxsdiPKqcpxx8Bn4fOXnofMMA3adt/a51fbGyCBi+CzAmW45XVt4hwl3QsTwb+59s1YeKjKGaC6MtcmG9RqiVzvprqrK4I38kW2ODJxGBKfB1/XEiwL7jaTDtMN0gGcm/D6oIrDOkxaGrxktM/l7Gl85Rfhtp98mP4smbU1IOnxe066aZiy/MMgm2cjPzRfuvSxiyGWVZempl4EV5extoGPTjtI0SddTwaStKbD8Ljj0AmldAks6eWJJJ8z+1GGx3zD8eYPmKaddddsqzxV0DB2adMD64vWu40yLPqjJQXj41Ic982AGLMqwDJkyYRkEhcMK0bx+c+Q/mg9APNlnguFnIob0GYIB3QYIfzPF8INAx+Pp+uOut7nKMtzW7zb07dDX062VLWzkt1U0zYJV3JuDGnzG8NluYQxSL500SK77jcFno60MbFsywNJVVTD3+rlYvn2563i97Hqu5dwyqG5aHKahB21IJhrgzIEzQ00sO42FiOHXVYM/4uwR0t9EcxllFZnH8MecP0Z4PItk+a5h2FS6CQDQoXGHZDC5Px/5Z+WyVaCyYjpo32Pt/qyuZ1llaO47EQX2G4PvB7YtmQ6Y7hsG3Vt2xyVHXCINvcAQxeiv2pDDvCH069Av8LkiiNzx6qrB94JI4mCSjo7OHARR7bfqBHt77tCkA9o2bovyf5QbD4LHWLhz8xIeQRl+TlYOlg9ZLnzDESEdGn4og08I+SOABwEcDqAPpbRAkm41gBIA1QCqKKXhZ1vqCBrkNsD//vi/SMvIdI1eB1F56Yjg5XWSKRBp+A+d8lCkZaYrKixb18IiR6p6x+jgjIPPwBsXv4E/HPEH23HRCtwgUJkQ35c0/IUAfg/gvwppT6WUbg1ZXp2DKmOJwi0zU900vSCctI3A4G+9cyvyc/ON52sKIg2fSToqq13DIF0M/4FTHsCpXU713U4zDAghuKLnFZ5pMtFbLSjC7ni1hFK6zFRl9keosqUo3DL3RYiuJQpJp2V+S6F3TKZA5KUzYsAInNL5FPym428iLTtdDL9+Tv2k/l2bCCrpyOAcQNI1gALp0/ApgKmEEArgv5RS8UzOfgbViV1APYyyZ3l1gKnFhPlrAAAISElEQVSIJJ3uLbtL0x/U5CCsK14Xeb3SDdFcxlEHHBV60x8VpNNAZQJMvQnLiNewE4ahsKQQt/cLHybFD74GnxDyOQDRzOS9lNKPFcv5DaW0kBDSBsA0QshSSul0SXmDAAwCgI4d5T66+xuePPNJtGnYRrhRRFgE3eS8NuCUdF676DVXfCIeK25dYZyhZQJq09U2nTu7ZQKibj+N8xpLvZlMw1fSoZSeQSk9UvCnauxBKS1M/N8C4EMAfTzSjqGU9qKU9mrdurVqEXUeTes3xcOnefv0+8HJMJg2euVRV2qdFyWmXzMd/z1PPiXEDP4RrY8AYC2Y8TJ+udm5RhdmZRpqYx5mv2P4GUh8giJySYcQ0hBAFqW0JPH5LADRuhHEEMLZcLu26KolK6UDJ3c6GSd3Oln6OzPuH/7pQxRsKECz+s3SVbWMgkosmqiwPzB8laBq+yJCTdoSQi4mhKwHcAKASYSQKYnj7QghkxPJDgAwgxDyE4A5ACZRSj8LU24MPQR9/c9ELx7G8Js3aI4zu55Zy7WpPfjt/BUl9juGn4H9IChCMXxK6YewJBrn8Q0Azk18Xgng6DDlhMG4i8ZhV/mu2io+o6DbcFms9iF9hkRRnUAIs+FLXYJzY510Yn9g+DyMe+nU4gBS51faXnW0fEKvtrDzrp1pfRUPqsE3rNcw4ySf2OBbYJEij2t7XNrL3u8YvqG+yiLnhg3pHAZ13uBnImrrgdeFyad9yeA3qtcIRx8QzcvtBYdegNW3rUanZt7ht6PAvhyMTxcXHXYRBvcebCSvpwY89f/t3VuIVVUcx/HvD0czLzg5lowZjoIUhZFDlJbkVBQ5hEEUaEE+pGH1kBSEEhQ9FhIVSBcq6cHuV1GiTOulB03NMcvUqSZSdMYCs3rp9u9h/48ehxlHnXNmr3P2/wObs/baZ2b/mDXnf/Ze+1xoa2mr6hvJBlL4gj9p7KQTvrCkHj3W9hhH/zrKktYleUcZtFp6E9nvK36v6u/Po9ifqk13baJpVFPeMc7YeaPPo+tIF2tuXVOxd1yPbBjJ7ZfcXpHfdaYKX/A7lnbQ/Ud33jFOWfv09j4/ofNkxp89ntW3rK5SoqFVpKPLWnbt1GvzjjAony/6nA0/bEj64zXOROEL/oRRE45dnKwF6+9Yn3eEUIdWta86rYuJK29YydyWuQPfsUZNaZzC4tbFeceouMIX/BDC6X9F4UNXPVSlJKGaouCHmrBz6U42/rgx7xgh1LQo+KEmzJg4gxkTZ+QdI4SaVjuvcQshhDAoUfBDCKEgouCHEEJBRMEPIYSCiIIfQggFEQU/hBAKIgp+CCEURBT8EEIoCKX8bS6SDgM/neGPTwB+qWCcSks9H0TGSkg9H0TGSkgp3xQz6/MLwZMu+IMhaauZXZ53jv6kng8iYyWkng8iYyWknq8kpnRCCKEgouCHEEJB1HPBfzHvAANIPR9ExkpIPR9ExkpIPR9Qx3P4IYQQTlTPR/ghhBDKRMEPIYSCqLuCL+kmSXskdUpanmOOVyT1SNpV1jde0gZJ+/z2HO+XpGc9805JrUOQ7wJJn0n6VtI3kh5IMONISVskdXjGx71/qqTNnuVNSSO8/yxf7/TtLdXO6PsdJukrSesSzdcl6WtJOyRt9b5kxtn32yjpHUnfSdotaXZKGSVd6H+/0nJU0rKUMp4SM6ubBRgGfA9MA0YAHcDFOWW5BmgFdpX1PQks9/Zy4AlvtwMfAQJmAZuHIF8z0OrtscBe4OLEMgoY4+3hwGbf91vAAu9/HrjX2/cBz3t7AfDmEI31g8BrwDpfTy1fFzChV18y4+z7fRVY7O0RQGNqGcuyDgMOAVNSzdhv9rwDVHggZgMfl62vAFbkmKelV8HfAzR7uxnY4+0XgIV93W8Is34I3JBqRmAUsB24kuwdjQ29xxz4GJjt7Qa/n6qcazKwEbgOWOcP8GTy+b76KvjJjDMwDvix998ipYy9ct0IfJFyxv6WepvSOR/4uWx9v/elYqKZHfT2IWCit3PN7VMLM8mOoJPK6NMlO4AeYAPZGdwRM/unjxzHMvr234CmKkd8GngY+M/XmxLLB2DAJ5K2SbrH+1Ia56nAYWC1T429JGl0YhnLLQBe93aqGftUbwW/Zlj2tJ/7a2IljQHeBZaZ2dHybSlkNLN/zewysiPpK4CL8sxTTtLNQI+Zbcs7ywDmmFkrMA+4X9I15RsTGOcGsunP58xsJvAn2fTIMQlkBMCvx8wH3u69LZWMJ1NvBf8AcEHZ+mTvS0W3pGYAv+3x/lxySxpOVuzXmNl7KWYsMbMjwGdkUySNkhr6yHEso28fB/xaxVhXA/MldQFvkE3rPJNQPgDM7IDf9gDvkz1xpjTO+4H9ZrbZ198hewJIKWPJPGC7mXX7eooZ+1VvBf9LYLq/SmIE2anX2pwzlVsLLPL2IrJ581L/XX5lfxbwW9lpYlVIEvAysNvMnko047mSGr19Ntk1ht1khf+2fjKWst8GbPKjrqowsxVmNtnMWsj+1zaZ2Z2p5AOQNFrS2FKbbP55FwmNs5kdAn6WdKF3XQ98m1LGMgs5Pp1TypJaxv7lfRGh0gvZ1fG9ZHO9j+SY43XgIPA32RHM3WTztRuBfcCnwHi/r4BVnvlr4PIhyDeH7PRzJ7DDl/bEMl4KfOUZdwGPev80YAvQSXZqfZb3j/T1Tt8+bQjHu43jr9JJJp9n6fDlm9JjIqVx9v1eBmz1sf4AOCfBjKPJzsjGlfUllXGgJT5aIYQQCqLepnRCCCH0Iwp+CCEURBT8EEIoiCj4IYRQEFHwQwihIKLghxBCQUTBDyGEgvgft+mZuO5pdwMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}